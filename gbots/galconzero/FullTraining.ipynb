{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\GalconZero\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\GalconZero\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from nnModel import getModel\n",
    "model = getModel(\"gz_dev.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "from os.path import isfile, join\n",
    "from subprocess import Popen\n",
    "\n",
    "from nnTrainingSession import NNTrainingSession\n",
    "from nnTrainingFile import createTrainingFiles\n",
    "\n",
    "currentDir = '.'\n",
    "gameSourceDir = \"D:/GalconZero/Games/\"\n",
    "gameArchiveDirPrefix = \"D:/GalconZero/OldGames/Iter\"\n",
    "modelArchiveDir = \"D:/GalconZero/OldModels\"\n",
    "\n",
    "NUM_FILES_PER_ITERATION = 100\n",
    "\n",
    "botProcess = None\n",
    "\n",
    "session = NNTrainingSession(model)\n",
    "\n",
    "def restartBots():\n",
    "    botBasePath = r\"C:\\Users\\Evan Sparano\\Documents\\GitHub\\galcon-alphazero\\gbots\"\n",
    "    botProcess = Popen(botBasePath + \"\\launch8Bots.bat\", cwd=botBasePath)\n",
    "\n",
    "def killBots():\n",
    "    # TODO: this only kills one bot process? not all of them?\n",
    "    if botProcess != None:\n",
    "        os.kill(botProcess.pid, signal.SIGTERM)\n",
    "    \n",
    "def archiveGames(iterationNum):\n",
    "    archiveDir = gameArchiveDirPrefix + str(iterationNum)\n",
    "    os.makedirs(archiveDir)\n",
    "\n",
    "    files = os.listdir(gameSourceDir)\n",
    "    for f in files:\n",
    "        if 'npz' in f:\n",
    "            shutil.move(gameSourceDir+f, archiveDir)\n",
    "        else:\n",
    "            os.remove(gameSourceDir+f)\n",
    "\n",
    "def getCurrentIteration():\n",
    "    onlyFiles = [f for f in os.listdir(modelArchiveDir) if isfile(join(modelArchiveDir, f)) and 'iter' in f]\n",
    "    return max([ int(re.findall(r'\\d+', filename)[0]) for filename in onlyFiles], default=-1) + 1\n",
    "\n",
    "def trainModel():\n",
    "    # 10 loops because only a 10th of the data is actually sampled per loop\n",
    "    # -1 numGamesPerLoop to use all games\n",
    "    session.doTrain(num_loops=10, numGamesPerLoop=-1, numEpochs=1)\n",
    "    print(\"trained the model!\")\n",
    "\n",
    "def nextIteration():\n",
    "    # TODO: this isn't actually killing the bots, so the bots keep generating unused games while model is training\n",
    "#     killBots()\n",
    "    \n",
    "    prevIterNum = getCurrentIteration()\n",
    "    model.save(modelArchiveDir + '/gz_dev.iter{0}.model'.format(prevIterNum))\n",
    "    \n",
    "    trainModel()\n",
    "    model.save(\"gz_dev.model\")\n",
    "    \n",
    "    archiveGames(prevIterNum)\n",
    "    \n",
    "    restartBots()\n",
    "    \n",
    "def startTrainingLoop(maxIterations=3):\n",
    "    restartBots()\n",
    "    \n",
    "    while getCurrentIteration() < maxIterations:\n",
    "        time.sleep(1)\n",
    "        createTrainingFiles()\n",
    "        files = os.listdir(gameSourceDir)\n",
    "        # multiply by two because of pickle and npz files\n",
    "        if len(files) >= NUM_FILES_PER_ITERATION * 2:\n",
    "            nextIteration()\n",
    "            \n",
    "    killBots()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading 90 training files and 10 validation files\n",
      "Train on 10800 samples, validate on 12000 samples\n",
      "Epoch 1/1\n",
      "10800/10800 [==============================] - 4s 397us/step - loss: 5.3982 - policy_loss: 2.3515 - value_loss: 0.3047 - policy_acc: 0.8966 - value_acc: 0.8765 - val_loss: 4.2499 - val_policy_loss: 2.6493 - val_value_loss: 0.1601 - val_policy_acc: 0.7239 - val_value_acc: 0.9295\n",
      "Finished loading 90 training files and 10 validation files\n",
      "Train on 10800 samples, validate on 12000 samples\n",
      "Epoch 1/1\n",
      "10800/10800 [==============================] - 2s 184us/step - loss: 4.5041 - policy_loss: 2.2743 - value_loss: 0.2230 - policy_acc: 0.8819 - value_acc: 0.9029 - val_loss: 3.9409 - val_policy_loss: 2.6360 - val_value_loss: 0.1305 - val_policy_acc: 0.7164 - val_value_acc: 0.9443\n",
      "Finished loading 90 training files and 10 validation files\n",
      "Train on 10800 samples, validate on 12000 samples\n",
      "Epoch 1/1\n",
      "10800/10800 [==============================] - 1s 102us/step - loss: 4.0701 - policy_loss: 2.2424 - value_loss: 0.1828 - policy_acc: 0.8811 - value_acc: 0.9234 - val_loss: 4.0557 - val_policy_loss: 2.6532 - val_value_loss: 0.1403 - val_policy_acc: 0.7112 - val_value_acc: 0.9405\n",
      "Finished loading 90 training files and 10 validation files\n",
      "Train on 10800 samples, validate on 12000 samples\n",
      "Epoch 1/1\n",
      "10800/10800 [==============================] - 1s 110us/step - loss: 3.7015 - policy_loss: 2.1918 - value_loss: 0.1510 - policy_acc: 0.8783 - value_acc: 0.9359 - val_loss: 3.9058 - val_policy_loss: 2.6397 - val_value_loss: 0.1266 - val_policy_acc: 0.7107 - val_value_acc: 0.9503\n",
      "Finished loading 90 training files and 10 validation files\n",
      "Train on 10800 samples, validate on 12000 samples\n",
      "Epoch 1/1\n",
      "10800/10800 [==============================] - 1s 111us/step - loss: 3.3719 - policy_loss: 2.2042 - value_loss: 0.1168 - policy_acc: 0.8673 - value_acc: 0.9499 - val_loss: 3.8339 - val_policy_loss: 2.6457 - val_value_loss: 0.1188 - val_policy_acc: 0.7012 - val_value_acc: 0.9561\n",
      "Finished loading 90 training files and 10 validation files\n",
      "Train on 10800 samples, validate on 12000 samples\n",
      "Epoch 1/1\n",
      "10800/10800 [==============================] - 1s 111us/step - loss: 3.1938 - policy_loss: 2.2061 - value_loss: 0.0988 - policy_acc: 0.8772 - value_acc: 0.9576 - val_loss: 3.9448 - val_policy_loss: 2.6767 - val_value_loss: 0.1268 - val_policy_acc: 0.7061 - val_value_acc: 0.9526\n",
      "Finished loading 90 training files and 10 validation files\n",
      "Train on 10800 samples, validate on 12000 samples\n",
      "Epoch 1/1\n",
      "10800/10800 [==============================] - 1s 111us/step - loss: 2.9730 - policy_loss: 2.1633 - value_loss: 0.0810 - policy_acc: 0.8751 - value_acc: 0.9671 - val_loss: 3.9497 - val_policy_loss: 2.7181 - val_value_loss: 0.1232 - val_policy_acc: 0.7220 - val_value_acc: 0.9540\n",
      "Finished loading 90 training files and 10 validation files\n",
      "Train on 10800 samples, validate on 12000 samples\n",
      "Epoch 1/1\n",
      "10800/10800 [==============================] - 1s 111us/step - loss: 2.8113 - policy_loss: 2.1405 - value_loss: 0.0671 - policy_acc: 0.8740 - value_acc: 0.9755 - val_loss: 4.3335 - val_policy_loss: 2.6552 - val_value_loss: 0.1678 - val_policy_acc: 0.7010 - val_value_acc: 0.9394\n",
      "Finished loading 90 training files and 10 validation files\n",
      "Train on 10800 samples, validate on 12000 samples\n",
      "Epoch 1/1\n",
      "10800/10800 [==============================] - 1s 111us/step - loss: 2.7247 - policy_loss: 2.1489 - value_loss: 0.0576 - policy_acc: 0.8735 - value_acc: 0.9789 - val_loss: 3.9619 - val_policy_loss: 2.6652 - val_value_loss: 0.1297 - val_policy_acc: 0.7085 - val_value_acc: 0.9537\n",
      "Finished loading 90 training files and 10 validation files\n",
      "Train on 10800 samples, validate on 12000 samples\n",
      "Epoch 1/1\n",
      "10800/10800 [==============================] - 1s 111us/step - loss: 2.6582 - policy_loss: 2.1322 - value_loss: 0.0526 - policy_acc: 0.8818 - value_acc: 0.9801 - val_loss: 4.1125 - val_policy_loss: 2.6674 - val_value_loss: 0.1445 - val_policy_acc: 0.7083 - val_value_acc: 0.9510\n",
      "trained the model!\n"
     ]
    }
   ],
   "source": [
    "startTrainingLoop(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnTrainingGraph import plotNNTrainingSession\n",
    "\n",
    "plotNNTrainingSession(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
