{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "    # device_count = {'GPU': 1}\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "set_session(session)\n",
    "tf.global_variables_initializer().run(session=session)\n",
    "tf.local_variables_initializer().run(session=session)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"gz_dev.model\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from trainingHelper import TrainingHelper\n",
    "from trainingGame import loadTrainingGame\n",
    "from mapHelper import mapHelper\n",
    "import nnHelper\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "filepath = \"D:/GalconZero/Games\"\n",
    "\n",
    "TRAINING_CACHE_SUFFIX = \".npz\"\n",
    "TRAINING_GAME_SUFFIX = \".pickle\"\n",
    "BATCH_SIZE = 128 #2048\n",
    "\n",
    "def createTrainCacheFile(trainingFile):\n",
    "    trainingGame = loadTrainingGame(trainingFile)\n",
    "    helper = TrainingHelper(trainingGame)    \n",
    "    exampleState = trainingGame.states[0]\n",
    "    mapHelper.setItems(exampleState)\n",
    "    \n",
    "    \n",
    "    trainX = helper.getTrainX()\n",
    "    trainPolicy, trainValue = helper.getTrainY()\n",
    "    \n",
    "    trainingCacheFile = trainingFile.replace(TRAINING_GAME_SUFFIX, TRAINING_CACHE_SUFFIX)\n",
    "    \n",
    "    np.savez(trainingCacheFile, trainX=trainX, trainPolicy=trainPolicy, trainValue=trainValue)\n",
    "\n",
    "def fetchTrainXY(trainingFile):\n",
    "    trainingCacheFile = trainingFile.replace(TRAINING_GAME_SUFFIX, TRAINING_CACHE_SUFFIX)\n",
    "    if not isfile(trainingCacheFile):\n",
    "        createTrainCacheFile(trainingFile)\n",
    "        \n",
    "    npzFile = np.load(trainingCacheFile)\n",
    "#     print('loaded ' + trainingCacheFile)\n",
    "    return npzFile['trainX'], npzFile['trainPolicy'], npzFile['trainValue']\n",
    "            \n",
    "# def getTrainingDataForNumGames(num=-1):\n",
    "#     onlyFiles = [f for f in listdir(filepath) if isfile(join(filepath, f)) and TRAINING_GAME_SUFFIX in f]\n",
    " \n",
    "#     trainX = np.empty((0, 22, 14))\n",
    "#     trainY = [np.empty((0, 925)), np.empty((0,))]\n",
    "\n",
    "#     filenames = onlyFiles if num==-1 else random.sample(onlyFiles, num)\n",
    "#     for filename in filenames:\n",
    "#     #     print(\"loading training file {}\".format(filename))\n",
    "#         nextTrainX, policy, value = fetchTrainXY(filepath + \"/\" + filename)\n",
    "        \n",
    "#         #twice, once for regular, once for flipped Y values\n",
    "#         trainX = np.concatenate((trainX, nextTrainX))\n",
    "#         trainX = np.concatenate((trainX, getXAxisReflectedTrainingData(nextTrainX)))\n",
    "\n",
    "#         #twice, once for regular, once for flipped Y values (reflecting over x axis does not change policy or value)\n",
    "#         trainY = [np.concatenate((trainY[0], policy)), np.concatenate((trainY[1], value))]\n",
    "#         trainY = [np.concatenate((trainY[0], policy)), np.concatenate((trainY[1], value))]\n",
    "\n",
    "#     print(\"Finished loading {} training files\".format(num))\n",
    "#     return trainX, trainY\n",
    "\n",
    "def getTrainingDataForNumGames(num=-1):\n",
    "    onlyFiles = [f for f in listdir(filepath) if isfile(join(filepath, f)) and TRAINING_GAME_SUFFIX in f]\n",
    " \n",
    "    NUM_VALIDATION_FILES = 10\n",
    "    \n",
    "    valTrainX = []\n",
    "    valYPolicy = []\n",
    "    valYValue = []\n",
    "    trainX = []\n",
    "    trainPolicy = []\n",
    "    trainValue = []\n",
    "    \n",
    "    # reserve 20 games worth of files for validation only\n",
    "    validationFilenames = onlyFiles[len(onlyFiles) - NUM_VALIDATION_FILES:]\n",
    "    for filename in validationFilenames:\n",
    "    #     print(\"loading training file {}\".format(filename))\n",
    "        nextTrainX, policy, value = fetchTrainXY(filepath + \"/\" + filename)\n",
    "        \n",
    "        #twice, once for regular, once for flipped Y values\n",
    "        valTrainX.extend(nextTrainX)\n",
    "        valTrainX.extend(getXAxisReflectedTrainingData(nextTrainX))\n",
    "\n",
    "        #twice, once for regular, once for flipped Y values (reflecting over x axis does not change policy or value)\n",
    "        valYPolicy.extend(policy)\n",
    "        valYPolicy.extend(policy)\n",
    "        valYValue.extend(value)\n",
    "        valYValue.extend(value)\n",
    "    \n",
    "    \n",
    "    \n",
    "    trainFilenames = onlyFiles[:len(onlyFiles) - NUM_VALIDATION_FILES]\n",
    "    \n",
    "    filenames = trainFilenames if num==-1 else random.sample(trainFilenames, num)\n",
    "    for filename in filenames:\n",
    "    #     print(\"loading training file {}\".format(filename))\n",
    "        nextTrainX, policy, value = fetchTrainXY(filepath + \"/\" + filename)\n",
    "        \n",
    "        #twice, once for regular, once for flipped Y values\n",
    "        trainX.extend(nextTrainX)\n",
    "        trainX.extend(getXAxisReflectedTrainingData(nextTrainX))\n",
    "\n",
    "        #twice, once for regular, once for flipped Y values (reflecting over x axis does not change policy or value)\n",
    "        trainPolicy.extend(policy)\n",
    "        trainPolicy.extend(policy)\n",
    "        trainValue.extend(value)\n",
    "        trainValue.extend(value)\n",
    "\n",
    "    valTrainX = np.array(valTrainX[::10])\n",
    "    valYPolicy = np.array(valYPolicy[::10])\n",
    "    valYValue = np.array(valYValue[::10])\n",
    "    trainX = np.array(trainX)\n",
    "    trainPolicy = np.array(trainPolicy)\n",
    "    trainValue = np.array(trainValue)\n",
    "    \n",
    "    print(\"Finished loading {} training files and {} validation files\".format(len(filenames), len(validationFilenames)))\n",
    "    return trainX, [trainPolicy, trainValue], valTrainX, [valYPolicy, valYValue]\n",
    "\n",
    "def trainingLoop(numGamesPerLoop, numEpochs):\n",
    "    trainX, [trainYPolicy, trainYValue], valTrainX, [valYPolicy, valYValue] = getTrainingDataForNumGames(numGamesPerLoop)\n",
    "    \n",
    "    indices = np.arange(len(trainX))\n",
    "    randomSubsetIndices = np.random.choice(indices, size=int(len(trainX)/10), replace=False)\n",
    "    \n",
    "    trainX = np.take(trainX, randomSubsetIndices, axis=0)\n",
    "    trainYPolicy = np.take(trainYPolicy, randomSubsetIndices, axis=0)  \n",
    "    trainYValue = np.take(trainYValue, randomSubsetIndices, axis=0)\n",
    "    \n",
    "    return model.fit(trainX, [trainYPolicy, trainYValue], validation_data=(valTrainX, [valYPolicy, valYValue]), epochs=numEpochs, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "def getXAxisReflectedTrainingData(data):\n",
    "    data = data.copy()\n",
    "    for sample in data:\n",
    "        for row in sample:\n",
    "            row[8] *= -1\n",
    "            row[11] *= -1\n",
    "            row[14] *= -1\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyPolicyValAcc = []\n",
    "historyValueValAcc = []\n",
    "\n",
    "historyPolicyValLoss = []\n",
    "historyValueValLoss = []\n",
    "historyValLoss = []\n",
    "\n",
    "def doTrain(num_loops, numGamesPerLoop,numEpochs=1):\n",
    "    for i in range(num_loops):\n",
    "        history = trainingLoop(numGamesPerLoop, numEpochs)\n",
    "\n",
    "        historyPolicyValAcc.extend(history.history['val_policy_acc'])\n",
    "        historyValueValAcc.extend(history.history['val_value_acc'])\n",
    "        \n",
    "        historyPolicyValLoss.extend(history.history['val_policy_loss'])\n",
    "        historyValueValLoss.extend(history.history['val_value_loss'])\n",
    "        historyValLoss.extend(history.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# doTrain(num_loops=1000, numGamesPerLoop=100)\n",
    "\n",
    "# for some dumb reason, I have to do this suddenly\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    # for some dumb reason, this fails the first time\n",
    "doTrain(num_loops=100, numGamesPerLoop=20,numEpochs=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "    \n",
    "plt.figure(1, figsize=(18, 18))\n",
    "   \n",
    "# summarize history for accuracy  \n",
    "   \n",
    "plt.subplot(211)  \n",
    "# plt.plot(history.history['policy_acc'])  \n",
    "plt.plot(historyPolicyValAcc)  \n",
    "# plt.plot(history.history['value_acc'])  \n",
    "plt.plot(historyValueValAcc)  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "# plt.legend(['policy_categorical_accuracy', 'val_policy_categorical_accuracy', 'value_categorical_accuracy', 'val_value_categorical_accuracy'], loc='upper left')  \n",
    "plt.legend(['Validation Policy Accuracy','Validation Value Accuracy'], loc='upper left')  \n",
    "   \n",
    "# summarize history for loss  \n",
    "   \n",
    "plt.subplot(212)  \n",
    "plt.plot(historyPolicyValLoss)  \n",
    "plt.plot([x * 10 for x in historyValueValLoss])  \n",
    "plt.plot(historyValLoss)   \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "# plt.legend(['policy_loss', 'val_policy_loss', 'value_loss','val_value_loss','loss','val_loss',], loc='upper left')  \n",
    "plt.legend(['val_policy_loss','val_value_loss','val_loss'], loc='upper left')  \n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and proceed to next iteration\n",
    "\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# find highest iteration model \n",
    "\n",
    "filepath = '.'\n",
    "\n",
    "onlyFiles = [f for f in listdir(filepath) if isfile(join(filepath, f)) and 'iter' in f]\n",
    "highestIteration = max([int(re.findall(r'\\d+', filename)[0]) for filename in onlyFiles], key=lambda iterNum: int(iterNum))\n",
    "\n",
    "# newModelFileName = 'gz_dev.iter{0}.model'.format(highestIteration + 1)\n",
    "newModelFileName = 'gz_dev.classic1.model'.format(highestIteration + 1)\n",
    "print(newModelFileName)\n",
    "\n",
    "model.save(\"gz_dev.model\")\n",
    "model.save(newModelFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainingGame import loadTrainingGame\n",
    "from trainingHelper import TrainingHelper\n",
    "from mapHelper import mapHelper\n",
    "\n",
    "game = loadTrainingGame(\"testGame.pickle\")\n",
    "exampleState = game.states[0]\n",
    "mapHelper.setItems(exampleState)\n",
    "helper = TrainingHelper(game) \n",
    "\n",
    "trainX = helper.getTrainX()\n",
    "trainY = helper.getTrainY()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX[299])\n",
    "print(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(trainY)\n",
    "a = model.predict(np.array([trainX[0]]))\n",
    "a[1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"gz_dev.classic1.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
