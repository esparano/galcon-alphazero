{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "    # device_count = {'GPU': 1}\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"gz_dev.model\")\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from trainingHelper import TrainingHelper\n",
    "from trainingGame import loadTrainingGame\n",
    "import nnHelper\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "filepath = \"D:/GalconZero/Games\"\n",
    "\n",
    "TRAINING_CACHE_SUFFIX = \".npz\"\n",
    "TRAINING_GAME_SUFFIX = \".pickle\"\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "def createTrainCacheFile(trainingFile):\n",
    "    trainingGame = loadTrainingGame(trainingFile)\n",
    "    helper = TrainingHelper(trainingGame)    \n",
    "    \n",
    "    trainX = helper.getTrainX()\n",
    "    trainPolicy, trainValue = helper.getTrainY()\n",
    "    \n",
    "    trainingCacheFile = trainingFile.replace(TRAINING_GAME_SUFFIX, TRAINING_CACHE_SUFFIX)\n",
    "    \n",
    "    np.savez(trainingCacheFile, trainX=trainX, trainPolicy=trainPolicy, trainValue=trainValue)\n",
    "\n",
    "def fetchTrainXY(trainingFile):\n",
    "    trainingCacheFile = trainingFile.replace(TRAINING_GAME_SUFFIX, TRAINING_CACHE_SUFFIX)\n",
    "    if not isfile(trainingCacheFile):\n",
    "        createTrainCacheFile(trainingFile)\n",
    "        \n",
    "    npzFile = np.load(trainingCacheFile)\n",
    "#     print('loaded ' + trainingCacheFile)\n",
    "    return npzFile['trainX'], npzFile['trainPolicy'], npzFile['trainValue']\n",
    "            \n",
    "# def getTrainingDataForNumGames(num=-1):\n",
    "#     onlyFiles = [f for f in listdir(filepath) if isfile(join(filepath, f)) and TRAINING_GAME_SUFFIX in f]\n",
    " \n",
    "#     trainX = np.empty((0, 22, 14))\n",
    "#     trainY = [np.empty((0, 925)), np.empty((0,))]\n",
    "\n",
    "#     filenames = onlyFiles if num==-1 else random.sample(onlyFiles, num)\n",
    "#     for filename in filenames:\n",
    "#     #     print(\"loading training file {}\".format(filename))\n",
    "#         nextTrainX, policy, value = fetchTrainXY(filepath + \"/\" + filename)\n",
    "        \n",
    "#         #twice, once for regular, once for flipped Y values\n",
    "#         trainX = np.concatenate((trainX, nextTrainX))\n",
    "#         trainX = np.concatenate((trainX, getXAxisReflectedTrainingData(nextTrainX)))\n",
    "\n",
    "#         #twice, once for regular, once for flipped Y values (reflecting over x axis does not change policy or value)\n",
    "#         trainY = [np.concatenate((trainY[0], policy)), np.concatenate((trainY[1], value))]\n",
    "#         trainY = [np.concatenate((trainY[0], policy)), np.concatenate((trainY[1], value))]\n",
    "\n",
    "#     print(\"Finished loading {} training files\".format(num))\n",
    "#     return trainX, trainY\n",
    "\n",
    "def getTrainingDataForNumGames(num=-1):\n",
    "    onlyFiles = [f for f in listdir(filepath) if isfile(join(filepath, f)) and TRAINING_GAME_SUFFIX in f]\n",
    " \n",
    "    NUM_VALIDATION_FILES = 10\n",
    "    \n",
    "    valTrainX = []\n",
    "    valYPolicy = []\n",
    "    valYValue = []\n",
    "    trainX = []\n",
    "    trainPolicy = []\n",
    "    trainValue = []\n",
    "    \n",
    "    # reserve 20 games worth of files for validation only\n",
    "    validationFilenames = onlyFiles[len(onlyFiles) - NUM_VALIDATION_FILES:]\n",
    "    for filename in validationFilenames:\n",
    "    #     print(\"loading training file {}\".format(filename))\n",
    "        nextTrainX, policy, value = fetchTrainXY(filepath + \"/\" + filename)\n",
    "        \n",
    "        #twice, once for regular, once for flipped Y values\n",
    "        valTrainX.extend(nextTrainX)\n",
    "        valTrainX.extend(getXAxisReflectedTrainingData(nextTrainX))\n",
    "\n",
    "        #twice, once for regular, once for flipped Y values (reflecting over x axis does not change policy or value)\n",
    "        valYPolicy.extend(policy)\n",
    "        valYPolicy.extend(policy)\n",
    "        valYValue.extend(value)\n",
    "        valYValue.extend(value)\n",
    "    \n",
    "    \n",
    "    trainFilenames = onlyFiles[:len(onlyFiles) - NUM_VALIDATION_FILES]\n",
    "    filenames = trainFilenames if num==-1 else random.sample(trainFilenames, num)\n",
    "    for filename in filenames:\n",
    "    #     print(\"loading training file {}\".format(filename))\n",
    "        nextTrainX, policy, value = fetchTrainXY(filepath + \"/\" + filename)\n",
    "        \n",
    "        #twice, once for regular, once for flipped Y values\n",
    "        trainX.extend(nextTrainX)\n",
    "        trainX.extend(getXAxisReflectedTrainingData(nextTrainX))\n",
    "\n",
    "        #twice, once for regular, once for flipped Y values (reflecting over x axis does not change policy or value)\n",
    "        trainPolicy.extend(policy)\n",
    "        trainPolicy.extend(policy)\n",
    "        trainValue.extend(value)\n",
    "        trainValue.extend(value)\n",
    "\n",
    "    valTrainX = np.array(valTrainX[::10])\n",
    "    valYPolicy = np.array(valYPolicy[::10])\n",
    "    valYValue = np.array(valYValue[::10])\n",
    "    trainX = np.array(trainX)\n",
    "    trainPolicy = np.array(trainPolicy)\n",
    "    trainValue = np.array(trainValue)\n",
    "    \n",
    "    print(\"Finished loading {} training files and {} validation files\".format(len(filenames), len(validationFilenames)))\n",
    "    return trainX, [trainPolicy, trainValue], valTrainX, [valYPolicy, valYValue]\n",
    "\n",
    "def trainingLoop(numGamesPerLoop):\n",
    "    trainX, [trainYPolicy, trainYValue], valTrainX, [valYPolicy, valYValue] = getTrainingDataForNumGames(numGamesPerLoop)\n",
    "    \n",
    "    indices = np.arange(len(trainX))\n",
    "    randomSubsetIndices = np.random.choice(indices, size=int(len(trainX)/10), replace=False)\n",
    "    \n",
    "    trainX = np.take(trainX, randomSubsetIndices, axis=0)\n",
    "    trainYPolicy = np.take(trainYPolicy, randomSubsetIndices, axis=0)  \n",
    "    trainYValue = np.take(trainYValue, randomSubsetIndices, axis=0)\n",
    "    \n",
    "    return model.fit(trainX, [trainYPolicy, trainYValue], validation_data=(valTrainX, [valYPolicy, valYValue]), epochs=1, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "def getXAxisReflectedTrainingData(data):\n",
    "    data = data.copy()\n",
    "    for sample in data:\n",
    "        for row in sample:\n",
    "            row[7] *= -1\n",
    "            row[10] *= -1\n",
    "            row[13] *= -1\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyPolicyValAcc = []\n",
    "historyValueValAcc = []\n",
    "\n",
    "historyPolicyValLoss = []\n",
    "historyValueValLoss = []\n",
    "historyValLoss = []\n",
    "\n",
    "def doTrain(num_loops, numGamesPerLoop):\n",
    "    for i in range(num_loops):\n",
    "        history = trainingLoop(numGamesPerLoop)\n",
    "\n",
    "        historyPolicyValAcc.extend(history.history['val_policy_acc'])\n",
    "        historyValueValAcc.extend(history.history['val_value_acc'])\n",
    "        \n",
    "        historyPolicyValLoss.extend(history.history['val_policy_loss'])\n",
    "        historyValueValLoss.extend(history.history['val_value_loss'])\n",
    "        historyValLoss.extend(history.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11656 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11656/11656 [==============================] - 0s 25us/step - loss: 5.5973 - policy_loss: 4.5166 - value_loss: 0.5403 - policy_acc: 0.7146 - value_acc: 0.7114 - val_loss: 5.2758 - val_policy_loss: 4.1605 - val_value_loss: 0.5576 - val_policy_acc: 0.8003 - val_value_acc: 0.7797\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11849 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11849/11849 [==============================] - 0s 24us/step - loss: 5.6187 - policy_loss: 4.5906 - value_loss: 0.5141 - policy_acc: 0.7024 - value_acc: 0.7181 - val_loss: 5.2812 - val_policy_loss: 4.1669 - val_value_loss: 0.5572 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11912 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11912/11912 [==============================] - 0s 24us/step - loss: 5.6423 - policy_loss: 4.5973 - value_loss: 0.5225 - policy_acc: 0.6945 - value_acc: 0.7101 - val_loss: 5.2721 - val_policy_loss: 4.1635 - val_value_loss: 0.5543 - val_policy_acc: 0.8003 - val_value_acc: 0.7040\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11871 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11871/11871 [==============================] - 0s 24us/step - loss: 5.4359 - policy_loss: 4.4179 - value_loss: 0.5090 - policy_acc: 0.7539 - value_acc: 0.7311 - val_loss: 5.2518 - val_policy_loss: 4.1588 - val_value_loss: 0.5465 - val_policy_acc: 0.8003 - val_value_acc: 0.7642\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11816 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11816/11816 [==============================] - 0s 26us/step - loss: 5.4756 - policy_loss: 4.4965 - value_loss: 0.4896 - policy_acc: 0.7255 - value_acc: 0.7449 - val_loss: 5.2330 - val_policy_loss: 4.1594 - val_value_loss: 0.5368 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11722 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11722/11722 [==============================] - 0s 24us/step - loss: 5.4487 - policy_loss: 4.4155 - value_loss: 0.5166 - policy_acc: 0.7332 - value_acc: 0.7244 - val_loss: 5.2238 - val_policy_loss: 4.1599 - val_value_loss: 0.5320 - val_policy_acc: 0.8003 - val_value_acc: 0.7728\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11906 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11906/11906 [==============================] - 0s 24us/step - loss: 5.4892 - policy_loss: 4.4838 - value_loss: 0.5027 - policy_acc: 0.7226 - value_acc: 0.7229 - val_loss: 5.2229 - val_policy_loss: 4.1615 - val_value_loss: 0.5307 - val_policy_acc: 0.8003 - val_value_acc: 0.7728\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11885 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11885/11885 [==============================] - 0s 24us/step - loss: 5.6327 - policy_loss: 4.5962 - value_loss: 0.5183 - policy_acc: 0.6774 - value_acc: 0.7177 - val_loss: 5.2313 - val_policy_loss: 4.1651 - val_value_loss: 0.5331 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11920 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11920/11920 [==============================] - 0s 24us/step - loss: 5.5834 - policy_loss: 4.5438 - value_loss: 0.5198 - policy_acc: 0.7221 - value_acc: 0.7239 - val_loss: 5.2269 - val_policy_loss: 4.1592 - val_value_loss: 0.5338 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11792 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11792/11792 [==============================] - 0s 24us/step - loss: 5.5005 - policy_loss: 4.5021 - value_loss: 0.4992 - policy_acc: 0.7281 - value_acc: 0.7414 - val_loss: 5.2245 - val_policy_loss: 4.1576 - val_value_loss: 0.5335 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11749 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11749/11749 [==============================] - 0s 24us/step - loss: 5.5174 - policy_loss: 4.5021 - value_loss: 0.5077 - policy_acc: 0.7298 - value_acc: 0.7316 - val_loss: 5.2293 - val_policy_loss: 4.1610 - val_value_loss: 0.5342 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11722 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11722/11722 [==============================] - 0s 24us/step - loss: 5.6240 - policy_loss: 4.5483 - value_loss: 0.5379 - policy_acc: 0.7065 - value_acc: 0.6978 - val_loss: 5.2433 - val_policy_loss: 4.1661 - val_value_loss: 0.5386 - val_policy_acc: 0.8003 - val_value_acc: 0.7883\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11709 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11709/11709 [==============================] - 0s 24us/step - loss: 5.4884 - policy_loss: 4.4604 - value_loss: 0.5140 - policy_acc: 0.7325 - value_acc: 0.7303 - val_loss: 5.2560 - val_policy_loss: 4.1668 - val_value_loss: 0.5446 - val_policy_acc: 0.8003 - val_value_acc: 0.7728\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11875 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11875/11875 [==============================] - 0s 24us/step - loss: 5.5305 - policy_loss: 4.4528 - value_loss: 0.5389 - policy_acc: 0.7263 - value_acc: 0.7061 - val_loss: 5.2533 - val_policy_loss: 4.1645 - val_value_loss: 0.5444 - val_policy_acc: 0.8003 - val_value_acc: 0.7814\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11741 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11741/11741 [==============================] - 0s 23us/step - loss: 5.5985 - policy_loss: 4.5510 - value_loss: 0.5237 - policy_acc: 0.7304 - value_acc: 0.7102 - val_loss: 5.2483 - val_policy_loss: 4.1609 - val_value_loss: 0.5437 - val_policy_acc: 0.8003 - val_value_acc: 0.7849\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11679 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11679/11679 [==============================] - 0s 24us/step - loss: 5.4037 - policy_loss: 4.4279 - value_loss: 0.4879 - policy_acc: 0.7216 - value_acc: 0.7353 - val_loss: 5.2435 - val_policy_loss: 4.1582 - val_value_loss: 0.5427 - val_policy_acc: 0.8003 - val_value_acc: 0.7883\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11847 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11847/11847 [==============================] - 0s 25us/step - loss: 5.5890 - policy_loss: 4.5962 - value_loss: 0.4964 - policy_acc: 0.6825 - value_acc: 0.7424 - val_loss: 5.2360 - val_policy_loss: 4.1600 - val_value_loss: 0.5380 - val_policy_acc: 0.8003 - val_value_acc: 0.7797\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11803 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11803/11803 [==============================] - 0s 24us/step - loss: 5.3622 - policy_loss: 4.3354 - value_loss: 0.5134 - policy_acc: 0.7555 - value_acc: 0.7244 - val_loss: 5.2321 - val_policy_loss: 4.1642 - val_value_loss: 0.5339 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11689 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11689/11689 [==============================] - 0s 24us/step - loss: 5.5232 - policy_loss: 4.5255 - value_loss: 0.4988 - policy_acc: 0.7333 - value_acc: 0.7360 - val_loss: 5.2288 - val_policy_loss: 4.1657 - val_value_loss: 0.5315 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11781 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11781/11781 [==============================] - 0s 26us/step - loss: 5.5660 - policy_loss: 4.5602 - value_loss: 0.5029 - policy_acc: 0.7250 - value_acc: 0.7402 - val_loss: 5.2220 - val_policy_loss: 4.1642 - val_value_loss: 0.5289 - val_policy_acc: 0.8003 - val_value_acc: 0.8021\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11810 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11810/11810 [==============================] - 0s 25us/step - loss: 5.5894 - policy_loss: 4.5771 - value_loss: 0.5061 - policy_acc: 0.7015 - value_acc: 0.7319 - val_loss: 5.2297 - val_policy_loss: 4.1628 - val_value_loss: 0.5335 - val_policy_acc: 0.8003 - val_value_acc: 0.7728\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11699 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11699/11699 [==============================] - 0s 24us/step - loss: 5.6358 - policy_loss: 4.5956 - value_loss: 0.5201 - policy_acc: 0.7006 - value_acc: 0.7180 - val_loss: 5.2409 - val_policy_loss: 4.1625 - val_value_loss: 0.5392 - val_policy_acc: 0.8003 - val_value_acc: 0.7986\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11915 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11915/11915 [==============================] - 0s 25us/step - loss: 5.5115 - policy_loss: 4.4994 - value_loss: 0.5060 - policy_acc: 0.7128 - value_acc: 0.7162 - val_loss: 5.2510 - val_policy_loss: 4.1619 - val_value_loss: 0.5446 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11628 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11628/11628 [==============================] - 0s 24us/step - loss: 5.5133 - policy_loss: 4.4754 - value_loss: 0.5189 - policy_acc: 0.7222 - value_acc: 0.7204 - val_loss: 5.2547 - val_policy_loss: 4.1603 - val_value_loss: 0.5472 - val_policy_acc: 0.8003 - val_value_acc: 0.7797\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11944 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11944/11944 [==============================] - 0s 24us/step - loss: 5.4778 - policy_loss: 4.4037 - value_loss: 0.5370 - policy_acc: 0.7222 - value_acc: 0.7021 - val_loss: 5.2666 - val_policy_loss: 4.1603 - val_value_loss: 0.5531 - val_policy_acc: 0.8003 - val_value_acc: 0.7935\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11747 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11747/11747 [==============================] - 0s 24us/step - loss: 5.4744 - policy_loss: 4.3900 - value_loss: 0.5422 - policy_acc: 0.7503 - value_acc: 0.6889 - val_loss: 5.2843 - val_policy_loss: 4.1630 - val_value_loss: 0.5607 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11847 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11847/11847 [==============================] - 0s 23us/step - loss: 5.5091 - policy_loss: 4.5143 - value_loss: 0.4974 - policy_acc: 0.7309 - value_acc: 0.7256 - val_loss: 5.2832 - val_policy_loss: 4.1632 - val_value_loss: 0.5600 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11626 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11626/11626 [==============================] - 0s 24us/step - loss: 5.5644 - policy_loss: 4.5115 - value_loss: 0.5264 - policy_acc: 0.7149 - value_acc: 0.6991 - val_loss: 5.2758 - val_policy_loss: 4.1593 - val_value_loss: 0.5582 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11876 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11876/11876 [==============================] - 0s 23us/step - loss: 5.5607 - policy_loss: 4.4889 - value_loss: 0.5359 - policy_acc: 0.7222 - value_acc: 0.6958 - val_loss: 5.2713 - val_policy_loss: 4.1589 - val_value_loss: 0.5562 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11810 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11810/11810 [==============================] - 0s 23us/step - loss: 5.5090 - policy_loss: 4.5440 - value_loss: 0.4825 - policy_acc: 0.7277 - value_acc: 0.7408 - val_loss: 5.2678 - val_policy_loss: 4.1631 - val_value_loss: 0.5524 - val_policy_acc: 0.8003 - val_value_acc: 0.7831\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11816 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11816/11816 [==============================] - 0s 23us/step - loss: 5.6219 - policy_loss: 4.5505 - value_loss: 0.5357 - policy_acc: 0.6985 - value_acc: 0.7029 - val_loss: 5.2684 - val_policy_loss: 4.1662 - val_value_loss: 0.5511 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11845 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11845/11845 [==============================] - 0s 24us/step - loss: 5.6556 - policy_loss: 4.5677 - value_loss: 0.5440 - policy_acc: 0.6962 - value_acc: 0.6922 - val_loss: 5.2810 - val_policy_loss: 4.1668 - val_value_loss: 0.5571 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11895 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11895/11895 [==============================] - 0s 23us/step - loss: 5.4606 - policy_loss: 4.4396 - value_loss: 0.5105 - policy_acc: 0.7345 - value_acc: 0.7253 - val_loss: 5.2791 - val_policy_loss: 4.1616 - val_value_loss: 0.5587 - val_policy_acc: 0.8003 - val_value_acc: 0.7728\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11903 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11903/11903 [==============================] - 0s 23us/step - loss: 5.5185 - policy_loss: 4.5039 - value_loss: 0.5073 - policy_acc: 0.7378 - value_acc: 0.7292 - val_loss: 5.2689 - val_policy_loss: 4.1603 - val_value_loss: 0.5543 - val_policy_acc: 0.8003 - val_value_acc: 0.7831\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11718 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11718/11718 [==============================] - 0s 25us/step - loss: 5.4911 - policy_loss: 4.4899 - value_loss: 0.5006 - policy_acc: 0.7052 - value_acc: 0.7249 - val_loss: 5.2623 - val_policy_loss: 4.1634 - val_value_loss: 0.5495 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11825 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11825/11825 [==============================] - 0s 24us/step - loss: 5.6279 - policy_loss: 4.5166 - value_loss: 0.5556 - policy_acc: 0.7172 - value_acc: 0.6848 - val_loss: 5.2597 - val_policy_loss: 4.1639 - val_value_loss: 0.5479 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11642 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11642/11642 [==============================] - 0s 24us/step - loss: 5.5387 - policy_loss: 4.5193 - value_loss: 0.5097 - policy_acc: 0.7065 - value_acc: 0.7228 - val_loss: 5.2591 - val_policy_loss: 4.1622 - val_value_loss: 0.5485 - val_policy_acc: 0.8003 - val_value_acc: 0.7849\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11830 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11830/11830 [==============================] - 0s 24us/step - loss: 5.5472 - policy_loss: 4.5194 - value_loss: 0.5139 - policy_acc: 0.7093 - value_acc: 0.7282 - val_loss: 5.2552 - val_policy_loss: 4.1610 - val_value_loss: 0.5471 - val_policy_acc: 0.8003 - val_value_acc: 0.7745\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11839 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11839/11839 [==============================] - 0s 23us/step - loss: 5.4944 - policy_loss: 4.4780 - value_loss: 0.5082 - policy_acc: 0.7449 - value_acc: 0.7229 - val_loss: 5.2544 - val_policy_loss: 4.1637 - val_value_loss: 0.5454 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11904 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11904/11904 [==============================] - 0s 24us/step - loss: 5.5555 - policy_loss: 4.5148 - value_loss: 0.5204 - policy_acc: 0.7187 - value_acc: 0.7089 - val_loss: 5.2537 - val_policy_loss: 4.1651 - val_value_loss: 0.5443 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11751 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11751/11751 [==============================] - 0s 25us/step - loss: 5.5884 - policy_loss: 4.5104 - value_loss: 0.5390 - policy_acc: 0.6952 - value_acc: 0.7058 - val_loss: 5.2618 - val_policy_loss: 4.1627 - val_value_loss: 0.5495 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11829 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11829/11829 [==============================] - 0s 24us/step - loss: 5.5103 - policy_loss: 4.4824 - value_loss: 0.5140 - policy_acc: 0.7269 - value_acc: 0.7303 - val_loss: 5.2608 - val_policy_loss: 4.1604 - val_value_loss: 0.5502 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11694 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11694/11694 [==============================] - 0s 24us/step - loss: 5.5343 - policy_loss: 4.4806 - value_loss: 0.5268 - policy_acc: 0.7219 - value_acc: 0.7117 - val_loss: 5.2572 - val_policy_loss: 4.1598 - val_value_loss: 0.5487 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11849 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11849/11849 [==============================] - 0s 24us/step - loss: 5.4593 - policy_loss: 4.4673 - value_loss: 0.4960 - policy_acc: 0.7296 - value_acc: 0.7448 - val_loss: 5.2487 - val_policy_loss: 4.1630 - val_value_loss: 0.5429 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11799 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11799/11799 [==============================] - 0s 24us/step - loss: 5.5330 - policy_loss: 4.4971 - value_loss: 0.5180 - policy_acc: 0.7458 - value_acc: 0.7183 - val_loss: 5.2397 - val_policy_loss: 4.1655 - val_value_loss: 0.5371 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11919 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11919/11919 [==============================] - 0s 25us/step - loss: 5.4430 - policy_loss: 4.4637 - value_loss: 0.4896 - policy_acc: 0.7376 - value_acc: 0.7484 - val_loss: 5.2349 - val_policy_loss: 4.1634 - val_value_loss: 0.5358 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11864 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11864/11864 [==============================] - 0s 24us/step - loss: 5.5803 - policy_loss: 4.5895 - value_loss: 0.4954 - policy_acc: 0.7149 - value_acc: 0.7342 - val_loss: 5.2307 - val_policy_loss: 4.1607 - val_value_loss: 0.5350 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11640 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11640/11640 [==============================] - 0s 24us/step - loss: 5.4283 - policy_loss: 4.3869 - value_loss: 0.5207 - policy_acc: 0.7301 - value_acc: 0.7271 - val_loss: 5.2355 - val_policy_loss: 4.1601 - val_value_loss: 0.5377 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11779 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11779/11779 [==============================] - 0s 24us/step - loss: 5.4928 - policy_loss: 4.5079 - value_loss: 0.4924 - policy_acc: 0.7278 - value_acc: 0.7496 - val_loss: 5.2378 - val_policy_loss: 4.1625 - val_value_loss: 0.5376 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11845 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11845/11845 [==============================] - 0s 24us/step - loss: 5.6496 - policy_loss: 4.6016 - value_loss: 0.5240 - policy_acc: 0.6939 - value_acc: 0.7098 - val_loss: 5.2454 - val_policy_loss: 4.1647 - val_value_loss: 0.5403 - val_policy_acc: 0.7831 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11806 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11806/11806 [==============================] - 0s 24us/step - loss: 5.5485 - policy_loss: 4.4949 - value_loss: 0.5268 - policy_acc: 0.7173 - value_acc: 0.7124 - val_loss: 5.2547 - val_policy_loss: 4.1615 - val_value_loss: 0.5466 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11902 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11902/11902 [==============================] - 0s 24us/step - loss: 5.4797 - policy_loss: 4.4890 - value_loss: 0.4954 - policy_acc: 0.7208 - value_acc: 0.7435 - val_loss: 5.2554 - val_policy_loss: 4.1608 - val_value_loss: 0.5473 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11922 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11922/11922 [==============================] - 0s 23us/step - loss: 5.5452 - policy_loss: 4.5074 - value_loss: 0.5189 - policy_acc: 0.7370 - value_acc: 0.7193 - val_loss: 5.2549 - val_policy_loss: 4.1633 - val_value_loss: 0.5458 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11742 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11742/11742 [==============================] - 0s 24us/step - loss: 5.5059 - policy_loss: 4.5214 - value_loss: 0.4923 - policy_acc: 0.6955 - value_acc: 0.7523 - val_loss: 5.2484 - val_policy_loss: 4.1599 - val_value_loss: 0.5442 - val_policy_acc: 0.8003 - val_value_acc: 0.6867\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11851 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11851/11851 [==============================] - 0s 24us/step - loss: 5.6930 - policy_loss: 4.5461 - value_loss: 0.5735 - policy_acc: 0.7329 - value_acc: 0.6675 - val_loss: 5.2519 - val_policy_loss: 4.1579 - val_value_loss: 0.5470 - val_policy_acc: 0.8003 - val_value_acc: 0.7177\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11793 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11793/11793 [==============================] - 0s 23us/step - loss: 5.5275 - policy_loss: 4.4757 - value_loss: 0.5259 - policy_acc: 0.7316 - value_acc: 0.7096 - val_loss: 5.2661 - val_policy_loss: 4.1587 - val_value_loss: 0.5537 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11768 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11768/11768 [==============================] - 0s 24us/step - loss: 5.4976 - policy_loss: 4.4464 - value_loss: 0.5256 - policy_acc: 0.7362 - value_acc: 0.7205 - val_loss: 5.2666 - val_policy_loss: 4.1601 - val_value_loss: 0.5533 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11786 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11786/11786 [==============================] - 0s 24us/step - loss: 5.5563 - policy_loss: 4.5126 - value_loss: 0.5219 - policy_acc: 0.7333 - value_acc: 0.7109 - val_loss: 5.2649 - val_policy_loss: 4.1629 - val_value_loss: 0.5510 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11657 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11657/11657 [==============================] - 0s 25us/step - loss: 5.6336 - policy_loss: 4.5847 - value_loss: 0.5244 - policy_acc: 0.6908 - value_acc: 0.7098 - val_loss: 5.2600 - val_policy_loss: 4.1611 - val_value_loss: 0.5494 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11638 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11638/11638 [==============================] - 0s 24us/step - loss: 5.4675 - policy_loss: 4.4709 - value_loss: 0.4983 - policy_acc: 0.7343 - value_acc: 0.7342 - val_loss: 5.2528 - val_policy_loss: 4.1595 - val_value_loss: 0.5467 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11816 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11816/11816 [==============================] - 0s 24us/step - loss: 5.5077 - policy_loss: 4.4963 - value_loss: 0.5057 - policy_acc: 0.7330 - value_acc: 0.7145 - val_loss: 5.2452 - val_policy_loss: 4.1597 - val_value_loss: 0.5427 - val_policy_acc: 0.7935 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11781 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11781/11781 [==============================] - 0s 25us/step - loss: 5.5858 - policy_loss: 4.5700 - value_loss: 0.5079 - policy_acc: 0.7116 - value_acc: 0.7284 - val_loss: 5.2435 - val_policy_loss: 4.1615 - val_value_loss: 0.5410 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11881 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11881/11881 [==============================] - 0s 24us/step - loss: 5.4078 - policy_loss: 4.4817 - value_loss: 0.4631 - policy_acc: 0.7398 - value_acc: 0.7697 - val_loss: 5.2313 - val_policy_loss: 4.1617 - val_value_loss: 0.5348 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11863 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11863/11863 [==============================] - 0s 24us/step - loss: 5.6346 - policy_loss: 4.5312 - value_loss: 0.5517 - policy_acc: 0.7180 - value_acc: 0.6963 - val_loss: 5.2384 - val_policy_loss: 4.1613 - val_value_loss: 0.5386 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11728 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11728/11728 [==============================] - 0s 25us/step - loss: 5.5690 - policy_loss: 4.5083 - value_loss: 0.5304 - policy_acc: 0.7228 - value_acc: 0.7179 - val_loss: 5.2560 - val_policy_loss: 4.1630 - val_value_loss: 0.5465 - val_policy_acc: 0.7969 - val_value_acc: 0.6781\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11857 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11857/11857 [==============================] - 0s 24us/step - loss: 5.5631 - policy_loss: 4.5546 - value_loss: 0.5043 - policy_acc: 0.7084 - value_acc: 0.7308 - val_loss: 5.2592 - val_policy_loss: 4.1610 - val_value_loss: 0.5491 - val_policy_acc: 0.8003 - val_value_acc: 0.6713\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11887 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11887/11887 [==============================] - 0s 24us/step - loss: 5.5720 - policy_loss: 4.5274 - value_loss: 0.5223 - policy_acc: 0.7279 - value_acc: 0.6971 - val_loss: 5.2541 - val_policy_loss: 4.1580 - val_value_loss: 0.5480 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11915 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11915/11915 [==============================] - 0s 24us/step - loss: 5.6268 - policy_loss: 4.5818 - value_loss: 0.5225 - policy_acc: 0.7405 - value_acc: 0.7073 - val_loss: 5.2582 - val_policy_loss: 4.1597 - val_value_loss: 0.5493 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11788 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11788/11788 [==============================] - 0s 37us/step - loss: 5.5369 - policy_loss: 4.4796 - value_loss: 0.5287 - policy_acc: 0.7364 - value_acc: 0.7000 - val_loss: 5.2617 - val_policy_loss: 4.1624 - val_value_loss: 0.5497 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11742 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11742/11742 [==============================] - 0s 25us/step - loss: 5.4831 - policy_loss: 4.5417 - value_loss: 0.4707 - policy_acc: 0.7088 - value_acc: 0.7621 - val_loss: 5.2601 - val_policy_loss: 4.1638 - val_value_loss: 0.5481 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11788 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11788/11788 [==============================] - 0s 25us/step - loss: 5.5284 - policy_loss: 4.4901 - value_loss: 0.5191 - policy_acc: 0.7160 - value_acc: 0.7306 - val_loss: 5.2531 - val_policy_loss: 4.1633 - val_value_loss: 0.5449 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11767 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11767/11767 [==============================] - 0s 26us/step - loss: 5.4276 - policy_loss: 4.3315 - value_loss: 0.5481 - policy_acc: 0.7674 - value_acc: 0.7077 - val_loss: 5.2371 - val_policy_loss: 4.1590 - val_value_loss: 0.5390 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11698 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11698/11698 [==============================] - 0s 28us/step - loss: 5.6296 - policy_loss: 4.5653 - value_loss: 0.5321 - policy_acc: 0.6937 - value_acc: 0.7154 - val_loss: 5.2339 - val_policy_loss: 4.1588 - val_value_loss: 0.5375 - val_policy_acc: 0.8003 - val_value_acc: 0.7814\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11725 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11725/11725 [==============================] - 0s 27us/step - loss: 5.5183 - policy_loss: 4.5371 - value_loss: 0.4906 - policy_acc: 0.7089 - value_acc: 0.7330 - val_loss: 5.2278 - val_policy_loss: 4.1594 - val_value_loss: 0.5342 - val_policy_acc: 0.8003 - val_value_acc: 0.7849\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11894 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11894/11894 [==============================] - 0s 31us/step - loss: 5.5428 - policy_loss: 4.5292 - value_loss: 0.5068 - policy_acc: 0.7245 - value_acc: 0.7386 - val_loss: 5.2231 - val_policy_loss: 4.1606 - val_value_loss: 0.5313 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11704 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11704/11704 [==============================] - 0s 29us/step - loss: 5.5616 - policy_loss: 4.4805 - value_loss: 0.5405 - policy_acc: 0.7373 - value_acc: 0.7065 - val_loss: 5.2147 - val_policy_loss: 4.1612 - val_value_loss: 0.5268 - val_policy_acc: 0.8003 - val_value_acc: 0.7935\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11990 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11990/11990 [==============================] - 0s 29us/step - loss: 5.5638 - policy_loss: 4.5441 - value_loss: 0.5098 - policy_acc: 0.7102 - value_acc: 0.7187 - val_loss: 5.2210 - val_policy_loss: 4.1617 - val_value_loss: 0.5296 - val_policy_acc: 0.8003 - val_value_acc: 0.7917\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11842 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11842/11842 [==============================] - 0s 28us/step - loss: 5.4437 - policy_loss: 4.4423 - value_loss: 0.5007 - policy_acc: 0.7417 - value_acc: 0.7349 - val_loss: 5.2284 - val_policy_loss: 4.1608 - val_value_loss: 0.5338 - val_policy_acc: 0.8003 - val_value_acc: 0.7917\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11627 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11627/11627 [==============================] - 0s 27us/step - loss: 5.4257 - policy_loss: 4.4298 - value_loss: 0.4980 - policy_acc: 0.7140 - value_acc: 0.7432 - val_loss: 5.2271 - val_policy_loss: 4.1562 - val_value_loss: 0.5354 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11893 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11893/11893 [==============================] - 0s 27us/step - loss: 5.6466 - policy_loss: 4.5721 - value_loss: 0.5372 - policy_acc: 0.7089 - value_acc: 0.6944 - val_loss: 5.2351 - val_policy_loss: 4.1555 - val_value_loss: 0.5398 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11982 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11982/11982 [==============================] - 0s 30us/step - loss: 5.5212 - policy_loss: 4.5009 - value_loss: 0.5101 - policy_acc: 0.7314 - value_acc: 0.7266 - val_loss: 5.2462 - val_policy_loss: 4.1611 - val_value_loss: 0.5426 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11594 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11594/11594 [==============================] - 0s 24us/step - loss: 5.5327 - policy_loss: 4.5336 - value_loss: 0.4996 - policy_acc: 0.7066 - value_acc: 0.7288 - val_loss: 5.2495 - val_policy_loss: 4.1633 - val_value_loss: 0.5431 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11664 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11664/11664 [==============================] - 0s 25us/step - loss: 5.5192 - policy_loss: 4.4836 - value_loss: 0.5178 - policy_acc: 0.7365 - value_acc: 0.7084 - val_loss: 5.2502 - val_policy_loss: 4.1640 - val_value_loss: 0.5431 - val_policy_acc: 0.8003 - val_value_acc: 0.7780\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11892 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11892/11892 [==============================] - 0s 24us/step - loss: 5.3849 - policy_loss: 4.4247 - value_loss: 0.4801 - policy_acc: 0.7503 - value_acc: 0.7439 - val_loss: 5.2494 - val_policy_loss: 4.1632 - val_value_loss: 0.5431 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11719 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11719/11719 [==============================] - 0s 24us/step - loss: 5.5208 - policy_loss: 4.5006 - value_loss: 0.5101 - policy_acc: 0.7239 - value_acc: 0.7153 - val_loss: 5.2530 - val_policy_loss: 4.1630 - val_value_loss: 0.5450 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11832 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11832/11832 [==============================] - 0s 26us/step - loss: 5.6024 - policy_loss: 4.5129 - value_loss: 0.5447 - policy_acc: 0.7138 - value_acc: 0.6957 - val_loss: 5.2594 - val_policy_loss: 4.1638 - val_value_loss: 0.5478 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11762 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11762/11762 [==============================] - 0s 25us/step - loss: 5.5008 - policy_loss: 4.5065 - value_loss: 0.4971 - policy_acc: 0.7264 - value_acc: 0.7462 - val_loss: 5.2498 - val_policy_loss: 4.1608 - val_value_loss: 0.5445 - val_policy_acc: 0.8003 - val_value_acc: 0.7728\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11894 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11894/11894 [==============================] - 0s 23us/step - loss: 5.4852 - policy_loss: 4.4871 - value_loss: 0.4991 - policy_acc: 0.7278 - value_acc: 0.7383 - val_loss: 5.2314 - val_policy_loss: 4.1564 - val_value_loss: 0.5375 - val_policy_acc: 0.8003 - val_value_acc: 0.7780\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11829 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11829/11829 [==============================] - 0s 24us/step - loss: 5.5844 - policy_loss: 4.6116 - value_loss: 0.4864 - policy_acc: 0.7167 - value_acc: 0.7430 - val_loss: 5.2223 - val_policy_loss: 4.1573 - val_value_loss: 0.5325 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11822 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11822/11822 [==============================] - 0s 26us/step - loss: 5.6070 - policy_loss: 4.5021 - value_loss: 0.5525 - policy_acc: 0.7082 - value_acc: 0.6887 - val_loss: 5.2262 - val_policy_loss: 4.1606 - val_value_loss: 0.5328 - val_policy_acc: 0.8003 - val_value_acc: 0.7849\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11919 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11919/11919 [==============================] - 0s 24us/step - loss: 5.5278 - policy_loss: 4.4739 - value_loss: 0.5269 - policy_acc: 0.7311 - value_acc: 0.7132 - val_loss: 5.2485 - val_policy_loss: 4.1634 - val_value_loss: 0.5425 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11796 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11796/11796 [==============================] - 0s 25us/step - loss: 5.5171 - policy_loss: 4.4631 - value_loss: 0.5270 - policy_acc: 0.7105 - value_acc: 0.7134 - val_loss: 5.2632 - val_policy_loss: 4.1636 - val_value_loss: 0.5498 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11955 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11955/11955 [==============================] - 0s 24us/step - loss: 5.5125 - policy_loss: 4.5331 - value_loss: 0.4897 - policy_acc: 0.7209 - value_acc: 0.7495 - val_loss: 5.2606 - val_policy_loss: 4.1646 - val_value_loss: 0.5480 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11671 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11671/11671 [==============================] - 0s 24us/step - loss: 5.5291 - policy_loss: 4.4722 - value_loss: 0.5284 - policy_acc: 0.7197 - value_acc: 0.7152 - val_loss: 5.2462 - val_policy_loss: 4.1622 - val_value_loss: 0.5420 - val_policy_acc: 0.8003 - val_value_acc: 0.7917\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11842 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11842/11842 [==============================] - 0s 28us/step - loss: 5.5272 - policy_loss: 4.5309 - value_loss: 0.4981 - policy_acc: 0.7196 - value_acc: 0.7236 - val_loss: 5.2351 - val_policy_loss: 4.1606 - val_value_loss: 0.5373 - val_policy_acc: 0.8003 - val_value_acc: 0.7900\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11985 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11985/11985 [==============================] - 0s 24us/step - loss: 5.4697 - policy_loss: 4.5146 - value_loss: 0.4776 - policy_acc: 0.7369 - value_acc: 0.7642 - val_loss: 5.2223 - val_policy_loss: 4.1608 - val_value_loss: 0.5308 - val_policy_acc: 0.8003 - val_value_acc: 0.7745\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 12000 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "12000/12000 [==============================] - 0s 23us/step - loss: 5.4398 - policy_loss: 4.4632 - value_loss: 0.4883 - policy_acc: 0.7226 - value_acc: 0.7432 - val_loss: 5.2096 - val_policy_loss: 4.1608 - val_value_loss: 0.5244 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11876 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11876/11876 [==============================] - 0s 24us/step - loss: 5.4020 - policy_loss: 4.4886 - value_loss: 0.4567 - policy_acc: 0.7424 - value_acc: 0.7751 - val_loss: 5.2009 - val_policy_loss: 4.1624 - val_value_loss: 0.5192 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11933 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11933/11933 [==============================] - 0s 24us/step - loss: 5.5393 - policy_loss: 4.4978 - value_loss: 0.5208 - policy_acc: 0.7258 - value_acc: 0.7249 - val_loss: 5.1969 - val_policy_loss: 4.1641 - val_value_loss: 0.5164 - val_policy_acc: 0.8003 - val_value_acc: 0.7935\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11716 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11716/11716 [==============================] - 0s 24us/step - loss: 5.6136 - policy_loss: 4.5460 - value_loss: 0.5338 - policy_acc: 0.7227 - value_acc: 0.7065 - val_loss: 5.2107 - val_policy_loss: 4.1617 - val_value_loss: 0.5245 - val_policy_acc: 0.8003 - val_value_acc: 0.7814\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11689 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11689/11689 [==============================] - 0s 24us/step - loss: 5.4539 - policy_loss: 4.4626 - value_loss: 0.4957 - policy_acc: 0.7394 - value_acc: 0.7426 - val_loss: 5.2196 - val_policy_loss: 4.1561 - val_value_loss: 0.5318 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11944 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11944/11944 [==============================] - 0s 25us/step - loss: 5.5465 - policy_loss: 4.5203 - value_loss: 0.5131 - policy_acc: 0.7174 - value_acc: 0.7241 - val_loss: 5.2247 - val_policy_loss: 4.1547 - val_value_loss: 0.5350 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11847 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11847/11847 [==============================] - 0s 25us/step - loss: 5.6595 - policy_loss: 4.6633 - value_loss: 0.4981 - policy_acc: 0.6887 - value_acc: 0.7329 - val_loss: 5.2303 - val_policy_loss: 4.1574 - val_value_loss: 0.5364 - val_policy_acc: 0.8003 - val_value_acc: 0.8003\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11800 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11800/11800 [==============================] - 0s 24us/step - loss: 5.5294 - policy_loss: 4.5248 - value_loss: 0.5023 - policy_acc: 0.7263 - value_acc: 0.7235 - val_loss: 5.2317 - val_policy_loss: 4.1605 - val_value_loss: 0.5356 - val_policy_acc: 0.8003 - val_value_acc: 0.8021\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11942 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11942/11942 [==============================] - 0s 25us/step - loss: 5.4812 - policy_loss: 4.4699 - value_loss: 0.5056 - policy_acc: 0.7476 - value_acc: 0.7251 - val_loss: 5.2303 - val_policy_loss: 4.1600 - val_value_loss: 0.5351 - val_policy_acc: 0.8003 - val_value_acc: 0.7642\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11789 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11789/11789 [==============================] - 0s 24us/step - loss: 5.4033 - policy_loss: 4.4508 - value_loss: 0.4762 - policy_acc: 0.7242 - value_acc: 0.7467 - val_loss: 5.2203 - val_policy_loss: 4.1589 - val_value_loss: 0.5307 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11821 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11821/11821 [==============================] - 0s 24us/step - loss: 5.5910 - policy_loss: 4.5312 - value_loss: 0.5299 - policy_acc: 0.6989 - value_acc: 0.7106 - val_loss: 5.2180 - val_policy_loss: 4.1612 - val_value_loss: 0.5284 - val_policy_acc: 0.8003 - val_value_acc: 0.7831\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11987 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11987/11987 [==============================] - 0s 25us/step - loss: 5.5210 - policy_loss: 4.4287 - value_loss: 0.5461 - policy_acc: 0.7294 - value_acc: 0.7027 - val_loss: 5.2322 - val_policy_loss: 4.1621 - val_value_loss: 0.5351 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11847 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11847/11847 [==============================] - 0s 24us/step - loss: 5.5360 - policy_loss: 4.5442 - value_loss: 0.4959 - policy_acc: 0.7204 - value_acc: 0.7205 - val_loss: 5.2405 - val_policy_loss: 4.1594 - val_value_loss: 0.5405 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11788 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11788/11788 [==============================] - 0s 25us/step - loss: 5.4772 - policy_loss: 4.4550 - value_loss: 0.5111 - policy_acc: 0.7396 - value_acc: 0.7139 - val_loss: 5.2446 - val_policy_loss: 4.1587 - val_value_loss: 0.5429 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11868 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11868/11868 [==============================] - 0s 24us/step - loss: 5.6173 - policy_loss: 4.5545 - value_loss: 0.5314 - policy_acc: 0.6930 - value_acc: 0.7095 - val_loss: 5.2468 - val_policy_loss: 4.1592 - val_value_loss: 0.5438 - val_policy_acc: 0.8003 - val_value_acc: 0.7797\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11954 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11954/11954 [==============================] - 0s 25us/step - loss: 5.3569 - policy_loss: 4.3671 - value_loss: 0.4949 - policy_acc: 0.7512 - value_acc: 0.7343 - val_loss: 5.2421 - val_policy_loss: 4.1589 - val_value_loss: 0.5416 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11931 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11931/11931 [==============================] - 0s 24us/step - loss: 5.5010 - policy_loss: 4.4850 - value_loss: 0.5080 - policy_acc: 0.7352 - value_acc: 0.7218 - val_loss: 5.2379 - val_policy_loss: 4.1622 - val_value_loss: 0.5378 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11890 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11890/11890 [==============================] - 0s 24us/step - loss: 5.5956 - policy_loss: 4.5590 - value_loss: 0.5183 - policy_acc: 0.6828 - value_acc: 0.7126 - val_loss: 5.2403 - val_policy_loss: 4.1625 - val_value_loss: 0.5389 - val_policy_acc: 0.8003 - val_value_acc: 0.7814\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11900 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11900/11900 [==============================] - 0s 26us/step - loss: 5.6052 - policy_loss: 4.4992 - value_loss: 0.5530 - policy_acc: 0.7182 - value_acc: 0.7035 - val_loss: 5.2468 - val_policy_loss: 4.1598 - val_value_loss: 0.5435 - val_policy_acc: 0.8003 - val_value_acc: 0.7952\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11984 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11984/11984 [==============================] - 0s 27us/step - loss: 5.4407 - policy_loss: 4.4604 - value_loss: 0.4902 - policy_acc: 0.7361 - value_acc: 0.7386 - val_loss: 5.2535 - val_policy_loss: 4.1614 - val_value_loss: 0.5461 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11915 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11915/11915 [==============================] - 0s 24us/step - loss: 5.5901 - policy_loss: 4.4669 - value_loss: 0.5616 - policy_acc: 0.7324 - value_acc: 0.6918 - val_loss: 5.2518 - val_policy_loss: 4.1618 - val_value_loss: 0.5450 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11811 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11811/11811 [==============================] - 0s 24us/step - loss: 5.5443 - policy_loss: 4.5095 - value_loss: 0.5174 - policy_acc: 0.7402 - value_acc: 0.7286 - val_loss: 5.2484 - val_policy_loss: 4.1615 - val_value_loss: 0.5435 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11854 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11854/11854 [==============================] - 0s 24us/step - loss: 5.5151 - policy_loss: 4.5012 - value_loss: 0.5070 - policy_acc: 0.7125 - value_acc: 0.7314 - val_loss: 5.2407 - val_policy_loss: 4.1599 - val_value_loss: 0.5404 - val_policy_acc: 0.8003 - val_value_acc: 0.7728\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11894 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11894/11894 [==============================] - 0s 24us/step - loss: 5.6155 - policy_loss: 4.5750 - value_loss: 0.5202 - policy_acc: 0.6972 - value_acc: 0.7069 - val_loss: 5.2428 - val_policy_loss: 4.1626 - val_value_loss: 0.5401 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11794 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11794/11794 [==============================] - 0s 25us/step - loss: 5.5932 - policy_loss: 4.5490 - value_loss: 0.5221 - policy_acc: 0.7086 - value_acc: 0.7037 - val_loss: 5.2459 - val_policy_loss: 4.1645 - val_value_loss: 0.5407 - val_policy_acc: 0.8003 - val_value_acc: 0.7797\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11986 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11986/11986 [==============================] - 0s 24us/step - loss: 5.5809 - policy_loss: 4.5571 - value_loss: 0.5119 - policy_acc: 0.6912 - value_acc: 0.7306 - val_loss: 5.2450 - val_policy_loss: 4.1614 - val_value_loss: 0.5418 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11949 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11949/11949 [==============================] - 0s 25us/step - loss: 5.5861 - policy_loss: 4.5316 - value_loss: 0.5272 - policy_acc: 0.7079 - value_acc: 0.7037 - val_loss: 5.2452 - val_policy_loss: 4.1612 - val_value_loss: 0.5420 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11930 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11930/11930 [==============================] - 0s 25us/step - loss: 5.4225 - policy_loss: 4.5082 - value_loss: 0.4571 - policy_acc: 0.7018 - value_acc: 0.7673 - val_loss: 5.2333 - val_policy_loss: 4.1610 - val_value_loss: 0.5361 - val_policy_acc: 0.8003 - val_value_acc: 0.7728\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11777 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11777/11777 [==============================] - 0s 25us/step - loss: 5.4488 - policy_loss: 4.4803 - value_loss: 0.4843 - policy_acc: 0.7446 - value_acc: 0.7489 - val_loss: 5.2134 - val_policy_loss: 4.1616 - val_value_loss: 0.5259 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11991 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11991/11991 [==============================] - 0s 26us/step - loss: 5.6013 - policy_loss: 4.5329 - value_loss: 0.5342 - policy_acc: 0.7243 - value_acc: 0.7092 - val_loss: 5.2145 - val_policy_loss: 4.1630 - val_value_loss: 0.5258 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11766 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11766/11766 [==============================] - 0s 24us/step - loss: 5.5488 - policy_loss: 4.5682 - value_loss: 0.4903 - policy_acc: 0.7148 - value_acc: 0.7517 - val_loss: 5.2164 - val_policy_loss: 4.1622 - val_value_loss: 0.5271 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11990 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11990/11990 [==============================] - 0s 24us/step - loss: 5.5030 - policy_loss: 4.4607 - value_loss: 0.5212 - policy_acc: 0.7401 - value_acc: 0.7229 - val_loss: 5.2200 - val_policy_loss: 4.1605 - val_value_loss: 0.5297 - val_policy_acc: 0.8003 - val_value_acc: 0.7797\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11662 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11662/11662 [==============================] - 0s 24us/step - loss: 5.4460 - policy_loss: 4.4625 - value_loss: 0.4917 - policy_acc: 0.7126 - value_acc: 0.7434 - val_loss: 5.2227 - val_policy_loss: 4.1595 - val_value_loss: 0.5316 - val_policy_acc: 0.8003 - val_value_acc: 0.7866\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11838 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11838/11838 [==============================] - 0s 25us/step - loss: 5.5973 - policy_loss: 4.5203 - value_loss: 0.5385 - policy_acc: 0.7250 - value_acc: 0.7146 - val_loss: 5.2318 - val_policy_loss: 4.1615 - val_value_loss: 0.5351 - val_policy_acc: 0.8003 - val_value_acc: 0.7866\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11770 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11770/11770 [==============================] - 0s 25us/step - loss: 5.4743 - policy_loss: 4.4749 - value_loss: 0.4997 - policy_acc: 0.7311 - value_acc: 0.7302 - val_loss: 5.2349 - val_policy_loss: 4.1606 - val_value_loss: 0.5372 - val_policy_acc: 0.8003 - val_value_acc: 0.7780\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11748 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11748/11748 [==============================] - 0s 25us/step - loss: 5.5635 - policy_loss: 4.4990 - value_loss: 0.5322 - policy_acc: 0.7411 - value_acc: 0.7102 - val_loss: 5.2340 - val_policy_loss: 4.1613 - val_value_loss: 0.5364 - val_policy_acc: 0.8003 - val_value_acc: 0.7814\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11785 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11785/11785 [==============================] - 0s 25us/step - loss: 5.5645 - policy_loss: 4.5175 - value_loss: 0.5235 - policy_acc: 0.6914 - value_acc: 0.7073 - val_loss: 5.2314 - val_policy_loss: 4.1622 - val_value_loss: 0.5346 - val_policy_acc: 0.7969 - val_value_acc: 0.7917\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11798 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11798/11798 [==============================] - 0s 24us/step - loss: 5.3993 - policy_loss: 4.4663 - value_loss: 0.4665 - policy_acc: 0.7161 - value_acc: 0.7600 - val_loss: 5.2263 - val_policy_loss: 4.1625 - val_value_loss: 0.5319 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11746 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11746/11746 [==============================] - 0s 24us/step - loss: 5.5434 - policy_loss: 4.4901 - value_loss: 0.5267 - policy_acc: 0.7273 - value_acc: 0.7154 - val_loss: 5.2258 - val_policy_loss: 4.1639 - val_value_loss: 0.5310 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11818 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11818/11818 [==============================] - 0s 26us/step - loss: 5.5304 - policy_loss: 4.5336 - value_loss: 0.4984 - policy_acc: 0.7064 - value_acc: 0.7332 - val_loss: 5.2242 - val_policy_loss: 4.1624 - val_value_loss: 0.5309 - val_policy_acc: 0.8003 - val_value_acc: 0.7780\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11984 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11984/11984 [==============================] - 0s 24us/step - loss: 5.5853 - policy_loss: 4.6001 - value_loss: 0.4926 - policy_acc: 0.7062 - value_acc: 0.7341 - val_loss: 5.2207 - val_policy_loss: 4.1596 - val_value_loss: 0.5306 - val_policy_acc: 0.8003 - val_value_acc: 0.7780\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11874 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11874/11874 [==============================] - 0s 25us/step - loss: 5.5266 - policy_loss: 4.5365 - value_loss: 0.4951 - policy_acc: 0.6950 - value_acc: 0.7335 - val_loss: 5.2169 - val_policy_loss: 4.1607 - val_value_loss: 0.5281 - val_policy_acc: 0.8003 - val_value_acc: 0.7797\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11874 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11874/11874 [==============================] - 0s 25us/step - loss: 5.6094 - policy_loss: 4.5267 - value_loss: 0.5414 - policy_acc: 0.7100 - value_acc: 0.6996 - val_loss: 5.2184 - val_policy_loss: 4.1615 - val_value_loss: 0.5284 - val_policy_acc: 0.8003 - val_value_acc: 0.7952\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11855 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11855/11855 [==============================] - 0s 25us/step - loss: 5.4845 - policy_loss: 4.4897 - value_loss: 0.4974 - policy_acc: 0.7243 - value_acc: 0.7337 - val_loss: 5.2288 - val_policy_loss: 4.1629 - val_value_loss: 0.5329 - val_policy_acc: 0.8003 - val_value_acc: 0.7866\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11794 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11794/11794 [==============================] - 0s 25us/step - loss: 5.5944 - policy_loss: 4.5412 - value_loss: 0.5266 - policy_acc: 0.7149 - value_acc: 0.7218 - val_loss: 5.2295 - val_policy_loss: 4.1620 - val_value_loss: 0.5338 - val_policy_acc: 0.8003 - val_value_acc: 0.7866\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11765 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11765/11765 [==============================] - 0s 24us/step - loss: 5.4971 - policy_loss: 4.5025 - value_loss: 0.4973 - policy_acc: 0.7369 - value_acc: 0.7432 - val_loss: 5.2200 - val_policy_loss: 4.1590 - val_value_loss: 0.5305 - val_policy_acc: 0.8003 - val_value_acc: 0.7883\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11816 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11816/11816 [==============================] - 0s 25us/step - loss: 5.5543 - policy_loss: 4.5319 - value_loss: 0.5112 - policy_acc: 0.7380 - value_acc: 0.7259 - val_loss: 5.2153 - val_policy_loss: 4.1588 - val_value_loss: 0.5283 - val_policy_acc: 0.8003 - val_value_acc: 0.7935\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11871 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11871/11871 [==============================] - 0s 24us/step - loss: 5.5791 - policy_loss: 4.5318 - value_loss: 0.5236 - policy_acc: 0.7182 - value_acc: 0.7158 - val_loss: 5.2139 - val_policy_loss: 4.1606 - val_value_loss: 0.5266 - val_policy_acc: 0.8003 - val_value_acc: 0.7917\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11928 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11928/11928 [==============================] - 0s 24us/step - loss: 5.4624 - policy_loss: 4.4889 - value_loss: 0.4868 - policy_acc: 0.6991 - value_acc: 0.7409 - val_loss: 5.2147 - val_policy_loss: 4.1598 - val_value_loss: 0.5274 - val_policy_acc: 0.8003 - val_value_acc: 0.7969\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11788 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11788/11788 [==============================] - 0s 24us/step - loss: 5.5370 - policy_loss: 4.4718 - value_loss: 0.5326 - policy_acc: 0.7436 - value_acc: 0.7112 - val_loss: 5.2220 - val_policy_loss: 4.1602 - val_value_loss: 0.5309 - val_policy_acc: 0.8003 - val_value_acc: 0.8003\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11884 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11884/11884 [==============================] - 0s 24us/step - loss: 5.5445 - policy_loss: 4.5347 - value_loss: 0.5049 - policy_acc: 0.7164 - value_acc: 0.7340 - val_loss: 5.2296 - val_policy_loss: 4.1609 - val_value_loss: 0.5343 - val_policy_acc: 0.8003 - val_value_acc: 0.8021\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11676 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11676/11676 [==============================] - 0s 26us/step - loss: 5.5665 - policy_loss: 4.5550 - value_loss: 0.5058 - policy_acc: 0.6981 - value_acc: 0.7340 - val_loss: 5.2270 - val_policy_loss: 4.1588 - val_value_loss: 0.5341 - val_policy_acc: 0.8003 - val_value_acc: 0.8003\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11780 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11780/11780 [==============================] - 0s 24us/step - loss: 5.5116 - policy_loss: 4.5048 - value_loss: 0.5034 - policy_acc: 0.7334 - value_acc: 0.7310 - val_loss: 5.2257 - val_policy_loss: 4.1591 - val_value_loss: 0.5333 - val_policy_acc: 0.8003 - val_value_acc: 0.8003\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11853 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11853/11853 [==============================] - 0s 24us/step - loss: 5.5706 - policy_loss: 4.5655 - value_loss: 0.5026 - policy_acc: 0.7139 - value_acc: 0.7355 - val_loss: 5.2284 - val_policy_loss: 4.1618 - val_value_loss: 0.5333 - val_policy_acc: 0.8003 - val_value_acc: 0.7900\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11850 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11850/11850 [==============================] - 0s 24us/step - loss: 5.4409 - policy_loss: 4.4452 - value_loss: 0.4978 - policy_acc: 0.7332 - value_acc: 0.7399 - val_loss: 5.2210 - val_policy_loss: 4.1620 - val_value_loss: 0.5295 - val_policy_acc: 0.8003 - val_value_acc: 0.7935\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11650 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11650/11650 [==============================] - 0s 25us/step - loss: 5.5353 - policy_loss: 4.5518 - value_loss: 0.4918 - policy_acc: 0.7196 - value_acc: 0.7300 - val_loss: 5.2190 - val_policy_loss: 4.1624 - val_value_loss: 0.5283 - val_policy_acc: 0.8003 - val_value_acc: 0.7986\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11924 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11924/11924 [==============================] - 0s 24us/step - loss: 5.5004 - policy_loss: 4.5167 - value_loss: 0.4918 - policy_acc: 0.7090 - value_acc: 0.7395 - val_loss: 5.2247 - val_policy_loss: 4.1624 - val_value_loss: 0.5312 - val_policy_acc: 0.8003 - val_value_acc: 0.7849\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11755 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11755/11755 [==============================] - 0s 25us/step - loss: 5.5341 - policy_loss: 4.4981 - value_loss: 0.5180 - policy_acc: 0.7434 - value_acc: 0.7196 - val_loss: 5.2234 - val_policy_loss: 4.1616 - val_value_loss: 0.5309 - val_policy_acc: 0.8003 - val_value_acc: 0.7866\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11841 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11841/11841 [==============================] - 0s 24us/step - loss: 5.5415 - policy_loss: 4.5275 - value_loss: 0.5070 - policy_acc: 0.7130 - value_acc: 0.7257 - val_loss: 5.2272 - val_policy_loss: 4.1606 - val_value_loss: 0.5333 - val_policy_acc: 0.8003 - val_value_acc: 0.7831\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11857 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11857/11857 [==============================] - 0s 24us/step - loss: 5.5406 - policy_loss: 4.4936 - value_loss: 0.5235 - policy_acc: 0.7358 - value_acc: 0.7338 - val_loss: 5.2286 - val_policy_loss: 4.1598 - val_value_loss: 0.5344 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11876 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11876/11876 [==============================] - 0s 26us/step - loss: 5.4430 - policy_loss: 4.4272 - value_loss: 0.5079 - policy_acc: 0.7380 - value_acc: 0.7397 - val_loss: 5.2229 - val_policy_loss: 4.1588 - val_value_loss: 0.5321 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11858 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11858/11858 [==============================] - 0s 25us/step - loss: 5.5924 - policy_loss: 4.5578 - value_loss: 0.5173 - policy_acc: 0.7081 - value_acc: 0.7185 - val_loss: 5.2246 - val_policy_loss: 4.1591 - val_value_loss: 0.5327 - val_policy_acc: 0.8003 - val_value_acc: 0.7952\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11842 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11842/11842 [==============================] - 0s 24us/step - loss: 5.5347 - policy_loss: 4.5280 - value_loss: 0.5033 - policy_acc: 0.7253 - value_acc: 0.7261 - val_loss: 5.2316 - val_policy_loss: 4.1578 - val_value_loss: 0.5369 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11808 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11808/11808 [==============================] - 0s 28us/step - loss: 5.5581 - policy_loss: 4.5263 - value_loss: 0.5159 - policy_acc: 0.7064 - value_acc: 0.7227 - val_loss: 5.2370 - val_policy_loss: 4.1587 - val_value_loss: 0.5391 - val_policy_acc: 0.8003 - val_value_acc: 0.7935\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11835 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11835/11835 [==============================] - 0s 24us/step - loss: 5.5326 - policy_loss: 4.5165 - value_loss: 0.5081 - policy_acc: 0.7138 - value_acc: 0.7299 - val_loss: 5.2406 - val_policy_loss: 4.1617 - val_value_loss: 0.5395 - val_policy_acc: 0.8003 - val_value_acc: 0.7849\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11802 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11802/11802 [==============================] - 0s 24us/step - loss: 5.4902 - policy_loss: 4.4920 - value_loss: 0.4991 - policy_acc: 0.7356 - value_acc: 0.7430 - val_loss: 5.2331 - val_policy_loss: 4.1592 - val_value_loss: 0.5369 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11879 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11879/11879 [==============================] - 0s 27us/step - loss: 5.5133 - policy_loss: 4.4492 - value_loss: 0.5321 - policy_acc: 0.7346 - value_acc: 0.7059 - val_loss: 5.2283 - val_policy_loss: 4.1576 - val_value_loss: 0.5354 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11920 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11920/11920 [==============================] - 0s 25us/step - loss: 5.6003 - policy_loss: 4.5229 - value_loss: 0.5387 - policy_acc: 0.7308 - value_acc: 0.7016 - val_loss: 5.2325 - val_policy_loss: 4.1604 - val_value_loss: 0.5360 - val_policy_acc: 0.8003 - val_value_acc: 0.7849\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11966 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11966/11966 [==============================] - 0s 29us/step - loss: 5.5656 - policy_loss: 4.5318 - value_loss: 0.5169 - policy_acc: 0.7077 - value_acc: 0.7238 - val_loss: 5.2362 - val_policy_loss: 4.1605 - val_value_loss: 0.5378 - val_policy_acc: 0.8003 - val_value_acc: 0.7849\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11916 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11916/11916 [==============================] - 0s 26us/step - loss: 5.4766 - policy_loss: 4.5134 - value_loss: 0.4816 - policy_acc: 0.7221 - value_acc: 0.7466 - val_loss: 5.2357 - val_policy_loss: 4.1595 - val_value_loss: 0.5381 - val_policy_acc: 0.8003 - val_value_acc: 0.7780\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11741 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11741/11741 [==============================] - 0s 23us/step - loss: 5.5542 - policy_loss: 4.4911 - value_loss: 0.5315 - policy_acc: 0.7303 - value_acc: 0.7068 - val_loss: 5.2372 - val_policy_loss: 4.1593 - val_value_loss: 0.5389 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11940 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11940/11940 [==============================] - 0s 27us/step - loss: 5.4838 - policy_loss: 4.4324 - value_loss: 0.5257 - policy_acc: 0.7372 - value_acc: 0.7129 - val_loss: 5.2417 - val_policy_loss: 4.1595 - val_value_loss: 0.5411 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11932 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11932/11932 [==============================] - 0s 25us/step - loss: 5.5989 - policy_loss: 4.5235 - value_loss: 0.5377 - policy_acc: 0.7145 - value_acc: 0.7104 - val_loss: 5.2561 - val_policy_loss: 4.1617 - val_value_loss: 0.5472 - val_policy_acc: 0.8003 - val_value_acc: 0.7315\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11873 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11873/11873 [==============================] - 0s 24us/step - loss: 5.4879 - policy_loss: 4.4923 - value_loss: 0.4978 - policy_acc: 0.7133 - value_acc: 0.7398 - val_loss: 5.2510 - val_policy_loss: 4.1601 - val_value_loss: 0.5455 - val_policy_acc: 0.8003 - val_value_acc: 0.7298\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11771 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11771/11771 [==============================] - 0s 24us/step - loss: 5.6115 - policy_loss: 4.5227 - value_loss: 0.5444 - policy_acc: 0.7232 - value_acc: 0.6954 - val_loss: 5.2498 - val_policy_loss: 4.1586 - val_value_loss: 0.5456 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11914 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11914/11914 [==============================] - 0s 27us/step - loss: 5.5232 - policy_loss: 4.5306 - value_loss: 0.4963 - policy_acc: 0.7268 - value_acc: 0.7310 - val_loss: 5.2473 - val_policy_loss: 4.1592 - val_value_loss: 0.5440 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11893 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11893/11893 [==============================] - 0s 24us/step - loss: 5.4866 - policy_loss: 4.4678 - value_loss: 0.5094 - policy_acc: 0.7258 - value_acc: 0.7257 - val_loss: 5.2440 - val_policy_loss: 4.1595 - val_value_loss: 0.5423 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11975 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11975/11975 [==============================] - 0s 25us/step - loss: 5.5203 - policy_loss: 4.4900 - value_loss: 0.5152 - policy_acc: 0.7477 - value_acc: 0.7273 - val_loss: 5.2338 - val_policy_loss: 4.1599 - val_value_loss: 0.5370 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11888 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11888/11888 [==============================] - 0s 28us/step - loss: 5.4642 - policy_loss: 4.5219 - value_loss: 0.4711 - policy_acc: 0.7272 - value_acc: 0.7605 - val_loss: 5.2153 - val_policy_loss: 4.1599 - val_value_loss: 0.5277 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11811 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11811/11811 [==============================] - 0s 23us/step - loss: 5.6123 - policy_loss: 4.5330 - value_loss: 0.5396 - policy_acc: 0.6919 - value_acc: 0.7023 - val_loss: 5.2110 - val_policy_loss: 4.1615 - val_value_loss: 0.5248 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11933 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11933/11933 [==============================] - 0s 24us/step - loss: 5.4757 - policy_loss: 4.4815 - value_loss: 0.4971 - policy_acc: 0.7181 - value_acc: 0.7433 - val_loss: 5.2127 - val_policy_loss: 4.1616 - val_value_loss: 0.5255 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11753 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11753/11753 [==============================] - 0s 24us/step - loss: 5.4321 - policy_loss: 4.4900 - value_loss: 0.4710 - policy_acc: 0.7455 - value_acc: 0.7476 - val_loss: 5.2121 - val_policy_loss: 4.1596 - val_value_loss: 0.5262 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11717 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11717/11717 [==============================] - 0s 25us/step - loss: 5.5917 - policy_loss: 4.5196 - value_loss: 0.5360 - policy_acc: 0.7145 - value_acc: 0.7067 - val_loss: 5.2182 - val_policy_loss: 4.1585 - val_value_loss: 0.5299 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11809 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11809/11809 [==============================] - 0s 24us/step - loss: 5.6358 - policy_loss: 4.5049 - value_loss: 0.5654 - policy_acc: 0.7160 - value_acc: 0.6833 - val_loss: 5.2407 - val_policy_loss: 4.1602 - val_value_loss: 0.5403 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11700 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11700/11700 [==============================] - 0s 24us/step - loss: 5.5272 - policy_loss: 4.5054 - value_loss: 0.5109 - policy_acc: 0.7181 - value_acc: 0.7253 - val_loss: 5.2553 - val_policy_loss: 4.1593 - val_value_loss: 0.5480 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11874 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11874/11874 [==============================] - 0s 24us/step - loss: 5.3803 - policy_loss: 4.4485 - value_loss: 0.4659 - policy_acc: 0.7213 - value_acc: 0.7613 - val_loss: 5.2509 - val_policy_loss: 4.1594 - val_value_loss: 0.5458 - val_policy_acc: 0.8003 - val_value_acc: 0.7057\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11954 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11954/11954 [==============================] - 0s 24us/step - loss: 5.5202 - policy_loss: 4.5055 - value_loss: 0.5073 - policy_acc: 0.7301 - value_acc: 0.7336 - val_loss: 5.2396 - val_policy_loss: 4.1599 - val_value_loss: 0.5398 - val_policy_acc: 0.8003 - val_value_acc: 0.7005\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11765 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11765/11765 [==============================] - 0s 26us/step - loss: 5.4167 - policy_loss: 4.4680 - value_loss: 0.4744 - policy_acc: 0.7470 - value_acc: 0.7495 - val_loss: 5.2269 - val_policy_loss: 4.1571 - val_value_loss: 0.5349 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11821 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11821/11821 [==============================] - 0s 24us/step - loss: 5.4539 - policy_loss: 4.4856 - value_loss: 0.4842 - policy_acc: 0.7280 - value_acc: 0.7405 - val_loss: 5.2231 - val_policy_loss: 4.1571 - val_value_loss: 0.5330 - val_policy_acc: 0.8003 - val_value_acc: 0.7177\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11892 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11892/11892 [==============================] - 0s 24us/step - loss: 5.5971 - policy_loss: 4.5128 - value_loss: 0.5422 - policy_acc: 0.7224 - value_acc: 0.7031 - val_loss: 5.2294 - val_policy_loss: 4.1586 - val_value_loss: 0.5354 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11895 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11895/11895 [==============================] - 0s 24us/step - loss: 5.5850 - policy_loss: 4.5564 - value_loss: 0.5143 - policy_acc: 0.7064 - value_acc: 0.7291 - val_loss: 5.2494 - val_policy_loss: 4.1592 - val_value_loss: 0.5451 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11846 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11846/11846 [==============================] - 0s 25us/step - loss: 5.5481 - policy_loss: 4.5337 - value_loss: 0.5072 - policy_acc: 0.6957 - value_acc: 0.7262 - val_loss: 5.2587 - val_policy_loss: 4.1579 - val_value_loss: 0.5504 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11725 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11725/11725 [==============================] - 0s 24us/step - loss: 5.5649 - policy_loss: 4.4749 - value_loss: 0.5450 - policy_acc: 0.7394 - value_acc: 0.7044 - val_loss: 5.2596 - val_policy_loss: 4.1570 - val_value_loss: 0.5513 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11770 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11770/11770 [==============================] - 0s 24us/step - loss: 5.5794 - policy_loss: 4.5207 - value_loss: 0.5294 - policy_acc: 0.7226 - value_acc: 0.7181 - val_loss: 5.2580 - val_policy_loss: 4.1586 - val_value_loss: 0.5497 - val_policy_acc: 0.7969 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11928 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11928/11928 [==============================] - 0s 25us/step - loss: 5.5779 - policy_loss: 4.5676 - value_loss: 0.5052 - policy_acc: 0.6801 - value_acc: 0.7323 - val_loss: 5.2518 - val_policy_loss: 4.1622 - val_value_loss: 0.5448 - val_policy_acc: 0.7969 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11778 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11778/11778 [==============================] - 0s 24us/step - loss: 5.6372 - policy_loss: 4.5486 - value_loss: 0.5443 - policy_acc: 0.7059 - value_acc: 0.6974 - val_loss: 5.2496 - val_policy_loss: 4.1618 - val_value_loss: 0.5439 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11801 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11801/11801 [==============================] - 0s 25us/step - loss: 5.5558 - policy_loss: 4.5470 - value_loss: 0.5044 - policy_acc: 0.7012 - value_acc: 0.7371 - val_loss: 5.2448 - val_policy_loss: 4.1597 - val_value_loss: 0.5426 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11809 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11809/11809 [==============================] - 0s 25us/step - loss: 5.5431 - policy_loss: 4.5461 - value_loss: 0.4985 - policy_acc: 0.7145 - value_acc: 0.7378 - val_loss: 5.2402 - val_policy_loss: 4.1591 - val_value_loss: 0.5406 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11803 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11803/11803 [==============================] - 0s 27us/step - loss: 5.5181 - policy_loss: 4.4659 - value_loss: 0.5261 - policy_acc: 0.7174 - value_acc: 0.7242 - val_loss: 5.2359 - val_policy_loss: 4.1582 - val_value_loss: 0.5388 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11736 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11736/11736 [==============================] - 0s 24us/step - loss: 5.5377 - policy_loss: 4.5340 - value_loss: 0.5018 - policy_acc: 0.7066 - value_acc: 0.7321 - val_loss: 5.2346 - val_policy_loss: 4.1579 - val_value_loss: 0.5384 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11756 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11756/11756 [==============================] - 0s 25us/step - loss: 5.5553 - policy_loss: 4.5291 - value_loss: 0.5131 - policy_acc: 0.7244 - value_acc: 0.7227 - val_loss: 5.2385 - val_policy_loss: 4.1596 - val_value_loss: 0.5394 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11787 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11787/11787 [==============================] - 0s 25us/step - loss: 5.6116 - policy_loss: 4.5361 - value_loss: 0.5378 - policy_acc: 0.7138 - value_acc: 0.7130 - val_loss: 5.2459 - val_policy_loss: 4.1617 - val_value_loss: 0.5421 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11889 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11889/11889 [==============================] - 0s 25us/step - loss: 5.4952 - policy_loss: 4.5373 - value_loss: 0.4790 - policy_acc: 0.7313 - value_acc: 0.7577 - val_loss: 5.2419 - val_policy_loss: 4.1607 - val_value_loss: 0.5406 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11827 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11827/11827 [==============================] - 0s 24us/step - loss: 5.5082 - policy_loss: 4.5216 - value_loss: 0.4933 - policy_acc: 0.7128 - value_acc: 0.7370 - val_loss: 5.2347 - val_policy_loss: 4.1583 - val_value_loss: 0.5382 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11798 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11798/11798 [==============================] - 0s 24us/step - loss: 5.5032 - policy_loss: 4.4750 - value_loss: 0.5141 - policy_acc: 0.7234 - value_acc: 0.7227 - val_loss: 5.2394 - val_policy_loss: 4.1577 - val_value_loss: 0.5409 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11900 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11900/11900 [==============================] - 0s 25us/step - loss: 5.4907 - policy_loss: 4.4878 - value_loss: 0.5014 - policy_acc: 0.7245 - value_acc: 0.7310 - val_loss: 5.2507 - val_policy_loss: 4.1587 - val_value_loss: 0.5460 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11686 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11686/11686 [==============================] - 0s 25us/step - loss: 5.4935 - policy_loss: 4.5122 - value_loss: 0.4907 - policy_acc: 0.7485 - value_acc: 0.7349 - val_loss: 5.2576 - val_policy_loss: 4.1604 - val_value_loss: 0.5486 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11764 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11764/11764 [==============================] - 0s 24us/step - loss: 5.4836 - policy_loss: 4.4808 - value_loss: 0.5014 - policy_acc: 0.7073 - value_acc: 0.7351 - val_loss: 5.2494 - val_policy_loss: 4.1597 - val_value_loss: 0.5449 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11824 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11824/11824 [==============================] - 0s 24us/step - loss: 5.5433 - policy_loss: 4.4817 - value_loss: 0.5308 - policy_acc: 0.7413 - value_acc: 0.7102 - val_loss: 5.2509 - val_policy_loss: 4.1600 - val_value_loss: 0.5455 - val_policy_acc: 0.8003 - val_value_acc: 0.7315\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11815 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11815/11815 [==============================] - 0s 25us/step - loss: 5.4546 - policy_loss: 4.4624 - value_loss: 0.4961 - policy_acc: 0.7292 - value_acc: 0.7306 - val_loss: 5.2514 - val_policy_loss: 4.1595 - val_value_loss: 0.5460 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11780 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11780/11780 [==============================] - 0s 24us/step - loss: 5.4037 - policy_loss: 4.4227 - value_loss: 0.4905 - policy_acc: 0.7384 - value_acc: 0.7442 - val_loss: 5.2452 - val_policy_loss: 4.1564 - val_value_loss: 0.5444 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11896 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11896/11896 [==============================] - 0s 25us/step - loss: 5.6060 - policy_loss: 4.5778 - value_loss: 0.5141 - policy_acc: 0.7057 - value_acc: 0.7193 - val_loss: 5.2563 - val_policy_loss: 4.1577 - val_value_loss: 0.5493 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11864 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11864/11864 [==============================] - 0s 24us/step - loss: 5.5191 - policy_loss: 4.4822 - value_loss: 0.5185 - policy_acc: 0.7171 - value_acc: 0.7233 - val_loss: 5.2564 - val_policy_loss: 4.1612 - val_value_loss: 0.5476 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11773 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11773/11773 [==============================] - 0s 25us/step - loss: 5.5675 - policy_loss: 4.6059 - value_loss: 0.4808 - policy_acc: 0.6748 - value_acc: 0.7475 - val_loss: 5.2403 - val_policy_loss: 4.1607 - val_value_loss: 0.5398 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11854 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11854/11854 [==============================] - 0s 24us/step - loss: 5.5162 - policy_loss: 4.5226 - value_loss: 0.4968 - policy_acc: 0.7286 - value_acc: 0.7449 - val_loss: 5.2270 - val_policy_loss: 4.1615 - val_value_loss: 0.5327 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11676 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11676/11676 [==============================] - 0s 27us/step - loss: 5.5108 - policy_loss: 4.5152 - value_loss: 0.4978 - policy_acc: 0.7298 - value_acc: 0.7361 - val_loss: 5.2223 - val_policy_loss: 4.1615 - val_value_loss: 0.5304 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11863 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11863/11863 [==============================] - 0s 24us/step - loss: 5.3860 - policy_loss: 4.4189 - value_loss: 0.4836 - policy_acc: 0.7320 - value_acc: 0.7474 - val_loss: 5.2151 - val_policy_loss: 4.1598 - val_value_loss: 0.5276 - val_policy_acc: 0.8003 - val_value_acc: 0.7298\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11821 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11821/11821 [==============================] - 0s 24us/step - loss: 5.4271 - policy_loss: 4.4206 - value_loss: 0.5033 - policy_acc: 0.7416 - value_acc: 0.7331 - val_loss: 5.2124 - val_policy_loss: 4.1599 - val_value_loss: 0.5263 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11998 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11998/11998 [==============================] - 0s 24us/step - loss: 5.5092 - policy_loss: 4.5332 - value_loss: 0.4880 - policy_acc: 0.7288 - value_acc: 0.7464 - val_loss: 5.2240 - val_policy_loss: 4.1598 - val_value_loss: 0.5321 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11911 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11911/11911 [==============================] - 0s 24us/step - loss: 5.3994 - policy_loss: 4.4004 - value_loss: 0.4995 - policy_acc: 0.7410 - value_acc: 0.7339 - val_loss: 5.2329 - val_policy_loss: 4.1577 - val_value_loss: 0.5376 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11841 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11841/11841 [==============================] - 0s 24us/step - loss: 5.6572 - policy_loss: 4.5573 - value_loss: 0.5499 - policy_acc: 0.7069 - value_acc: 0.6970 - val_loss: 5.2497 - val_policy_loss: 4.1581 - val_value_loss: 0.5458 - val_policy_acc: 0.7969 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11809 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11809/11809 [==============================] - 0s 25us/step - loss: 5.4554 - policy_loss: 4.5117 - value_loss: 0.4718 - policy_acc: 0.7199 - value_acc: 0.7627 - val_loss: 5.2527 - val_policy_loss: 4.1564 - val_value_loss: 0.5482 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11806 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11806/11806 [==============================] - 0s 25us/step - loss: 5.3940 - policy_loss: 4.4622 - value_loss: 0.4659 - policy_acc: 0.7381 - value_acc: 0.7495 - val_loss: 5.2462 - val_policy_loss: 4.1588 - val_value_loss: 0.5437 - val_policy_acc: 0.8003 - val_value_acc: 0.7022\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11796 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11796/11796 [==============================] - 0s 23us/step - loss: 5.5598 - policy_loss: 4.5086 - value_loss: 0.5256 - policy_acc: 0.7319 - value_acc: 0.7185 - val_loss: 5.2434 - val_policy_loss: 4.1593 - val_value_loss: 0.5421 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11764 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11764/11764 [==============================] - 0s 24us/step - loss: 5.5102 - policy_loss: 4.5044 - value_loss: 0.5029 - policy_acc: 0.6970 - value_acc: 0.7364 - val_loss: 5.2502 - val_policy_loss: 4.1605 - val_value_loss: 0.5448 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11893 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11893/11893 [==============================] - 0s 24us/step - loss: 5.5718 - policy_loss: 4.4804 - value_loss: 0.5457 - policy_acc: 0.7152 - value_acc: 0.7014 - val_loss: 5.2647 - val_policy_loss: 4.1612 - val_value_loss: 0.5518 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11842 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11842/11842 [==============================] - 0s 25us/step - loss: 5.4715 - policy_loss: 4.4754 - value_loss: 0.4981 - policy_acc: 0.7569 - value_acc: 0.7435 - val_loss: 5.2642 - val_policy_loss: 4.1587 - val_value_loss: 0.5528 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11648 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11648/11648 [==============================] - 0s 29us/step - loss: 5.4597 - policy_loss: 4.5171 - value_loss: 0.4713 - policy_acc: 0.7388 - value_acc: 0.7663 - val_loss: 5.2440 - val_policy_loss: 4.1579 - val_value_loss: 0.5430 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11852 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11852/11852 [==============================] - 0s 27us/step - loss: 5.4563 - policy_loss: 4.4595 - value_loss: 0.4984 - policy_acc: 0.7220 - value_acc: 0.7382 - val_loss: 5.2269 - val_policy_loss: 4.1581 - val_value_loss: 0.5344 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11970 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11970/11970 [==============================] - 0s 24us/step - loss: 5.5551 - policy_loss: 4.4882 - value_loss: 0.5334 - policy_acc: 0.7260 - value_acc: 0.7068 - val_loss: 5.2262 - val_policy_loss: 4.1574 - val_value_loss: 0.5344 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11821 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11821/11821 [==============================] - 0s 24us/step - loss: 5.5016 - policy_loss: 4.5343 - value_loss: 0.4836 - policy_acc: 0.7456 - value_acc: 0.7394 - val_loss: 5.2358 - val_policy_loss: 4.1583 - val_value_loss: 0.5387 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11677 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11677/11677 [==============================] - 0s 26us/step - loss: 5.4654 - policy_loss: 4.4881 - value_loss: 0.4887 - policy_acc: 0.7042 - value_acc: 0.7466 - val_loss: 5.2442 - val_policy_loss: 4.1590 - val_value_loss: 0.5426 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11800 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11800/11800 [==============================] - 0s 23us/step - loss: 5.4542 - policy_loss: 4.4337 - value_loss: 0.5102 - policy_acc: 0.7530 - value_acc: 0.7285 - val_loss: 5.2500 - val_policy_loss: 4.1616 - val_value_loss: 0.5442 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11842 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11842/11842 [==============================] - 0s 24us/step - loss: 5.4999 - policy_loss: 4.5254 - value_loss: 0.4872 - policy_acc: 0.6953 - value_acc: 0.7421 - val_loss: 5.2509 - val_policy_loss: 4.1638 - val_value_loss: 0.5436 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11728 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11728/11728 [==============================] - 0s 25us/step - loss: 5.4904 - policy_loss: 4.4802 - value_loss: 0.5051 - policy_acc: 0.7207 - value_acc: 0.7422 - val_loss: 5.2387 - val_policy_loss: 4.1592 - val_value_loss: 0.5398 - val_policy_acc: 0.8003 - val_value_acc: 0.7642\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11642 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11642/11642 [==============================] - 0s 24us/step - loss: 5.4926 - policy_loss: 4.4632 - value_loss: 0.5147 - policy_acc: 0.7336 - value_acc: 0.7225 - val_loss: 5.2380 - val_policy_loss: 4.1586 - val_value_loss: 0.5397 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11950 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11950/11950 [==============================] - 0s 28us/step - loss: 5.5711 - policy_loss: 4.5351 - value_loss: 0.5180 - policy_acc: 0.7113 - value_acc: 0.7275 - val_loss: 5.2445 - val_policy_loss: 4.1600 - val_value_loss: 0.5423 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11843 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11843/11843 [==============================] - 0s 24us/step - loss: 5.4471 - policy_loss: 4.4753 - value_loss: 0.4859 - policy_acc: 0.7294 - value_acc: 0.7444 - val_loss: 5.2389 - val_policy_loss: 4.1551 - val_value_loss: 0.5419 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11774 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11774/11774 [==============================] - 0s 24us/step - loss: 5.5043 - policy_loss: 4.4824 - value_loss: 0.5110 - policy_acc: 0.7297 - value_acc: 0.7260 - val_loss: 5.2422 - val_policy_loss: 4.1562 - val_value_loss: 0.5430 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11860 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11860/11860 [==============================] - 0s 24us/step - loss: 5.5648 - policy_loss: 4.5595 - value_loss: 0.5026 - policy_acc: 0.7051 - value_acc: 0.7333 - val_loss: 5.2469 - val_policy_loss: 4.1577 - val_value_loss: 0.5446 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11859 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11859/11859 [==============================] - 0s 25us/step - loss: 5.4836 - policy_loss: 4.4180 - value_loss: 0.5328 - policy_acc: 0.7228 - value_acc: 0.7063 - val_loss: 5.2502 - val_policy_loss: 4.1565 - val_value_loss: 0.5468 - val_policy_acc: 0.8003 - val_value_acc: 0.7194\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11858 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11858/11858 [==============================] - 0s 24us/step - loss: 5.5477 - policy_loss: 4.4831 - value_loss: 0.5323 - policy_acc: 0.7415 - value_acc: 0.7141 - val_loss: 5.2562 - val_policy_loss: 4.1581 - val_value_loss: 0.5490 - val_policy_acc: 0.8003 - val_value_acc: 0.7315\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11739 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11739/11739 [==============================] - 0s 24us/step - loss: 5.3895 - policy_loss: 4.4278 - value_loss: 0.4808 - policy_acc: 0.7397 - value_acc: 0.7496 - val_loss: 5.2536 - val_policy_loss: 4.1567 - val_value_loss: 0.5484 - val_policy_acc: 0.8003 - val_value_acc: 0.7298\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11641 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11641/11641 [==============================] - 0s 24us/step - loss: 5.4347 - policy_loss: 4.4778 - value_loss: 0.4784 - policy_acc: 0.7158 - value_acc: 0.7470 - val_loss: 5.2472 - val_policy_loss: 4.1553 - val_value_loss: 0.5459 - val_policy_acc: 0.8003 - val_value_acc: 0.7057\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11928 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11928/11928 [==============================] - 0s 25us/step - loss: 5.5550 - policy_loss: 4.5421 - value_loss: 0.5064 - policy_acc: 0.7031 - value_acc: 0.7241 - val_loss: 5.2492 - val_policy_loss: 4.1591 - val_value_loss: 0.5451 - val_policy_acc: 0.8003 - val_value_acc: 0.7005\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11872 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11872/11872 [==============================] - 0s 26us/step - loss: 5.4453 - policy_loss: 4.4769 - value_loss: 0.4842 - policy_acc: 0.7122 - value_acc: 0.7478 - val_loss: 5.2447 - val_policy_loss: 4.1588 - val_value_loss: 0.5430 - val_policy_acc: 0.8003 - val_value_acc: 0.7108\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11655 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11655/11655 [==============================] - 0s 24us/step - loss: 5.5468 - policy_loss: 4.5570 - value_loss: 0.4949 - policy_acc: 0.7114 - value_acc: 0.7393 - val_loss: 5.2412 - val_policy_loss: 4.1571 - val_value_loss: 0.5421 - val_policy_acc: 0.8003 - val_value_acc: 0.7126\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11783 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11783/11783 [==============================] - 0s 24us/step - loss: 5.5892 - policy_loss: 4.5601 - value_loss: 0.5145 - policy_acc: 0.7095 - value_acc: 0.7151 - val_loss: 5.2406 - val_policy_loss: 4.1588 - val_value_loss: 0.5409 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11890 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11890/11890 [==============================] - 0s 24us/step - loss: 5.6209 - policy_loss: 4.5751 - value_loss: 0.5229 - policy_acc: 0.6990 - value_acc: 0.7082 - val_loss: 5.2484 - val_policy_loss: 4.1585 - val_value_loss: 0.5449 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11965 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11965/11965 [==============================] - 0s 24us/step - loss: 5.4967 - policy_loss: 4.4989 - value_loss: 0.4989 - policy_acc: 0.7315 - value_acc: 0.7300 - val_loss: 5.2578 - val_policy_loss: 4.1588 - val_value_loss: 0.5495 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11945 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11945/11945 [==============================] - 0s 24us/step - loss: 5.5839 - policy_loss: 4.5551 - value_loss: 0.5144 - policy_acc: 0.7221 - value_acc: 0.7136 - val_loss: 5.2618 - val_policy_loss: 4.1614 - val_value_loss: 0.5502 - val_policy_acc: 0.7797 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11873 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11873/11873 [==============================] - 0s 24us/step - loss: 5.5786 - policy_loss: 4.5862 - value_loss: 0.4962 - policy_acc: 0.7069 - value_acc: 0.7362 - val_loss: 5.2543 - val_policy_loss: 4.1600 - val_value_loss: 0.5472 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11670 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11670/11670 [==============================] - 0s 24us/step - loss: 5.5794 - policy_loss: 4.5790 - value_loss: 0.5002 - policy_acc: 0.6931 - value_acc: 0.7385 - val_loss: 5.2454 - val_policy_loss: 4.1585 - val_value_loss: 0.5434 - val_policy_acc: 0.8003 - val_value_acc: 0.7745\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11957 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11957/11957 [==============================] - 0s 24us/step - loss: 5.5908 - policy_loss: 4.5231 - value_loss: 0.5339 - policy_acc: 0.7177 - value_acc: 0.7062 - val_loss: 5.2496 - val_policy_loss: 4.1593 - val_value_loss: 0.5452 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11739 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11739/11739 [==============================] - 0s 25us/step - loss: 5.4695 - policy_loss: 4.5053 - value_loss: 0.4821 - policy_acc: 0.7376 - value_acc: 0.7462 - val_loss: 5.2459 - val_policy_loss: 4.1606 - val_value_loss: 0.5427 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11785 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11785/11785 [==============================] - 0s 24us/step - loss: 5.5198 - policy_loss: 4.4741 - value_loss: 0.5228 - policy_acc: 0.7050 - value_acc: 0.7222 - val_loss: 5.2353 - val_policy_loss: 4.1583 - val_value_loss: 0.5385 - val_policy_acc: 0.8003 - val_value_acc: 0.7900\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11896 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11896/11896 [==============================] - 0s 23us/step - loss: 5.4862 - policy_loss: 4.5051 - value_loss: 0.4905 - policy_acc: 0.7149 - value_acc: 0.7363 - val_loss: 5.2356 - val_policy_loss: 4.1591 - val_value_loss: 0.5383 - val_policy_acc: 0.8003 - val_value_acc: 0.7814\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11670 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11670/11670 [==============================] - 0s 25us/step - loss: 5.5332 - policy_loss: 4.5187 - value_loss: 0.5072 - policy_acc: 0.7215 - value_acc: 0.7191 - val_loss: 5.2394 - val_policy_loss: 4.1619 - val_value_loss: 0.5387 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11920 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11920/11920 [==============================] - 0s 24us/step - loss: 5.6588 - policy_loss: 4.5709 - value_loss: 0.5440 - policy_acc: 0.7182 - value_acc: 0.7049 - val_loss: 5.2428 - val_policy_loss: 4.1584 - val_value_loss: 0.5422 - val_policy_acc: 0.8003 - val_value_acc: 0.7831\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11870 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11870/11870 [==============================] - 0s 24us/step - loss: 5.5251 - policy_loss: 4.5228 - value_loss: 0.5011 - policy_acc: 0.7340 - value_acc: 0.7306 - val_loss: 5.2545 - val_policy_loss: 4.1576 - val_value_loss: 0.5484 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11891 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11891/11891 [==============================] - 0s 24us/step - loss: 5.4587 - policy_loss: 4.4641 - value_loss: 0.4973 - policy_acc: 0.7404 - value_acc: 0.7385 - val_loss: 5.2562 - val_policy_loss: 4.1592 - val_value_loss: 0.5485 - val_policy_acc: 0.8003 - val_value_acc: 0.7797\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11720 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11720/11720 [==============================] - 0s 25us/step - loss: 5.5309 - policy_loss: 4.4851 - value_loss: 0.5229 - policy_acc: 0.7138 - value_acc: 0.7151 - val_loss: 5.2575 - val_policy_loss: 4.1597 - val_value_loss: 0.5489 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11890 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11890/11890 [==============================] - 0s 23us/step - loss: 5.5090 - policy_loss: 4.4488 - value_loss: 0.5301 - policy_acc: 0.7336 - value_acc: 0.7165 - val_loss: 5.2569 - val_policy_loss: 4.1607 - val_value_loss: 0.5481 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11846 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11846/11846 [==============================] - 0s 25us/step - loss: 5.6153 - policy_loss: 4.4929 - value_loss: 0.5612 - policy_acc: 0.7289 - value_acc: 0.6876 - val_loss: 5.2630 - val_policy_loss: 4.1593 - val_value_loss: 0.5519 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11843 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11843/11843 [==============================] - 0s 23us/step - loss: 5.5156 - policy_loss: 4.4803 - value_loss: 0.5177 - policy_acc: 0.7223 - value_acc: 0.7242 - val_loss: 5.2665 - val_policy_loss: 4.1590 - val_value_loss: 0.5537 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11815 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11815/11815 [==============================] - 0s 23us/step - loss: 5.4645 - policy_loss: 4.4676 - value_loss: 0.4985 - policy_acc: 0.7220 - value_acc: 0.7434 - val_loss: 5.2612 - val_policy_loss: 4.1582 - val_value_loss: 0.5515 - val_policy_acc: 0.8003 - val_value_acc: 0.6850\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11902 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11902/11902 [==============================] - 0s 24us/step - loss: 5.5378 - policy_loss: 4.4925 - value_loss: 0.5226 - policy_acc: 0.7316 - value_acc: 0.7164 - val_loss: 5.2557 - val_policy_loss: 4.1559 - val_value_loss: 0.5499 - val_policy_acc: 0.8003 - val_value_acc: 0.6764\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11814 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11814/11814 [==============================] - 0s 24us/step - loss: 5.5695 - policy_loss: 4.5724 - value_loss: 0.4985 - policy_acc: 0.7241 - value_acc: 0.7273 - val_loss: 5.2464 - val_policy_loss: 4.1571 - val_value_loss: 0.5447 - val_policy_acc: 0.8003 - val_value_acc: 0.7091\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11951 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11951/11951 [==============================] - 0s 24us/step - loss: 5.4674 - policy_loss: 4.4940 - value_loss: 0.4867 - policy_acc: 0.7337 - value_acc: 0.7384 - val_loss: 5.2401 - val_policy_loss: 4.1615 - val_value_loss: 0.5393 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11758 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11758/11758 [==============================] - 0s 24us/step - loss: 5.4739 - policy_loss: 4.4506 - value_loss: 0.5117 - policy_acc: 0.7507 - value_acc: 0.7357 - val_loss: 5.2321 - val_policy_loss: 4.1602 - val_value_loss: 0.5360 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11914 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11914/11914 [==============================] - 0s 25us/step - loss: 5.5943 - policy_loss: 4.5669 - value_loss: 0.5137 - policy_acc: 0.7044 - value_acc: 0.7173 - val_loss: 5.2396 - val_policy_loss: 4.1588 - val_value_loss: 0.5404 - val_policy_acc: 0.8003 - val_value_acc: 0.7642\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11897 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11897/11897 [==============================] - 0s 24us/step - loss: 5.4147 - policy_loss: 4.4743 - value_loss: 0.4702 - policy_acc: 0.7311 - value_acc: 0.7602 - val_loss: 5.2428 - val_policy_loss: 4.1571 - val_value_loss: 0.5429 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11854 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11854/11854 [==============================] - 0s 25us/step - loss: 5.5422 - policy_loss: 4.4946 - value_loss: 0.5238 - policy_acc: 0.7261 - value_acc: 0.7246 - val_loss: 5.2408 - val_policy_loss: 4.1598 - val_value_loss: 0.5405 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11781 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11781/11781 [==============================] - 0s 24us/step - loss: 5.5976 - policy_loss: 4.5144 - value_loss: 0.5416 - policy_acc: 0.7043 - value_acc: 0.7055 - val_loss: 5.2471 - val_policy_loss: 4.1635 - val_value_loss: 0.5418 - val_policy_acc: 0.8003 - val_value_acc: 0.7057\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11946 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11946/11946 [==============================] - 0s 23us/step - loss: 5.4895 - policy_loss: 4.4833 - value_loss: 0.5031 - policy_acc: 0.7084 - value_acc: 0.7365 - val_loss: 5.2426 - val_policy_loss: 4.1621 - val_value_loss: 0.5403 - val_policy_acc: 0.8003 - val_value_acc: 0.7040\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11960 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11960/11960 [==============================] - 0s 24us/step - loss: 5.5930 - policy_loss: 4.5472 - value_loss: 0.5229 - policy_acc: 0.7217 - value_acc: 0.7289 - val_loss: 5.2368 - val_policy_loss: 4.1609 - val_value_loss: 0.5380 - val_policy_acc: 0.8003 - val_value_acc: 0.7194\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11822 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11822/11822 [==============================] - 0s 24us/step - loss: 5.4717 - policy_loss: 4.5352 - value_loss: 0.4683 - policy_acc: 0.7193 - value_acc: 0.7569 - val_loss: 5.2279 - val_policy_loss: 4.1589 - val_value_loss: 0.5345 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11814 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11814/11814 [==============================] - 0s 28us/step - loss: 5.5259 - policy_loss: 4.5052 - value_loss: 0.5104 - policy_acc: 0.7281 - value_acc: 0.7246 - val_loss: 5.2268 - val_policy_loss: 4.1598 - val_value_loss: 0.5335 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11903 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11903/11903 [==============================] - 0s 26us/step - loss: 5.5066 - policy_loss: 4.4853 - value_loss: 0.5107 - policy_acc: 0.7215 - value_acc: 0.7261 - val_loss: 5.2270 - val_policy_loss: 4.1587 - val_value_loss: 0.5341 - val_policy_acc: 0.8003 - val_value_acc: 0.7212\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11859 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11859/11859 [==============================] - 0s 28us/step - loss: 5.5366 - policy_loss: 4.5367 - value_loss: 0.5000 - policy_acc: 0.7069 - value_acc: 0.7243 - val_loss: 5.2226 - val_policy_loss: 4.1576 - val_value_loss: 0.5325 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11548 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11548/11548 [==============================] - 0s 24us/step - loss: 5.4154 - policy_loss: 4.4351 - value_loss: 0.4901 - policy_acc: 0.7293 - value_acc: 0.7450 - val_loss: 5.2252 - val_policy_loss: 4.1599 - val_value_loss: 0.5326 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11947 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11947/11947 [==============================] - 0s 23us/step - loss: 5.5525 - policy_loss: 4.5341 - value_loss: 0.5092 - policy_acc: 0.7097 - value_acc: 0.7354 - val_loss: 5.2270 - val_policy_loss: 4.1616 - val_value_loss: 0.5327 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11888 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11888/11888 [==============================] - 0s 24us/step - loss: 5.4024 - policy_loss: 4.4085 - value_loss: 0.4970 - policy_acc: 0.7394 - value_acc: 0.7284 - val_loss: 5.2228 - val_policy_loss: 4.1581 - val_value_loss: 0.5323 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11945 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11945/11945 [==============================] - 0s 23us/step - loss: 5.5622 - policy_loss: 4.5695 - value_loss: 0.4964 - policy_acc: 0.7140 - value_acc: 0.7420 - val_loss: 5.2163 - val_policy_loss: 4.1577 - val_value_loss: 0.5293 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11844 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11844/11844 [==============================] - 0s 24us/step - loss: 5.5210 - policy_loss: 4.5413 - value_loss: 0.4899 - policy_acc: 0.7199 - value_acc: 0.7440 - val_loss: 5.2134 - val_policy_loss: 4.1575 - val_value_loss: 0.5279 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11859 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11859/11859 [==============================] - 0s 24us/step - loss: 5.5901 - policy_loss: 4.5397 - value_loss: 0.5252 - policy_acc: 0.7183 - value_acc: 0.7129 - val_loss: 5.2163 - val_policy_loss: 4.1552 - val_value_loss: 0.5306 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11914 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11914/11914 [==============================] - 0s 24us/step - loss: 5.3976 - policy_loss: 4.5048 - value_loss: 0.4464 - policy_acc: 0.7185 - value_acc: 0.7714 - val_loss: 5.2225 - val_policy_loss: 4.1566 - val_value_loss: 0.5329 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11940 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11940/11940 [==============================] - 0s 23us/step - loss: 5.5412 - policy_loss: 4.5274 - value_loss: 0.5069 - policy_acc: 0.6992 - value_acc: 0.7333 - val_loss: 5.2319 - val_policy_loss: 4.1586 - val_value_loss: 0.5367 - val_policy_acc: 0.8003 - val_value_acc: 0.7814\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11912 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11912/11912 [==============================] - 0s 23us/step - loss: 5.5274 - policy_loss: 4.5487 - value_loss: 0.4893 - policy_acc: 0.6957 - value_acc: 0.7403 - val_loss: 5.2360 - val_policy_loss: 4.1581 - val_value_loss: 0.5389 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11680 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11680/11680 [==============================] - 0s 24us/step - loss: 5.4051 - policy_loss: 4.4368 - value_loss: 0.4842 - policy_acc: 0.7200 - value_acc: 0.7329 - val_loss: 5.2380 - val_policy_loss: 4.1596 - val_value_loss: 0.5392 - val_policy_acc: 0.8003 - val_value_acc: 0.7831\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11818 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11818/11818 [==============================] - 0s 26us/step - loss: 5.5076 - policy_loss: 4.4566 - value_loss: 0.5255 - policy_acc: 0.7134 - value_acc: 0.7125 - val_loss: 5.2500 - val_policy_loss: 4.1620 - val_value_loss: 0.5440 - val_policy_acc: 0.8003 - val_value_acc: 0.7797\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11661 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11661/11661 [==============================] - 0s 23us/step - loss: 5.5564 - policy_loss: 4.5422 - value_loss: 0.5071 - policy_acc: 0.7065 - value_acc: 0.7280 - val_loss: 5.2561 - val_policy_loss: 4.1606 - val_value_loss: 0.5478 - val_policy_acc: 0.8003 - val_value_acc: 0.7831\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11915 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11915/11915 [==============================] - 0s 24us/step - loss: 5.4478 - policy_loss: 4.4213 - value_loss: 0.5132 - policy_acc: 0.7246 - value_acc: 0.7167 - val_loss: 5.2567 - val_policy_loss: 4.1595 - val_value_loss: 0.5486 - val_policy_acc: 0.8003 - val_value_acc: 0.7814\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11964 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11964/11964 [==============================] - 0s 23us/step - loss: 5.4215 - policy_loss: 4.4207 - value_loss: 0.5004 - policy_acc: 0.7492 - value_acc: 0.7340 - val_loss: 5.2539 - val_policy_loss: 4.1602 - val_value_loss: 0.5469 - val_policy_acc: 0.8003 - val_value_acc: 0.7814\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11955 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11955/11955 [==============================] - 0s 23us/step - loss: 5.5289 - policy_loss: 4.5069 - value_loss: 0.5110 - policy_acc: 0.7450 - value_acc: 0.7289 - val_loss: 5.2476 - val_policy_loss: 4.1626 - val_value_loss: 0.5425 - val_policy_acc: 0.8003 - val_value_acc: 0.7780\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11776 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11776/11776 [==============================] - 0s 24us/step - loss: 5.4515 - policy_loss: 4.4877 - value_loss: 0.4819 - policy_acc: 0.7428 - value_acc: 0.7484 - val_loss: 5.2433 - val_policy_loss: 4.1630 - val_value_loss: 0.5401 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11861 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11861/11861 [==============================] - 0s 24us/step - loss: 5.4692 - policy_loss: 4.4225 - value_loss: 0.5233 - policy_acc: 0.7295 - value_acc: 0.7337 - val_loss: 5.2417 - val_policy_loss: 4.1611 - val_value_loss: 0.5403 - val_policy_acc: 0.8003 - val_value_acc: 0.7229\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11831 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11831/11831 [==============================] - 0s 24us/step - loss: 5.4896 - policy_loss: 4.5046 - value_loss: 0.4925 - policy_acc: 0.7460 - value_acc: 0.7353 - val_loss: 5.2389 - val_policy_loss: 4.1586 - val_value_loss: 0.5401 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11856 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11856/11856 [==============================] - 0s 23us/step - loss: 5.5644 - policy_loss: 4.5572 - value_loss: 0.5036 - policy_acc: 0.7058 - value_acc: 0.7305 - val_loss: 5.2403 - val_policy_loss: 4.1570 - val_value_loss: 0.5417 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11719 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11719/11719 [==============================] - 0s 25us/step - loss: 5.4975 - policy_loss: 4.5081 - value_loss: 0.4947 - policy_acc: 0.7279 - value_acc: 0.7342 - val_loss: 5.2512 - val_policy_loss: 4.1588 - val_value_loss: 0.5462 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11858 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11858/11858 [==============================] - 0s 25us/step - loss: 5.5126 - policy_loss: 4.5425 - value_loss: 0.4850 - policy_acc: 0.7087 - value_acc: 0.7531 - val_loss: 5.2593 - val_policy_loss: 4.1595 - val_value_loss: 0.5499 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11859 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11859/11859 [==============================] - 0s 24us/step - loss: 5.5392 - policy_loss: 4.5339 - value_loss: 0.5027 - policy_acc: 0.7142 - value_acc: 0.7392 - val_loss: 5.2594 - val_policy_loss: 4.1592 - val_value_loss: 0.5501 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11876 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11876/11876 [==============================] - 0s 25us/step - loss: 5.4547 - policy_loss: 4.5053 - value_loss: 0.4747 - policy_acc: 0.7300 - value_acc: 0.7600 - val_loss: 5.2521 - val_policy_loss: 4.1585 - val_value_loss: 0.5468 - val_policy_acc: 0.8003 - val_value_acc: 0.7642\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11946 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11946/11946 [==============================] - 0s 23us/step - loss: 5.5057 - policy_loss: 4.4671 - value_loss: 0.5193 - policy_acc: 0.7094 - value_acc: 0.7248 - val_loss: 5.2354 - val_policy_loss: 4.1579 - val_value_loss: 0.5387 - val_policy_acc: 0.8003 - val_value_acc: 0.7745\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11922 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11922/11922 [==============================] - 0s 23us/step - loss: 5.4600 - policy_loss: 4.5347 - value_loss: 0.4626 - policy_acc: 0.7254 - value_acc: 0.7639 - val_loss: 5.2257 - val_policy_loss: 4.1607 - val_value_loss: 0.5325 - val_policy_acc: 0.8003 - val_value_acc: 0.6954\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11707 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11707/11707 [==============================] - 0s 24us/step - loss: 5.5325 - policy_loss: 4.4875 - value_loss: 0.5225 - policy_acc: 0.7267 - value_acc: 0.7301 - val_loss: 5.2361 - val_policy_loss: 4.1632 - val_value_loss: 0.5364 - val_policy_acc: 0.8003 - val_value_acc: 0.6816\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11885 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11885/11885 [==============================] - 0s 23us/step - loss: 5.5054 - policy_loss: 4.4655 - value_loss: 0.5199 - policy_acc: 0.7011 - value_acc: 0.7308 - val_loss: 5.2374 - val_policy_loss: 4.1638 - val_value_loss: 0.5368 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11814 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11814/11814 [==============================] - 0s 24us/step - loss: 5.4791 - policy_loss: 4.5017 - value_loss: 0.4887 - policy_acc: 0.7229 - value_acc: 0.7367 - val_loss: 5.2481 - val_policy_loss: 4.1630 - val_value_loss: 0.5425 - val_policy_acc: 0.8003 - val_value_acc: 0.7831\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11672 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11672/11672 [==============================] - 0s 28us/step - loss: 5.5281 - policy_loss: 4.4724 - value_loss: 0.5279 - policy_acc: 0.7144 - value_acc: 0.7309 - val_loss: 5.2477 - val_policy_loss: 4.1640 - val_value_loss: 0.5419 - val_policy_acc: 0.8003 - val_value_acc: 0.7814\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11844 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11844/11844 [==============================] - 0s 24us/step - loss: 5.5174 - policy_loss: 4.4435 - value_loss: 0.5369 - policy_acc: 0.7045 - value_acc: 0.7091 - val_loss: 5.2310 - val_policy_loss: 4.1614 - val_value_loss: 0.5348 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11876 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11876/11876 [==============================] - 0s 23us/step - loss: 5.5140 - policy_loss: 4.4679 - value_loss: 0.5231 - policy_acc: 0.7308 - value_acc: 0.7023 - val_loss: 5.2369 - val_policy_loss: 4.1604 - val_value_loss: 0.5382 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11717 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11717/11717 [==============================] - 0s 24us/step - loss: 5.3571 - policy_loss: 4.4357 - value_loss: 0.4607 - policy_acc: 0.7323 - value_acc: 0.7538 - val_loss: 5.2392 - val_policy_loss: 4.1615 - val_value_loss: 0.5389 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11589 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11589/11589 [==============================] - 0s 24us/step - loss: 5.6160 - policy_loss: 4.4836 - value_loss: 0.5662 - policy_acc: 0.7345 - value_acc: 0.6843 - val_loss: 5.2489 - val_policy_loss: 4.1617 - val_value_loss: 0.5436 - val_policy_acc: 0.8003 - val_value_acc: 0.7814\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11747 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11747/11747 [==============================] - 0s 24us/step - loss: 5.5503 - policy_loss: 4.5380 - value_loss: 0.5062 - policy_acc: 0.7094 - value_acc: 0.7346 - val_loss: 5.2532 - val_policy_loss: 4.1592 - val_value_loss: 0.5470 - val_policy_acc: 0.8003 - val_value_acc: 0.7780\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11978 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11978/11978 [==============================] - 0s 24us/step - loss: 5.4944 - policy_loss: 4.4873 - value_loss: 0.5036 - policy_acc: 0.7308 - value_acc: 0.7424 - val_loss: 5.2407 - val_policy_loss: 4.1570 - val_value_loss: 0.5418 - val_policy_acc: 0.8003 - val_value_acc: 0.7849\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11790 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11790/11790 [==============================] - 0s 24us/step - loss: 5.4061 - policy_loss: 4.4007 - value_loss: 0.5027 - policy_acc: 0.7459 - value_acc: 0.7441 - val_loss: 5.2234 - val_policy_loss: 4.1564 - val_value_loss: 0.5335 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11732 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11732/11732 [==============================] - 0s 24us/step - loss: 5.4769 - policy_loss: 4.4662 - value_loss: 0.5054 - policy_acc: 0.7301 - value_acc: 0.7305 - val_loss: 5.2172 - val_policy_loss: 4.1575 - val_value_loss: 0.5298 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11883 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11883/11883 [==============================] - 0s 25us/step - loss: 5.4533 - policy_loss: 4.4059 - value_loss: 0.5237 - policy_acc: 0.7473 - value_acc: 0.7085 - val_loss: 5.2233 - val_policy_loss: 4.1599 - val_value_loss: 0.5317 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11714 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11714/11714 [==============================] - 0s 24us/step - loss: 5.5653 - policy_loss: 4.5195 - value_loss: 0.5229 - policy_acc: 0.7029 - value_acc: 0.7132 - val_loss: 5.2310 - val_policy_loss: 4.1606 - val_value_loss: 0.5352 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11958 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11958/11958 [==============================] - 0s 23us/step - loss: 5.4315 - policy_loss: 4.3635 - value_loss: 0.5340 - policy_acc: 0.7541 - value_acc: 0.7009 - val_loss: 5.2378 - val_policy_loss: 4.1595 - val_value_loss: 0.5392 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11609 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11609/11609 [==============================] - 0s 25us/step - loss: 5.4440 - policy_loss: 4.4771 - value_loss: 0.4834 - policy_acc: 0.7287 - value_acc: 0.7585 - val_loss: 5.2395 - val_policy_loss: 4.1585 - val_value_loss: 0.5405 - val_policy_acc: 0.8003 - val_value_acc: 0.7194\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11665 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11665/11665 [==============================] - 0s 25us/step - loss: 5.4735 - policy_loss: 4.4380 - value_loss: 0.5177 - policy_acc: 0.7424 - value_acc: 0.7300 - val_loss: 5.2347 - val_policy_loss: 4.1600 - val_value_loss: 0.5374 - val_policy_acc: 0.8003 - val_value_acc: 0.7074\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11773 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11773/11773 [==============================] - 0s 24us/step - loss: 5.5903 - policy_loss: 4.5457 - value_loss: 0.5223 - policy_acc: 0.7023 - value_acc: 0.7258 - val_loss: 5.2345 - val_policy_loss: 4.1612 - val_value_loss: 0.5366 - val_policy_acc: 0.8003 - val_value_acc: 0.7315\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11927 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11927/11927 [==============================] - 0s 26us/step - loss: 5.4658 - policy_loss: 4.4673 - value_loss: 0.4992 - policy_acc: 0.7255 - value_acc: 0.7379 - val_loss: 5.2363 - val_policy_loss: 4.1600 - val_value_loss: 0.5381 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11759 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11759/11759 [==============================] - 0s 24us/step - loss: 5.4918 - policy_loss: 4.4725 - value_loss: 0.5096 - policy_acc: 0.7300 - value_acc: 0.7358 - val_loss: 5.2407 - val_policy_loss: 4.1602 - val_value_loss: 0.5403 - val_policy_acc: 0.8003 - val_value_acc: 0.6988\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11882 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11882/11882 [==============================] - 0s 24us/step - loss: 5.4242 - policy_loss: 4.4256 - value_loss: 0.4993 - policy_acc: 0.7304 - value_acc: 0.7274 - val_loss: 5.2402 - val_policy_loss: 4.1609 - val_value_loss: 0.5396 - val_policy_acc: 0.8003 - val_value_acc: 0.6816\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11708 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11708/11708 [==============================] - 0s 25us/step - loss: 5.4089 - policy_loss: 4.4473 - value_loss: 0.4808 - policy_acc: 0.7073 - value_acc: 0.7419 - val_loss: 5.2355 - val_policy_loss: 4.1600 - val_value_loss: 0.5377 - val_policy_acc: 0.8003 - val_value_acc: 0.6919\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11729 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11729/11729 [==============================] - 0s 26us/step - loss: 5.4336 - policy_loss: 4.4250 - value_loss: 0.5043 - policy_acc: 0.7419 - value_acc: 0.7383 - val_loss: 5.2289 - val_policy_loss: 4.1587 - val_value_loss: 0.5351 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11900 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11900/11900 [==============================] - 0s 24us/step - loss: 5.5395 - policy_loss: 4.4953 - value_loss: 0.5221 - policy_acc: 0.7250 - value_acc: 0.7288 - val_loss: 5.2366 - val_policy_loss: 4.1606 - val_value_loss: 0.5380 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11887 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11887/11887 [==============================] - 0s 24us/step - loss: 5.6051 - policy_loss: 4.5168 - value_loss: 0.5442 - policy_acc: 0.7054 - value_acc: 0.6972 - val_loss: 5.2494 - val_policy_loss: 4.1582 - val_value_loss: 0.5456 - val_policy_acc: 0.8003 - val_value_acc: 0.7022\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11865 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11865/11865 [==============================] - 0s 24us/step - loss: 5.5199 - policy_loss: 4.4712 - value_loss: 0.5243 - policy_acc: 0.7231 - value_acc: 0.7115 - val_loss: 5.2562 - val_policy_loss: 4.1570 - val_value_loss: 0.5496 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11793 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11793/11793 [==============================] - 0s 24us/step - loss: 5.5723 - policy_loss: 4.5090 - value_loss: 0.5317 - policy_acc: 0.7231 - value_acc: 0.7091 - val_loss: 5.2668 - val_policy_loss: 4.1586 - val_value_loss: 0.5541 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11778 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11778/11778 [==============================] - 0s 24us/step - loss: 5.5533 - policy_loss: 4.4763 - value_loss: 0.5385 - policy_acc: 0.7206 - value_acc: 0.7193 - val_loss: 5.2708 - val_policy_loss: 4.1588 - val_value_loss: 0.5560 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11914 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11914/11914 [==============================] - 0s 24us/step - loss: 5.5509 - policy_loss: 4.5502 - value_loss: 0.5004 - policy_acc: 0.7156 - value_acc: 0.7441 - val_loss: 5.2656 - val_policy_loss: 4.1594 - val_value_loss: 0.5531 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11723 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11723/11723 [==============================] - 0s 24us/step - loss: 5.4583 - policy_loss: 4.4513 - value_loss: 0.5035 - policy_acc: 0.7398 - value_acc: 0.7258 - val_loss: 5.2471 - val_policy_loss: 4.1603 - val_value_loss: 0.5434 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11828 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11828/11828 [==============================] - 0s 25us/step - loss: 5.5587 - policy_loss: 4.5289 - value_loss: 0.5149 - policy_acc: 0.7165 - value_acc: 0.7286 - val_loss: 5.2349 - val_policy_loss: 4.1607 - val_value_loss: 0.5371 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11820 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11820/11820 [==============================] - 0s 25us/step - loss: 5.5119 - policy_loss: 4.5079 - value_loss: 0.5020 - policy_acc: 0.7087 - value_acc: 0.7325 - val_loss: 5.2382 - val_policy_loss: 4.1594 - val_value_loss: 0.5394 - val_policy_acc: 0.8003 - val_value_acc: 0.7057\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11956 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11956/11956 [==============================] - 0s 24us/step - loss: 5.5117 - policy_loss: 4.4259 - value_loss: 0.5429 - policy_acc: 0.7313 - value_acc: 0.7079 - val_loss: 5.2517 - val_policy_loss: 4.1583 - val_value_loss: 0.5467 - val_policy_acc: 0.8003 - val_value_acc: 0.6902\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11770 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11770/11770 [==============================] - 0s 24us/step - loss: 5.3884 - policy_loss: 4.3638 - value_loss: 0.5123 - policy_acc: 0.7526 - value_acc: 0.7262 - val_loss: 5.2641 - val_policy_loss: 4.1590 - val_value_loss: 0.5526 - val_policy_acc: 0.8003 - val_value_acc: 0.6919\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11688 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11688/11688 [==============================] - 0s 24us/step - loss: 5.5072 - policy_loss: 4.4658 - value_loss: 0.5207 - policy_acc: 0.7178 - value_acc: 0.7218 - val_loss: 5.2682 - val_policy_loss: 4.1573 - val_value_loss: 0.5555 - val_policy_acc: 0.8003 - val_value_acc: 0.7091\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11845 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11845/11845 [==============================] - 0s 24us/step - loss: 5.4199 - policy_loss: 4.4617 - value_loss: 0.4791 - policy_acc: 0.7618 - value_acc: 0.7570 - val_loss: 5.2607 - val_policy_loss: 4.1590 - val_value_loss: 0.5509 - val_policy_acc: 0.8003 - val_value_acc: 0.7091\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11924 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11924/11924 [==============================] - 0s 26us/step - loss: 5.6433 - policy_loss: 4.5972 - value_loss: 0.5231 - policy_acc: 0.7103 - value_acc: 0.7154 - val_loss: 5.2496 - val_policy_loss: 4.1610 - val_value_loss: 0.5443 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11878 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11878/11878 [==============================] - 0s 25us/step - loss: 5.4411 - policy_loss: 4.4151 - value_loss: 0.5130 - policy_acc: 0.7348 - value_acc: 0.7258 - val_loss: 5.2479 - val_policy_loss: 4.1602 - val_value_loss: 0.5438 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11822 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11822/11822 [==============================] - 0s 24us/step - loss: 5.5331 - policy_loss: 4.4975 - value_loss: 0.5178 - policy_acc: 0.7264 - value_acc: 0.7224 - val_loss: 5.2468 - val_policy_loss: 4.1612 - val_value_loss: 0.5428 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11954 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11954/11954 [==============================] - 0s 24us/step - loss: 5.5305 - policy_loss: 4.5214 - value_loss: 0.5045 - policy_acc: 0.7095 - value_acc: 0.7332 - val_loss: 5.2461 - val_policy_loss: 4.1625 - val_value_loss: 0.5418 - val_policy_acc: 0.8003 - val_value_acc: 0.7177\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11826 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11826/11826 [==============================] - 0s 24us/step - loss: 5.5475 - policy_loss: 4.5205 - value_loss: 0.5135 - policy_acc: 0.7329 - value_acc: 0.7154 - val_loss: 5.2413 - val_policy_loss: 4.1598 - val_value_loss: 0.5407 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11849 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11849/11849 [==============================] - 0s 24us/step - loss: 5.4673 - policy_loss: 4.4854 - value_loss: 0.4909 - policy_acc: 0.7144 - value_acc: 0.7405 - val_loss: 5.2357 - val_policy_loss: 4.1575 - val_value_loss: 0.5391 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11851 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11851/11851 [==============================] - 0s 24us/step - loss: 5.4775 - policy_loss: 4.5139 - value_loss: 0.4818 - policy_acc: 0.7129 - value_acc: 0.7501 - val_loss: 5.2335 - val_policy_loss: 4.1611 - val_value_loss: 0.5362 - val_policy_acc: 0.8003 - val_value_acc: 0.7315\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11935 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11935/11935 [==============================] - 0s 23us/step - loss: 5.4656 - policy_loss: 4.4437 - value_loss: 0.5110 - policy_acc: 0.7438 - value_acc: 0.7287 - val_loss: 5.2373 - val_policy_loss: 4.1644 - val_value_loss: 0.5364 - val_policy_acc: 0.7969 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11675 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11675/11675 [==============================] - 0s 24us/step - loss: 5.5697 - policy_loss: 4.4868 - value_loss: 0.5414 - policy_acc: 0.7248 - value_acc: 0.6976 - val_loss: 5.2450 - val_policy_loss: 4.1607 - val_value_loss: 0.5422 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11898 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11898/11898 [==============================] - 0s 24us/step - loss: 5.5331 - policy_loss: 4.5184 - value_loss: 0.5073 - policy_acc: 0.7300 - value_acc: 0.7310 - val_loss: 5.2569 - val_policy_loss: 4.1603 - val_value_loss: 0.5483 - val_policy_acc: 0.8003 - val_value_acc: 0.7642\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11889 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11889/11889 [==============================] - 0s 24us/step - loss: 5.5087 - policy_loss: 4.4657 - value_loss: 0.5215 - policy_acc: 0.6966 - value_acc: 0.7225 - val_loss: 5.2621 - val_policy_loss: 4.1586 - val_value_loss: 0.5518 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11698 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11698/11698 [==============================] - 0s 24us/step - loss: 5.5071 - policy_loss: 4.4879 - value_loss: 0.5096 - policy_acc: 0.6988 - value_acc: 0.7290 - val_loss: 5.2628 - val_policy_loss: 4.1588 - val_value_loss: 0.5520 - val_policy_acc: 0.8003 - val_value_acc: 0.6954\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11797 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11797/11797 [==============================] - 0s 24us/step - loss: 5.4544 - policy_loss: 4.4542 - value_loss: 0.5001 - policy_acc: 0.7287 - value_acc: 0.7341 - val_loss: 5.2597 - val_policy_loss: 4.1609 - val_value_loss: 0.5494 - val_policy_acc: 0.8003 - val_value_acc: 0.6954\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11715 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11715/11715 [==============================] - 0s 24us/step - loss: 5.5426 - policy_loss: 4.5272 - value_loss: 0.5077 - policy_acc: 0.7147 - value_acc: 0.7295 - val_loss: 5.2541 - val_policy_loss: 4.1603 - val_value_loss: 0.5469 - val_policy_acc: 0.8003 - val_value_acc: 0.6833\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11862 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11862/11862 [==============================] - 0s 23us/step - loss: 5.5169 - policy_loss: 4.4688 - value_loss: 0.5241 - policy_acc: 0.7201 - value_acc: 0.7278 - val_loss: 5.2500 - val_policy_loss: 4.1581 - val_value_loss: 0.5459 - val_policy_acc: 0.8003 - val_value_acc: 0.6764\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11791 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11791/11791 [==============================] - 0s 23us/step - loss: 5.4844 - policy_loss: 4.4870 - value_loss: 0.4987 - policy_acc: 0.7309 - value_acc: 0.7324 - val_loss: 5.2477 - val_policy_loss: 4.1592 - val_value_loss: 0.5442 - val_policy_acc: 0.8003 - val_value_acc: 0.6988\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11718 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11718/11718 [==============================] - 0s 23us/step - loss: 5.4621 - policy_loss: 4.4596 - value_loss: 0.5012 - policy_acc: 0.7396 - value_acc: 0.7367 - val_loss: 5.2499 - val_policy_loss: 4.1601 - val_value_loss: 0.5449 - val_policy_acc: 0.8003 - val_value_acc: 0.6833\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11867 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11867/11867 [==============================] - 0s 24us/step - loss: 5.3453 - policy_loss: 4.3875 - value_loss: 0.4789 - policy_acc: 0.7437 - value_acc: 0.7474 - val_loss: 5.2504 - val_policy_loss: 4.1597 - val_value_loss: 0.5454 - val_policy_acc: 0.8003 - val_value_acc: 0.6747\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11672 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11672/11672 [==============================] - 0s 24us/step - loss: 5.4585 - policy_loss: 4.4616 - value_loss: 0.4984 - policy_acc: 0.7168 - value_acc: 0.7375 - val_loss: 5.2488 - val_policy_loss: 4.1617 - val_value_loss: 0.5436 - val_policy_acc: 0.8003 - val_value_acc: 0.6747\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11884 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11884/11884 [==============================] - 0s 23us/step - loss: 5.4806 - policy_loss: 4.4099 - value_loss: 0.5354 - policy_acc: 0.7345 - value_acc: 0.7077 - val_loss: 5.2488 - val_policy_loss: 4.1609 - val_value_loss: 0.5439 - val_policy_acc: 0.8003 - val_value_acc: 0.7091\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11728 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11728/11728 [==============================] - 0s 24us/step - loss: 5.5014 - policy_loss: 4.4893 - value_loss: 0.5060 - policy_acc: 0.7296 - value_acc: 0.7325 - val_loss: 5.2521 - val_policy_loss: 4.1600 - val_value_loss: 0.5460 - val_policy_acc: 0.8003 - val_value_acc: 0.7315\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11830 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11830/11830 [==============================] - 0s 27us/step - loss: 5.5037 - policy_loss: 4.5088 - value_loss: 0.4975 - policy_acc: 0.6900 - value_acc: 0.7347 - val_loss: 5.2560 - val_policy_loss: 4.1612 - val_value_loss: 0.5474 - val_policy_acc: 0.8003 - val_value_acc: 0.6867\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11788 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11788/11788 [==============================] - 0s 23us/step - loss: 5.4701 - policy_loss: 4.4283 - value_loss: 0.5209 - policy_acc: 0.7408 - value_acc: 0.7212 - val_loss: 5.2604 - val_policy_loss: 4.1630 - val_value_loss: 0.5487 - val_policy_acc: 0.8003 - val_value_acc: 0.6885\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11783 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11783/11783 [==============================] - 0s 23us/step - loss: 5.5123 - policy_loss: 4.4461 - value_loss: 0.5331 - policy_acc: 0.7442 - value_acc: 0.7120 - val_loss: 5.2594 - val_policy_loss: 4.1605 - val_value_loss: 0.5494 - val_policy_acc: 0.8003 - val_value_acc: 0.6919\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11869 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11869/11869 [==============================] - 0s 24us/step - loss: 5.4474 - policy_loss: 4.4665 - value_loss: 0.4905 - policy_acc: 0.7360 - value_acc: 0.7397 - val_loss: 5.2567 - val_policy_loss: 4.1583 - val_value_loss: 0.5492 - val_policy_acc: 0.8003 - val_value_acc: 0.7074\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11942 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11942/11942 [==============================] - 0s 24us/step - loss: 5.4722 - policy_loss: 4.4850 - value_loss: 0.4936 - policy_acc: 0.7262 - value_acc: 0.7386 - val_loss: 5.2535 - val_policy_loss: 4.1608 - val_value_loss: 0.5464 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11891 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11891/11891 [==============================] - 0s 24us/step - loss: 5.5399 - policy_loss: 4.5237 - value_loss: 0.5081 - policy_acc: 0.7219 - value_acc: 0.7303 - val_loss: 5.2500 - val_policy_loss: 4.1624 - val_value_loss: 0.5438 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11480 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11480/11480 [==============================] - 0s 24us/step - loss: 5.5479 - policy_loss: 4.5039 - value_loss: 0.5220 - policy_acc: 0.7297 - value_acc: 0.7209 - val_loss: 5.2506 - val_policy_loss: 4.1608 - val_value_loss: 0.5449 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11806 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11806/11806 [==============================] - 0s 23us/step - loss: 5.4511 - policy_loss: 4.4878 - value_loss: 0.4816 - policy_acc: 0.7242 - value_acc: 0.7495 - val_loss: 5.2501 - val_policy_loss: 4.1596 - val_value_loss: 0.5453 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11718 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11718/11718 [==============================] - 0s 25us/step - loss: 5.5904 - policy_loss: 4.5173 - value_loss: 0.5365 - policy_acc: 0.7171 - value_acc: 0.7015 - val_loss: 5.2573 - val_policy_loss: 4.1646 - val_value_loss: 0.5463 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11894 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11894/11894 [==============================] - 0s 24us/step - loss: 5.5685 - policy_loss: 4.5328 - value_loss: 0.5178 - policy_acc: 0.7007 - value_acc: 0.7120 - val_loss: 5.2630 - val_policy_loss: 4.1625 - val_value_loss: 0.5503 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11747 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11747/11747 [==============================] - 0s 24us/step - loss: 5.5569 - policy_loss: 4.5598 - value_loss: 0.4986 - policy_acc: 0.7252 - value_acc: 0.7421 - val_loss: 5.2611 - val_policy_loss: 4.1614 - val_value_loss: 0.5498 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11904 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11904/11904 [==============================] - 0s 29us/step - loss: 5.5198 - policy_loss: 4.4453 - value_loss: 0.5373 - policy_acc: 0.7337 - value_acc: 0.7050 - val_loss: 5.2578 - val_policy_loss: 4.1596 - val_value_loss: 0.5491 - val_policy_acc: 0.8003 - val_value_acc: 0.7126\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11838 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11838/11838 [==============================] - 0s 23us/step - loss: 5.6444 - policy_loss: 4.5285 - value_loss: 0.5580 - policy_acc: 0.7046 - value_acc: 0.7038 - val_loss: 5.2705 - val_policy_loss: 4.1595 - val_value_loss: 0.5555 - val_policy_acc: 0.8003 - val_value_acc: 0.6627\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11673 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11673/11673 [==============================] - 0s 23us/step - loss: 5.3681 - policy_loss: 4.4091 - value_loss: 0.4795 - policy_acc: 0.7490 - value_acc: 0.7505 - val_loss: 5.2741 - val_policy_loss: 4.1610 - val_value_loss: 0.5566 - val_policy_acc: 0.8003 - val_value_acc: 0.6644\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11808 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11808/11808 [==============================] - 0s 25us/step - loss: 5.5561 - policy_loss: 4.4738 - value_loss: 0.5411 - policy_acc: 0.7336 - value_acc: 0.6943 - val_loss: 5.2699 - val_policy_loss: 4.1631 - val_value_loss: 0.5534 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11812 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11812/11812 [==============================] - 0s 25us/step - loss: 5.5201 - policy_loss: 4.5216 - value_loss: 0.4992 - policy_acc: 0.7345 - value_acc: 0.7374 - val_loss: 5.2685 - val_policy_loss: 4.1663 - val_value_loss: 0.5511 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11855 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11855/11855 [==============================] - 0s 23us/step - loss: 5.4789 - policy_loss: 4.4944 - value_loss: 0.4922 - policy_acc: 0.7139 - value_acc: 0.7571 - val_loss: 5.2540 - val_policy_loss: 4.1621 - val_value_loss: 0.5460 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11909 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11909/11909 [==============================] - 0s 24us/step - loss: 5.5096 - policy_loss: 4.5256 - value_loss: 0.4920 - policy_acc: 0.7161 - value_acc: 0.7464 - val_loss: 5.2363 - val_policy_loss: 4.1605 - val_value_loss: 0.5379 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11695 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11695/11695 [==============================] - 0s 25us/step - loss: 5.4970 - policy_loss: 4.4682 - value_loss: 0.5144 - policy_acc: 0.7395 - value_acc: 0.7316 - val_loss: 5.2227 - val_policy_loss: 4.1621 - val_value_loss: 0.5303 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11710 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11710/11710 [==============================] - 0s 23us/step - loss: 5.5261 - policy_loss: 4.5429 - value_loss: 0.4916 - policy_acc: 0.7178 - value_acc: 0.7389 - val_loss: 5.2143 - val_policy_loss: 4.1593 - val_value_loss: 0.5275 - val_policy_acc: 0.8003 - val_value_acc: 0.7797\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11806 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11806/11806 [==============================] - 0s 25us/step - loss: 5.5024 - policy_loss: 4.4948 - value_loss: 0.5038 - policy_acc: 0.7162 - value_acc: 0.7329 - val_loss: 5.2167 - val_policy_loss: 4.1587 - val_value_loss: 0.5290 - val_policy_acc: 0.8003 - val_value_acc: 0.7780\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11768 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11768/11768 [==============================] - 0s 24us/step - loss: 5.3267 - policy_loss: 4.3805 - value_loss: 0.4731 - policy_acc: 0.7503 - value_acc: 0.7611 - val_loss: 5.2158 - val_policy_loss: 4.1609 - val_value_loss: 0.5274 - val_policy_acc: 0.8003 - val_value_acc: 0.7831\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11874 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11874/11874 [==============================] - 0s 23us/step - loss: 5.6510 - policy_loss: 4.5802 - value_loss: 0.5354 - policy_acc: 0.7009 - value_acc: 0.7062 - val_loss: 5.2209 - val_policy_loss: 4.1630 - val_value_loss: 0.5290 - val_policy_acc: 0.8003 - val_value_acc: 0.7745\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11894 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11894/11894 [==============================] - 0s 24us/step - loss: 5.5117 - policy_loss: 4.5387 - value_loss: 0.4865 - policy_acc: 0.6764 - value_acc: 0.7432 - val_loss: 5.2335 - val_policy_loss: 4.1632 - val_value_loss: 0.5351 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11887 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11887/11887 [==============================] - 0s 24us/step - loss: 5.5375 - policy_loss: 4.5596 - value_loss: 0.4890 - policy_acc: 0.7008 - value_acc: 0.7434 - val_loss: 5.2408 - val_policy_loss: 4.1637 - val_value_loss: 0.5386 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11842 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11842/11842 [==============================] - 0s 24us/step - loss: 5.5761 - policy_loss: 4.5246 - value_loss: 0.5258 - policy_acc: 0.6952 - value_acc: 0.7157 - val_loss: 5.2468 - val_policy_loss: 4.1638 - val_value_loss: 0.5415 - val_policy_acc: 0.8003 - val_value_acc: 0.7728\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11762 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11762/11762 [==============================] - 0s 23us/step - loss: 5.4607 - policy_loss: 4.4504 - value_loss: 0.5052 - policy_acc: 0.7195 - value_acc: 0.7334 - val_loss: 5.2415 - val_policy_loss: 4.1603 - val_value_loss: 0.5406 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11830 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11830/11830 [==============================] - 0s 25us/step - loss: 5.4686 - policy_loss: 4.4164 - value_loss: 0.5261 - policy_acc: 0.7676 - value_acc: 0.7199 - val_loss: 5.2417 - val_policy_loss: 4.1614 - val_value_loss: 0.5401 - val_policy_acc: 0.8003 - val_value_acc: 0.6919\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11821 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11821/11821 [==============================] - 0s 23us/step - loss: 5.4610 - policy_loss: 4.4880 - value_loss: 0.4865 - policy_acc: 0.7215 - value_acc: 0.7459 - val_loss: 5.2407 - val_policy_loss: 4.1610 - val_value_loss: 0.5399 - val_policy_acc: 0.8003 - val_value_acc: 0.6885\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11842 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11842/11842 [==============================] - 0s 24us/step - loss: 5.5099 - policy_loss: 4.4989 - value_loss: 0.5055 - policy_acc: 0.7300 - value_acc: 0.7311 - val_loss: 5.2366 - val_policy_loss: 4.1610 - val_value_loss: 0.5378 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11962 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11962/11962 [==============================] - 0s 23us/step - loss: 5.4958 - policy_loss: 4.5048 - value_loss: 0.4955 - policy_acc: 0.7256 - value_acc: 0.7271 - val_loss: 5.2489 - val_policy_loss: 4.1629 - val_value_loss: 0.5430 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11872 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11872/11872 [==============================] - 0s 24us/step - loss: 5.6088 - policy_loss: 4.5538 - value_loss: 0.5275 - policy_acc: 0.7003 - value_acc: 0.7212 - val_loss: 5.2570 - val_policy_loss: 4.1636 - val_value_loss: 0.5467 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11699 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11699/11699 [==============================] - 0s 23us/step - loss: 5.5564 - policy_loss: 4.4978 - value_loss: 0.5293 - policy_acc: 0.7097 - value_acc: 0.7121 - val_loss: 5.2500 - val_policy_loss: 4.1605 - val_value_loss: 0.5448 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11774 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11774/11774 [==============================] - 0s 23us/step - loss: 5.4673 - policy_loss: 4.4575 - value_loss: 0.5049 - policy_acc: 0.7465 - value_acc: 0.7299 - val_loss: 5.2501 - val_policy_loss: 4.1603 - val_value_loss: 0.5449 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11905 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11905/11905 [==============================] - 0s 25us/step - loss: 5.6061 - policy_loss: 4.5801 - value_loss: 0.5130 - policy_acc: 0.7065 - value_acc: 0.7220 - val_loss: 5.2498 - val_policy_loss: 4.1610 - val_value_loss: 0.5444 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11717 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11717/11717 [==============================] - 0s 23us/step - loss: 5.5362 - policy_loss: 4.5389 - value_loss: 0.4986 - policy_acc: 0.7099 - value_acc: 0.7481 - val_loss: 5.2467 - val_policy_loss: 4.1601 - val_value_loss: 0.5433 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11843 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11843/11843 [==============================] - 0s 24us/step - loss: 5.6025 - policy_loss: 4.5916 - value_loss: 0.5055 - policy_acc: 0.7165 - value_acc: 0.7301 - val_loss: 5.2458 - val_policy_loss: 4.1609 - val_value_loss: 0.5425 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11710 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11710/11710 [==============================] - 0s 24us/step - loss: 5.4994 - policy_loss: 4.5568 - value_loss: 0.4713 - policy_acc: 0.7236 - value_acc: 0.7575 - val_loss: 5.2379 - val_policy_loss: 4.1606 - val_value_loss: 0.5387 - val_policy_acc: 0.8003 - val_value_acc: 0.7229\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11864 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11864/11864 [==============================] - 0s 24us/step - loss: 5.5489 - policy_loss: 4.4543 - value_loss: 0.5473 - policy_acc: 0.7312 - value_acc: 0.7011 - val_loss: 5.2326 - val_policy_loss: 4.1600 - val_value_loss: 0.5363 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11794 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11794/11794 [==============================] - 0s 23us/step - loss: 5.5263 - policy_loss: 4.5022 - value_loss: 0.5121 - policy_acc: 0.7260 - value_acc: 0.7376 - val_loss: 5.2315 - val_policy_loss: 4.1611 - val_value_loss: 0.5352 - val_policy_acc: 0.8003 - val_value_acc: 0.7728\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11580 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11580/11580 [==============================] - 0s 23us/step - loss: 5.4537 - policy_loss: 4.4404 - value_loss: 0.5067 - policy_acc: 0.7320 - value_acc: 0.7281 - val_loss: 5.2227 - val_policy_loss: 4.1587 - val_value_loss: 0.5320 - val_policy_acc: 0.8003 - val_value_acc: 0.7780\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11868 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11868/11868 [==============================] - 0s 24us/step - loss: 5.6621 - policy_loss: 4.5927 - value_loss: 0.5347 - policy_acc: 0.6990 - value_acc: 0.6977 - val_loss: 5.2247 - val_policy_loss: 4.1589 - val_value_loss: 0.5329 - val_policy_acc: 0.8003 - val_value_acc: 0.7883\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11773 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11773/11773 [==============================] - 0s 24us/step - loss: 5.3667 - policy_loss: 4.3921 - value_loss: 0.4873 - policy_acc: 0.7478 - value_acc: 0.7516 - val_loss: 5.2266 - val_policy_loss: 4.1593 - val_value_loss: 0.5337 - val_policy_acc: 0.8003 - val_value_acc: 0.7780\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11884 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11884/11884 [==============================] - 0s 24us/step - loss: 5.4620 - policy_loss: 4.4948 - value_loss: 0.4836 - policy_acc: 0.7325 - value_acc: 0.7410 - val_loss: 5.2286 - val_policy_loss: 4.1633 - val_value_loss: 0.5327 - val_policy_acc: 0.8003 - val_value_acc: 0.7814\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11812 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11812/11812 [==============================] - 0s 25us/step - loss: 5.3603 - policy_loss: 4.3807 - value_loss: 0.4898 - policy_acc: 0.7470 - value_acc: 0.7473 - val_loss: 5.2218 - val_policy_loss: 4.1661 - val_value_loss: 0.5279 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11921 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11921/11921 [==============================] - 0s 24us/step - loss: 5.6446 - policy_loss: 4.5733 - value_loss: 0.5356 - policy_acc: 0.6696 - value_acc: 0.7120 - val_loss: 5.2242 - val_policy_loss: 4.1628 - val_value_loss: 0.5307 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11872 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11872/11872 [==============================] - 0s 24us/step - loss: 5.5075 - policy_loss: 4.5316 - value_loss: 0.4879 - policy_acc: 0.7127 - value_acc: 0.7509 - val_loss: 5.2284 - val_policy_loss: 4.1589 - val_value_loss: 0.5347 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11942 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11942/11942 [==============================] - 0s 23us/step - loss: 5.5548 - policy_loss: 4.5342 - value_loss: 0.5103 - policy_acc: 0.7362 - value_acc: 0.7327 - val_loss: 5.2383 - val_policy_loss: 4.1614 - val_value_loss: 0.5384 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11783 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11783/11783 [==============================] - 0s 24us/step - loss: 5.5122 - policy_loss: 4.4504 - value_loss: 0.5309 - policy_acc: 0.7279 - value_acc: 0.7161 - val_loss: 5.2441 - val_policy_loss: 4.1618 - val_value_loss: 0.5412 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11852 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11852/11852 [==============================] - 0s 24us/step - loss: 5.5340 - policy_loss: 4.5439 - value_loss: 0.4950 - policy_acc: 0.7234 - value_acc: 0.7374 - val_loss: 5.2429 - val_policy_loss: 4.1614 - val_value_loss: 0.5408 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11849 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11849/11849 [==============================] - 0s 24us/step - loss: 5.4829 - policy_loss: 4.4826 - value_loss: 0.5001 - policy_acc: 0.7450 - value_acc: 0.7290 - val_loss: 5.2398 - val_policy_loss: 4.1600 - val_value_loss: 0.5399 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11776 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11776/11776 [==============================] - 0s 23us/step - loss: 5.3979 - policy_loss: 4.4644 - value_loss: 0.4668 - policy_acc: 0.7238 - value_acc: 0.7605 - val_loss: 5.2271 - val_policy_loss: 4.1595 - val_value_loss: 0.5338 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11871 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11871/11871 [==============================] - 0s 23us/step - loss: 5.5238 - policy_loss: 4.5124 - value_loss: 0.5057 - policy_acc: 0.7195 - value_acc: 0.7322 - val_loss: 5.2153 - val_policy_loss: 4.1604 - val_value_loss: 0.5275 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11910 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11910/11910 [==============================] - 0s 25us/step - loss: 5.5623 - policy_loss: 4.5215 - value_loss: 0.5204 - policy_acc: 0.7154 - value_acc: 0.7156 - val_loss: 5.2200 - val_policy_loss: 4.1628 - val_value_loss: 0.5286 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11828 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11828/11828 [==============================] - 0s 24us/step - loss: 5.4986 - policy_loss: 4.4905 - value_loss: 0.5040 - policy_acc: 0.7365 - value_acc: 0.7355 - val_loss: 5.2263 - val_policy_loss: 4.1618 - val_value_loss: 0.5322 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11742 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11742/11742 [==============================] - 0s 24us/step - loss: 5.4114 - policy_loss: 4.4187 - value_loss: 0.4964 - policy_acc: 0.7266 - value_acc: 0.7422 - val_loss: 5.2320 - val_policy_loss: 4.1592 - val_value_loss: 0.5364 - val_policy_acc: 0.8003 - val_value_acc: 0.7298\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11786 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11786/11786 [==============================] - 0s 24us/step - loss: 5.4794 - policy_loss: 4.5582 - value_loss: 0.4606 - policy_acc: 0.6931 - value_acc: 0.7685 - val_loss: 5.2354 - val_policy_loss: 4.1586 - val_value_loss: 0.5384 - val_policy_acc: 0.8003 - val_value_acc: 0.6885\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11866 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11866/11866 [==============================] - 0s 23us/step - loss: 5.4900 - policy_loss: 4.4501 - value_loss: 0.5200 - policy_acc: 0.7649 - value_acc: 0.7247 - val_loss: 5.2345 - val_policy_loss: 4.1600 - val_value_loss: 0.5373 - val_policy_acc: 0.8003 - val_value_acc: 0.6954\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11867 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11867/11867 [==============================] - 0s 24us/step - loss: 5.4738 - policy_loss: 4.4846 - value_loss: 0.4946 - policy_acc: 0.7109 - value_acc: 0.7300 - val_loss: 5.2433 - val_policy_loss: 4.1605 - val_value_loss: 0.5414 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11783 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11783/11783 [==============================] - 0s 24us/step - loss: 5.5176 - policy_loss: 4.4885 - value_loss: 0.5146 - policy_acc: 0.7227 - value_acc: 0.7176 - val_loss: 5.2520 - val_policy_loss: 4.1609 - val_value_loss: 0.5455 - val_policy_acc: 0.8003 - val_value_acc: 0.6936\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11844 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11844/11844 [==============================] - 0s 23us/step - loss: 5.5128 - policy_loss: 4.4315 - value_loss: 0.5407 - policy_acc: 0.7292 - value_acc: 0.7063 - val_loss: 5.2578 - val_policy_loss: 4.1590 - val_value_loss: 0.5494 - val_policy_acc: 0.8003 - val_value_acc: 0.6867\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11796 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11796/11796 [==============================] - 0s 24us/step - loss: 5.5063 - policy_loss: 4.4768 - value_loss: 0.5148 - policy_acc: 0.7285 - value_acc: 0.7267 - val_loss: 5.2615 - val_policy_loss: 4.1586 - val_value_loss: 0.5514 - val_policy_acc: 0.8003 - val_value_acc: 0.6988\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11815 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11815/11815 [==============================] - 0s 23us/step - loss: 5.5765 - policy_loss: 4.5145 - value_loss: 0.5310 - policy_acc: 0.6971 - value_acc: 0.7145 - val_loss: 5.2631 - val_policy_loss: 4.1594 - val_value_loss: 0.5518 - val_policy_acc: 0.8003 - val_value_acc: 0.7177\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11751 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11751/11751 [==============================] - 0s 23us/step - loss: 5.6012 - policy_loss: 4.5350 - value_loss: 0.5331 - policy_acc: 0.7291 - value_acc: 0.7151 - val_loss: 5.2653 - val_policy_loss: 4.1609 - val_value_loss: 0.5522 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11879 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11879/11879 [==============================] - 0s 24us/step - loss: 5.5785 - policy_loss: 4.5635 - value_loss: 0.5075 - policy_acc: 0.6844 - value_acc: 0.7346 - val_loss: 5.2658 - val_policy_loss: 4.1607 - val_value_loss: 0.5526 - val_policy_acc: 0.8003 - val_value_acc: 0.7298\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11838 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11838/11838 [==============================] - 0s 25us/step - loss: 5.4382 - policy_loss: 4.4657 - value_loss: 0.4862 - policy_acc: 0.7269 - value_acc: 0.7517 - val_loss: 5.2580 - val_policy_loss: 4.1608 - val_value_loss: 0.5486 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11954 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11954/11954 [==============================] - 0s 23us/step - loss: 5.5775 - policy_loss: 4.5673 - value_loss: 0.5051 - policy_acc: 0.7070 - value_acc: 0.7222 - val_loss: 5.2488 - val_policy_loss: 4.1590 - val_value_loss: 0.5449 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11825 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11825/11825 [==============================] - 0s 23us/step - loss: 5.5315 - policy_loss: 4.4906 - value_loss: 0.5204 - policy_acc: 0.7230 - value_acc: 0.7238 - val_loss: 5.2445 - val_policy_loss: 4.1571 - val_value_loss: 0.5437 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11848 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11848/11848 [==============================] - 0s 24us/step - loss: 5.5431 - policy_loss: 4.5624 - value_loss: 0.4904 - policy_acc: 0.7220 - value_acc: 0.7491 - val_loss: 5.2390 - val_policy_loss: 4.1607 - val_value_loss: 0.5391 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11814 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11814/11814 [==============================] - 0s 23us/step - loss: 5.4352 - policy_loss: 4.4486 - value_loss: 0.4933 - policy_acc: 0.7442 - value_acc: 0.7392 - val_loss: 5.2315 - val_policy_loss: 4.1608 - val_value_loss: 0.5354 - val_policy_acc: 0.8003 - val_value_acc: 0.6730\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11880 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11880/11880 [==============================] - 0s 23us/step - loss: 5.4807 - policy_loss: 4.4778 - value_loss: 0.5015 - policy_acc: 0.7338 - value_acc: 0.7231 - val_loss: 5.2243 - val_policy_loss: 4.1599 - val_value_loss: 0.5322 - val_policy_acc: 0.8003 - val_value_acc: 0.6833\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11821 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11821/11821 [==============================] - 0s 26us/step - loss: 5.5530 - policy_loss: 4.5742 - value_loss: 0.4894 - policy_acc: 0.7246 - value_acc: 0.7403 - val_loss: 5.2233 - val_policy_loss: 4.1575 - val_value_loss: 0.5329 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11823 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11823/11823 [==============================] - 0s 23us/step - loss: 5.5011 - policy_loss: 4.4626 - value_loss: 0.5193 - policy_acc: 0.7205 - value_acc: 0.7345 - val_loss: 5.2376 - val_policy_loss: 4.1555 - val_value_loss: 0.5410 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11857 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11857/11857 [==============================] - 0s 22us/step - loss: 5.5097 - policy_loss: 4.4771 - value_loss: 0.5163 - policy_acc: 0.7036 - value_acc: 0.7294 - val_loss: 5.2516 - val_policy_loss: 4.1562 - val_value_loss: 0.5477 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11820 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11820/11820 [==============================] - 0s 24us/step - loss: 5.4444 - policy_loss: 4.4221 - value_loss: 0.5112 - policy_acc: 0.7242 - value_acc: 0.7269 - val_loss: 5.2604 - val_policy_loss: 4.1607 - val_value_loss: 0.5499 - val_policy_acc: 0.8003 - val_value_acc: 0.6954\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11874 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11874/11874 [==============================] - 0s 24us/step - loss: 5.4504 - policy_loss: 4.4800 - value_loss: 0.4852 - policy_acc: 0.6998 - value_acc: 0.7451 - val_loss: 5.2570 - val_policy_loss: 4.1607 - val_value_loss: 0.5481 - val_policy_acc: 0.8003 - val_value_acc: 0.6936\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11809 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11809/11809 [==============================] - 0s 23us/step - loss: 5.5518 - policy_loss: 4.5296 - value_loss: 0.5111 - policy_acc: 0.7138 - value_acc: 0.7237 - val_loss: 5.2447 - val_policy_loss: 4.1602 - val_value_loss: 0.5422 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11831 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11831/11831 [==============================] - 0s 25us/step - loss: 5.4460 - policy_loss: 4.4425 - value_loss: 0.5017 - policy_acc: 0.7403 - value_acc: 0.7490 - val_loss: 5.2292 - val_policy_loss: 4.1610 - val_value_loss: 0.5341 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11722 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11722/11722 [==============================] - 0s 24us/step - loss: 5.5698 - policy_loss: 4.5216 - value_loss: 0.5241 - policy_acc: 0.6986 - value_acc: 0.7236 - val_loss: 5.2263 - val_policy_loss: 4.1609 - val_value_loss: 0.5327 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11938 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11938/11938 [==============================] - 0s 24us/step - loss: 5.5303 - policy_loss: 4.4888 - value_loss: 0.5207 - policy_acc: 0.7526 - value_acc: 0.7191 - val_loss: 5.2306 - val_policy_loss: 4.1614 - val_value_loss: 0.5346 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11916 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11916/11916 [==============================] - 0s 24us/step - loss: 5.5193 - policy_loss: 4.5164 - value_loss: 0.5015 - policy_acc: 0.7193 - value_acc: 0.7366 - val_loss: 5.2377 - val_policy_loss: 4.1613 - val_value_loss: 0.5382 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11844 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11844/11844 [==============================] - 0s 24us/step - loss: 5.5714 - policy_loss: 4.5316 - value_loss: 0.5199 - policy_acc: 0.6963 - value_acc: 0.7187 - val_loss: 5.2494 - val_policy_loss: 4.1604 - val_value_loss: 0.5445 - val_policy_acc: 0.8003 - val_value_acc: 0.7194\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11668 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11668/11668 [==============================] - 0s 24us/step - loss: 5.5324 - policy_loss: 4.5336 - value_loss: 0.4994 - policy_acc: 0.6993 - value_acc: 0.7353 - val_loss: 5.2588 - val_policy_loss: 4.1634 - val_value_loss: 0.5477 - val_policy_acc: 0.8003 - val_value_acc: 0.7212\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11861 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11861/11861 [==============================] - 0s 25us/step - loss: 5.4553 - policy_loss: 4.4745 - value_loss: 0.4904 - policy_acc: 0.7464 - value_acc: 0.7476 - val_loss: 5.2493 - val_policy_loss: 4.1620 - val_value_loss: 0.5437 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11672 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11672/11672 [==============================] - 0s 23us/step - loss: 5.5839 - policy_loss: 4.4629 - value_loss: 0.5605 - policy_acc: 0.7361 - value_acc: 0.6919 - val_loss: 5.2486 - val_policy_loss: 4.1628 - val_value_loss: 0.5429 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11733 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11733/11733 [==============================] - 0s 23us/step - loss: 5.4682 - policy_loss: 4.5104 - value_loss: 0.4789 - policy_acc: 0.7009 - value_acc: 0.7463 - val_loss: 5.2473 - val_policy_loss: 4.1643 - val_value_loss: 0.5415 - val_policy_acc: 0.8003 - val_value_acc: 0.7642\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11948 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11948/11948 [==============================] - 0s 23us/step - loss: 5.3532 - policy_loss: 4.4499 - value_loss: 0.4517 - policy_acc: 0.7457 - value_acc: 0.7754 - val_loss: 5.2275 - val_policy_loss: 4.1655 - val_value_loss: 0.5310 - val_policy_acc: 0.8003 - val_value_acc: 0.7642\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11892 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11892/11892 [==============================] - 0s 24us/step - loss: 5.5492 - policy_loss: 4.5410 - value_loss: 0.5041 - policy_acc: 0.7190 - value_acc: 0.7277 - val_loss: 5.2145 - val_policy_loss: 4.1654 - val_value_loss: 0.5246 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11876 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11876/11876 [==============================] - 0s 23us/step - loss: 5.5534 - policy_loss: 4.5228 - value_loss: 0.5153 - policy_acc: 0.7008 - value_acc: 0.7198 - val_loss: 5.2131 - val_policy_loss: 4.1631 - val_value_loss: 0.5250 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11875 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11875/11875 [==============================] - 0s 23us/step - loss: 5.4586 - policy_loss: 4.4696 - value_loss: 0.4945 - policy_acc: 0.7215 - value_acc: 0.7523 - val_loss: 5.2121 - val_policy_loss: 4.1612 - val_value_loss: 0.5254 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11685 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11685/11685 [==============================] - 0s 24us/step - loss: 5.4806 - policy_loss: 4.5284 - value_loss: 0.4761 - policy_acc: 0.7182 - value_acc: 0.7453 - val_loss: 5.2088 - val_policy_loss: 4.1591 - val_value_loss: 0.5248 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11911 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11911/11911 [==============================] - 0s 24us/step - loss: 5.4849 - policy_loss: 4.4343 - value_loss: 0.5253 - policy_acc: 0.7382 - value_acc: 0.7266 - val_loss: 5.2080 - val_policy_loss: 4.1583 - val_value_loss: 0.5248 - val_policy_acc: 0.8003 - val_value_acc: 0.7229\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11907 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11907/11907 [==============================] - 0s 23us/step - loss: 5.4764 - policy_loss: 4.4913 - value_loss: 0.4926 - policy_acc: 0.7363 - value_acc: 0.7356 - val_loss: 5.2087 - val_policy_loss: 4.1595 - val_value_loss: 0.5246 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11873 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11873/11873 [==============================] - 0s 23us/step - loss: 5.4666 - policy_loss: 4.4993 - value_loss: 0.4837 - policy_acc: 0.7128 - value_acc: 0.7394 - val_loss: 5.2025 - val_policy_loss: 4.1582 - val_value_loss: 0.5222 - val_policy_acc: 0.8003 - val_value_acc: 0.7797\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11785 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11785/11785 [==============================] - 0s 23us/step - loss: 5.5147 - policy_loss: 4.4809 - value_loss: 0.5169 - policy_acc: 0.7335 - value_acc: 0.7211 - val_loss: 5.2137 - val_policy_loss: 4.1581 - val_value_loss: 0.5278 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11845 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11845/11845 [==============================] - 0s 24us/step - loss: 5.5150 - policy_loss: 4.4948 - value_loss: 0.5101 - policy_acc: 0.7408 - value_acc: 0.7300 - val_loss: 5.2147 - val_policy_loss: 4.1606 - val_value_loss: 0.5270 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11747 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11747/11747 [==============================] - 0s 23us/step - loss: 5.6154 - policy_loss: 4.5953 - value_loss: 0.5100 - policy_acc: 0.6958 - value_acc: 0.7329 - val_loss: 5.2225 - val_policy_loss: 4.1605 - val_value_loss: 0.5310 - val_policy_acc: 0.8003 - val_value_acc: 0.7298\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11760 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11760/11760 [==============================] - 0s 23us/step - loss: 5.5920 - policy_loss: 4.5761 - value_loss: 0.5079 - policy_acc: 0.7089 - value_acc: 0.7244 - val_loss: 5.2318 - val_policy_loss: 4.1593 - val_value_loss: 0.5362 - val_policy_acc: 0.8003 - val_value_acc: 0.7057\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11863 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11863/11863 [==============================] - 0s 23us/step - loss: 5.6288 - policy_loss: 4.5177 - value_loss: 0.5556 - policy_acc: 0.7372 - value_acc: 0.6822 - val_loss: 5.2421 - val_policy_loss: 4.1613 - val_value_loss: 0.5404 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11843 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11843/11843 [==============================] - 0s 23us/step - loss: 5.5477 - policy_loss: 4.5129 - value_loss: 0.5174 - policy_acc: 0.7289 - value_acc: 0.7230 - val_loss: 5.2545 - val_policy_loss: 4.1603 - val_value_loss: 0.5471 - val_policy_acc: 0.8003 - val_value_acc: 0.7642\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11884 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11884/11884 [==============================] - 0s 23us/step - loss: 5.4425 - policy_loss: 4.4582 - value_loss: 0.4921 - policy_acc: 0.7423 - value_acc: 0.7461 - val_loss: 5.2461 - val_policy_loss: 4.1578 - val_value_loss: 0.5442 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11817 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11817/11817 [==============================] - 0s 24us/step - loss: 5.4807 - policy_loss: 4.4958 - value_loss: 0.4924 - policy_acc: 0.7255 - value_acc: 0.7524 - val_loss: 5.2314 - val_policy_loss: 4.1584 - val_value_loss: 0.5365 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11864 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11864/11864 [==============================] - 0s 24us/step - loss: 5.6004 - policy_loss: 4.5777 - value_loss: 0.5114 - policy_acc: 0.7034 - value_acc: 0.7261 - val_loss: 5.2309 - val_policy_loss: 4.1634 - val_value_loss: 0.5337 - val_policy_acc: 0.8003 - val_value_acc: 0.7315\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11832 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11832/11832 [==============================] - 0s 24us/step - loss: 5.4014 - policy_loss: 4.4310 - value_loss: 0.4852 - policy_acc: 0.7184 - value_acc: 0.7569 - val_loss: 5.2326 - val_policy_loss: 4.1650 - val_value_loss: 0.5338 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11722 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11722/11722 [==============================] - 0s 24us/step - loss: 5.5634 - policy_loss: 4.5721 - value_loss: 0.4957 - policy_acc: 0.7146 - value_acc: 0.7393 - val_loss: 5.2355 - val_policy_loss: 4.1627 - val_value_loss: 0.5364 - val_policy_acc: 0.8003 - val_value_acc: 0.6936\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11802 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11802/11802 [==============================] - 0s 24us/step - loss: 5.4214 - policy_loss: 4.4447 - value_loss: 0.4884 - policy_acc: 0.7042 - value_acc: 0.7509 - val_loss: 5.2378 - val_policy_loss: 4.1606 - val_value_loss: 0.5386 - val_policy_acc: 0.8003 - val_value_acc: 0.6850\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11797 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11797/11797 [==============================] - 0s 23us/step - loss: 5.4740 - policy_loss: 4.5128 - value_loss: 0.4806 - policy_acc: 0.7009 - value_acc: 0.7426 - val_loss: 5.2329 - val_policy_loss: 4.1574 - val_value_loss: 0.5378 - val_policy_acc: 0.8003 - val_value_acc: 0.6988\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11889 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11889/11889 [==============================] - 0s 24us/step - loss: 5.4742 - policy_loss: 4.4596 - value_loss: 0.5073 - policy_acc: 0.7316 - value_acc: 0.7344 - val_loss: 5.2372 - val_policy_loss: 4.1599 - val_value_loss: 0.5387 - val_policy_acc: 0.8003 - val_value_acc: 0.6919\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11944 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11944/11944 [==============================] - 0s 24us/step - loss: 5.4900 - policy_loss: 4.4741 - value_loss: 0.5080 - policy_acc: 0.7364 - value_acc: 0.7240 - val_loss: 5.2517 - val_policy_loss: 4.1673 - val_value_loss: 0.5422 - val_policy_acc: 0.8003 - val_value_acc: 0.6936\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11829 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11829/11829 [==============================] - 0s 24us/step - loss: 5.6322 - policy_loss: 4.5434 - value_loss: 0.5444 - policy_acc: 0.6809 - value_acc: 0.6904 - val_loss: 5.2565 - val_policy_loss: 4.1650 - val_value_loss: 0.5458 - val_policy_acc: 0.8003 - val_value_acc: 0.7091\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11833 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11833/11833 [==============================] - 0s 23us/step - loss: 5.4853 - policy_loss: 4.4706 - value_loss: 0.5073 - policy_acc: 0.7223 - value_acc: 0.7310 - val_loss: 5.2561 - val_policy_loss: 4.1606 - val_value_loss: 0.5477 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11792 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11792/11792 [==============================] - 0s 24us/step - loss: 5.5115 - policy_loss: 4.5534 - value_loss: 0.4790 - policy_acc: 0.7259 - value_acc: 0.7464 - val_loss: 5.2496 - val_policy_loss: 4.1598 - val_value_loss: 0.5449 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11866 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11866/11866 [==============================] - 0s 24us/step - loss: 5.5085 - policy_loss: 4.5038 - value_loss: 0.5024 - policy_acc: 0.7227 - value_acc: 0.7277 - val_loss: 5.2454 - val_policy_loss: 4.1622 - val_value_loss: 0.5416 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11824 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11824/11824 [==============================] - 0s 23us/step - loss: 5.3780 - policy_loss: 4.3992 - value_loss: 0.4894 - policy_acc: 0.7372 - value_acc: 0.7478 - val_loss: 5.2427 - val_policy_loss: 4.1605 - val_value_loss: 0.5411 - val_policy_acc: 0.8003 - val_value_acc: 0.7108\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11878 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11878/11878 [==============================] - 0s 23us/step - loss: 5.4941 - policy_loss: 4.4543 - value_loss: 0.5199 - policy_acc: 0.7347 - value_acc: 0.7166 - val_loss: 5.2438 - val_policy_loss: 4.1591 - val_value_loss: 0.5424 - val_policy_acc: 0.8003 - val_value_acc: 0.6919\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11762 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11762/11762 [==============================] - 0s 24us/step - loss: 5.5683 - policy_loss: 4.5228 - value_loss: 0.5228 - policy_acc: 0.7028 - value_acc: 0.7131 - val_loss: 5.2392 - val_policy_loss: 4.1590 - val_value_loss: 0.5401 - val_policy_acc: 0.8003 - val_value_acc: 0.7143\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11848 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11848/11848 [==============================] - 0s 24us/step - loss: 5.5176 - policy_loss: 4.4646 - value_loss: 0.5265 - policy_acc: 0.7093 - value_acc: 0.7253 - val_loss: 5.2454 - val_policy_loss: 4.1592 - val_value_loss: 0.5431 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11772 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11772/11772 [==============================] - 0s 24us/step - loss: 5.4599 - policy_loss: 4.4850 - value_loss: 0.4875 - policy_acc: 0.7211 - value_acc: 0.7520 - val_loss: 5.2545 - val_policy_loss: 4.1594 - val_value_loss: 0.5476 - val_policy_acc: 0.8003 - val_value_acc: 0.6902\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11960 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11960/11960 [==============================] - 0s 24us/step - loss: 5.4588 - policy_loss: 4.4621 - value_loss: 0.4984 - policy_acc: 0.7166 - value_acc: 0.7329 - val_loss: 5.2551 - val_policy_loss: 4.1600 - val_value_loss: 0.5475 - val_policy_acc: 0.8003 - val_value_acc: 0.6902\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11903 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11903/11903 [==============================] - 0s 24us/step - loss: 5.6326 - policy_loss: 4.6316 - value_loss: 0.5005 - policy_acc: 0.6922 - value_acc: 0.7238 - val_loss: 5.2513 - val_policy_loss: 4.1616 - val_value_loss: 0.5449 - val_policy_acc: 0.8003 - val_value_acc: 0.7057\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11827 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11827/11827 [==============================] - 0s 23us/step - loss: 5.4164 - policy_loss: 4.4707 - value_loss: 0.4729 - policy_acc: 0.7485 - value_acc: 0.7607 - val_loss: 5.2366 - val_policy_loss: 4.1591 - val_value_loss: 0.5388 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11689 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11689/11689 [==============================] - 0s 23us/step - loss: 5.4861 - policy_loss: 4.4534 - value_loss: 0.5164 - policy_acc: 0.7273 - value_acc: 0.7096 - val_loss: 5.2318 - val_policy_loss: 4.1609 - val_value_loss: 0.5354 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11795 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11795/11795 [==============================] - 0s 24us/step - loss: 5.4539 - policy_loss: 4.4813 - value_loss: 0.4863 - policy_acc: 0.7479 - value_acc: 0.7487 - val_loss: 5.2353 - val_policy_loss: 4.1641 - val_value_loss: 0.5356 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11849 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11849/11849 [==============================] - 0s 23us/step - loss: 5.4326 - policy_loss: 4.5002 - value_loss: 0.4662 - policy_acc: 0.7265 - value_acc: 0.7602 - val_loss: 5.2292 - val_policy_loss: 4.1626 - val_value_loss: 0.5333 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11798 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11798/11798 [==============================] - 0s 23us/step - loss: 5.5099 - policy_loss: 4.4926 - value_loss: 0.5087 - policy_acc: 0.7171 - value_acc: 0.7183 - val_loss: 5.2280 - val_policy_loss: 4.1604 - val_value_loss: 0.5338 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11804 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11804/11804 [==============================] - 0s 23us/step - loss: 5.5298 - policy_loss: 4.4787 - value_loss: 0.5256 - policy_acc: 0.7405 - value_acc: 0.7026 - val_loss: 5.2414 - val_policy_loss: 4.1603 - val_value_loss: 0.5406 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11759 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11759/11759 [==============================] - 0s 23us/step - loss: 5.5897 - policy_loss: 4.5071 - value_loss: 0.5413 - policy_acc: 0.7069 - value_acc: 0.7049 - val_loss: 5.2625 - val_policy_loss: 4.1604 - val_value_loss: 0.5510 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11916 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11916/11916 [==============================] - 0s 23us/step - loss: 5.4291 - policy_loss: 4.4198 - value_loss: 0.5047 - policy_acc: 0.7304 - value_acc: 0.7362 - val_loss: 5.2735 - val_policy_loss: 4.1607 - val_value_loss: 0.5564 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11853 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11853/11853 [==============================] - 0s 23us/step - loss: 5.5717 - policy_loss: 4.4937 - value_loss: 0.5390 - policy_acc: 0.7054 - value_acc: 0.7092 - val_loss: 5.2789 - val_policy_loss: 4.1597 - val_value_loss: 0.5596 - val_policy_acc: 0.8003 - val_value_acc: 0.6833\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11982 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11982/11982 [==============================] - 0s 23us/step - loss: 5.4784 - policy_loss: 4.4856 - value_loss: 0.4964 - policy_acc: 0.7275 - value_acc: 0.7433 - val_loss: 5.2838 - val_policy_loss: 4.1637 - val_value_loss: 0.5601 - val_policy_acc: 0.8003 - val_value_acc: 0.6713\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11968 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11968/11968 [==============================] - 0s 23us/step - loss: 5.5132 - policy_loss: 4.5177 - value_loss: 0.4977 - policy_acc: 0.7267 - value_acc: 0.7421 - val_loss: 5.2700 - val_policy_loss: 4.1611 - val_value_loss: 0.5545 - val_policy_acc: 0.8003 - val_value_acc: 0.6678\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11943 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11943/11943 [==============================] - 0s 24us/step - loss: 5.4422 - policy_loss: 4.4583 - value_loss: 0.4920 - policy_acc: 0.7246 - value_acc: 0.7506 - val_loss: 5.2539 - val_policy_loss: 4.1594 - val_value_loss: 0.5472 - val_policy_acc: 0.8003 - val_value_acc: 0.6816\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11924 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11924/11924 [==============================] - 0s 25us/step - loss: 5.5159 - policy_loss: 4.5147 - value_loss: 0.5006 - policy_acc: 0.7286 - value_acc: 0.7235 - val_loss: 5.2433 - val_policy_loss: 4.1607 - val_value_loss: 0.5413 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11988 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11988/11988 [==============================] - 0s 24us/step - loss: 5.3783 - policy_loss: 4.4457 - value_loss: 0.4663 - policy_acc: 0.7302 - value_acc: 0.7607 - val_loss: 5.2334 - val_policy_loss: 4.1615 - val_value_loss: 0.5359 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11836 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11836/11836 [==============================] - 0s 24us/step - loss: 5.4704 - policy_loss: 4.4798 - value_loss: 0.4953 - policy_acc: 0.7276 - value_acc: 0.7470 - val_loss: 5.2241 - val_policy_loss: 4.1601 - val_value_loss: 0.5320 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11780 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11780/11780 [==============================] - 0s 24us/step - loss: 5.3964 - policy_loss: 4.4425 - value_loss: 0.4770 - policy_acc: 0.7392 - value_acc: 0.7536 - val_loss: 5.2182 - val_policy_loss: 4.1597 - val_value_loss: 0.5293 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11901 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11901/11901 [==============================] - 0s 24us/step - loss: 5.5527 - policy_loss: 4.6032 - value_loss: 0.4748 - policy_acc: 0.6723 - value_acc: 0.7458 - val_loss: 5.2198 - val_policy_loss: 4.1607 - val_value_loss: 0.5296 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11843 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11843/11843 [==============================] - 0s 23us/step - loss: 5.4526 - policy_loss: 4.5123 - value_loss: 0.4701 - policy_acc: 0.7194 - value_acc: 0.7523 - val_loss: 5.2199 - val_policy_loss: 4.1610 - val_value_loss: 0.5294 - val_policy_acc: 0.8003 - val_value_acc: 0.7728\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11940 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11940/11940 [==============================] - 0s 23us/step - loss: 5.5438 - policy_loss: 4.5793 - value_loss: 0.4823 - policy_acc: 0.6939 - value_acc: 0.7442 - val_loss: 5.2184 - val_policy_loss: 4.1599 - val_value_loss: 0.5293 - val_policy_acc: 0.8003 - val_value_acc: 0.7728\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11696 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11696/11696 [==============================] - 0s 23us/step - loss: 5.5941 - policy_loss: 4.5218 - value_loss: 0.5362 - policy_acc: 0.7099 - value_acc: 0.7074 - val_loss: 5.2332 - val_policy_loss: 4.1608 - val_value_loss: 0.5362 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11858 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11858/11858 [==============================] - 0s 23us/step - loss: 5.5143 - policy_loss: 4.4800 - value_loss: 0.5172 - policy_acc: 0.7036 - value_acc: 0.7337 - val_loss: 5.2505 - val_policy_loss: 4.1603 - val_value_loss: 0.5451 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11961 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11961/11961 [==============================] - 0s 25us/step - loss: 5.4661 - policy_loss: 4.4606 - value_loss: 0.5027 - policy_acc: 0.7438 - value_acc: 0.7448 - val_loss: 5.2593 - val_policy_loss: 4.1606 - val_value_loss: 0.5493 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11902 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11902/11902 [==============================] - 0s 24us/step - loss: 5.4457 - policy_loss: 4.4422 - value_loss: 0.5018 - policy_acc: 0.7469 - value_acc: 0.7380 - val_loss: 5.2496 - val_policy_loss: 4.1602 - val_value_loss: 0.5447 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11767 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11767/11767 [==============================] - 0s 23us/step - loss: 5.4523 - policy_loss: 4.4915 - value_loss: 0.4804 - policy_acc: 0.7198 - value_acc: 0.7405 - val_loss: 5.2373 - val_policy_loss: 4.1584 - val_value_loss: 0.5395 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11853 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11853/11853 [==============================] - 0s 24us/step - loss: 5.4648 - policy_loss: 4.4756 - value_loss: 0.4946 - policy_acc: 0.7261 - value_acc: 0.7509 - val_loss: 5.2335 - val_policy_loss: 4.1610 - val_value_loss: 0.5362 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11854 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11854/11854 [==============================] - 0s 24us/step - loss: 5.4613 - policy_loss: 4.4970 - value_loss: 0.4821 - policy_acc: 0.7222 - value_acc: 0.7362 - val_loss: 5.2344 - val_policy_loss: 4.1649 - val_value_loss: 0.5348 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11940 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11940/11940 [==============================] - 0s 23us/step - loss: 5.5689 - policy_loss: 4.5291 - value_loss: 0.5199 - policy_acc: 0.6975 - value_acc: 0.7259 - val_loss: 5.2419 - val_policy_loss: 4.1628 - val_value_loss: 0.5395 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11921 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11921/11921 [==============================] - 0s 23us/step - loss: 5.5028 - policy_loss: 4.4797 - value_loss: 0.5115 - policy_acc: 0.7194 - value_acc: 0.7280 - val_loss: 5.2431 - val_policy_loss: 4.1596 - val_value_loss: 0.5417 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11775 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11775/11775 [==============================] - 0s 23us/step - loss: 5.4180 - policy_loss: 4.4856 - value_loss: 0.4662 - policy_acc: 0.7441 - value_acc: 0.7608 - val_loss: 5.2363 - val_policy_loss: 4.1593 - val_value_loss: 0.5385 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11787 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11787/11787 [==============================] - 0s 22us/step - loss: 5.4744 - policy_loss: 4.5016 - value_loss: 0.4864 - policy_acc: 0.7227 - value_acc: 0.7413 - val_loss: 5.2340 - val_policy_loss: 4.1591 - val_value_loss: 0.5375 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11911 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11911/11911 [==============================] - 0s 25us/step - loss: 5.5465 - policy_loss: 4.5730 - value_loss: 0.4868 - policy_acc: 0.7001 - value_acc: 0.7407 - val_loss: 5.2346 - val_policy_loss: 4.1603 - val_value_loss: 0.5372 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11953 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11953/11953 [==============================] - 0s 24us/step - loss: 5.5738 - policy_loss: 4.5443 - value_loss: 0.5148 - policy_acc: 0.7127 - value_acc: 0.7299 - val_loss: 5.2354 - val_policy_loss: 4.1609 - val_value_loss: 0.5372 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11938 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11938/11938 [==============================] - 0s 23us/step - loss: 5.4979 - policy_loss: 4.4811 - value_loss: 0.5084 - policy_acc: 0.7127 - value_acc: 0.7263 - val_loss: 5.2392 - val_policy_loss: 4.1606 - val_value_loss: 0.5393 - val_policy_acc: 0.8003 - val_value_acc: 0.7728\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11816 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11816/11816 [==============================] - 0s 24us/step - loss: 5.4756 - policy_loss: 4.5313 - value_loss: 0.4721 - policy_acc: 0.7193 - value_acc: 0.7514 - val_loss: 5.2375 - val_policy_loss: 4.1596 - val_value_loss: 0.5389 - val_policy_acc: 0.8003 - val_value_acc: 0.7711\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11888 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11888/11888 [==============================] - 0s 24us/step - loss: 5.4620 - policy_loss: 4.5108 - value_loss: 0.4756 - policy_acc: 0.6994 - value_acc: 0.7462 - val_loss: 5.2277 - val_policy_loss: 4.1581 - val_value_loss: 0.5348 - val_policy_acc: 0.8003 - val_value_acc: 0.7762\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11762 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11762/11762 [==============================] - 0s 24us/step - loss: 5.5166 - policy_loss: 4.5294 - value_loss: 0.4936 - policy_acc: 0.7191 - value_acc: 0.7370 - val_loss: 5.2246 - val_policy_loss: 4.1556 - val_value_loss: 0.5345 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11966 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11966/11966 [==============================] - 0s 24us/step - loss: 5.5345 - policy_loss: 4.4946 - value_loss: 0.5199 - policy_acc: 0.7110 - value_acc: 0.7205 - val_loss: 5.2316 - val_policy_loss: 4.1590 - val_value_loss: 0.5363 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11956 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11956/11956 [==============================] - 0s 23us/step - loss: 5.4728 - policy_loss: 4.4589 - value_loss: 0.5069 - policy_acc: 0.7549 - value_acc: 0.7365 - val_loss: 5.2430 - val_policy_loss: 4.1651 - val_value_loss: 0.5389 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11722 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11722/11722 [==============================] - 0s 24us/step - loss: 5.4717 - policy_loss: 4.5024 - value_loss: 0.4846 - policy_acc: 0.7310 - value_acc: 0.7448 - val_loss: 5.2321 - val_policy_loss: 4.1583 - val_value_loss: 0.5369 - val_policy_acc: 0.8003 - val_value_acc: 0.7780\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11775 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11775/11775 [==============================] - 0s 23us/step - loss: 5.5388 - policy_loss: 4.5829 - value_loss: 0.4780 - policy_acc: 0.6870 - value_acc: 0.7469 - val_loss: 5.2265 - val_policy_loss: 4.1569 - val_value_loss: 0.5348 - val_policy_acc: 0.8003 - val_value_acc: 0.7728\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11925 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11925/11925 [==============================] - 0s 25us/step - loss: 5.4801 - policy_loss: 4.4113 - value_loss: 0.5344 - policy_acc: 0.7535 - value_acc: 0.7110 - val_loss: 5.2337 - val_policy_loss: 4.1597 - val_value_loss: 0.5370 - val_policy_acc: 0.8003 - val_value_acc: 0.7694\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11754 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11754/11754 [==============================] - 0s 25us/step - loss: 5.4917 - policy_loss: 4.5148 - value_loss: 0.4884 - policy_acc: 0.7124 - value_acc: 0.7370 - val_loss: 5.2446 - val_policy_loss: 4.1603 - val_value_loss: 0.5422 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11832 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11832/11832 [==============================] - 0s 24us/step - loss: 5.5476 - policy_loss: 4.4813 - value_loss: 0.5331 - policy_acc: 0.7257 - value_acc: 0.7079 - val_loss: 5.2595 - val_policy_loss: 4.1625 - val_value_loss: 0.5485 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11929 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11929/11929 [==============================] - 0s 23us/step - loss: 5.4064 - policy_loss: 4.4638 - value_loss: 0.4713 - policy_acc: 0.7284 - value_acc: 0.7616 - val_loss: 5.2614 - val_policy_loss: 4.1632 - val_value_loss: 0.5491 - val_policy_acc: 0.8003 - val_value_acc: 0.7315\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11815 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11815/11815 [==============================] - 0s 23us/step - loss: 5.5440 - policy_loss: 4.5119 - value_loss: 0.5161 - policy_acc: 0.7207 - value_acc: 0.7318 - val_loss: 5.2553 - val_policy_loss: 4.1612 - val_value_loss: 0.5470 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11617 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11617/11617 [==============================] - 0s 24us/step - loss: 5.5189 - policy_loss: 4.5222 - value_loss: 0.4984 - policy_acc: 0.6882 - value_acc: 0.7403 - val_loss: 5.2551 - val_policy_loss: 4.1609 - val_value_loss: 0.5471 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11813 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11813/11813 [==============================] - 0s 24us/step - loss: 5.4520 - policy_loss: 4.4664 - value_loss: 0.4928 - policy_acc: 0.7328 - value_acc: 0.7364 - val_loss: 5.2524 - val_policy_loss: 4.1623 - val_value_loss: 0.5450 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11836 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11836/11836 [==============================] - 0s 23us/step - loss: 5.4879 - policy_loss: 4.4909 - value_loss: 0.4985 - policy_acc: 0.6983 - value_acc: 0.7339 - val_loss: 5.2446 - val_policy_loss: 4.1633 - val_value_loss: 0.5407 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11755 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11755/11755 [==============================] - 0s 24us/step - loss: 5.4897 - policy_loss: 4.5000 - value_loss: 0.4948 - policy_acc: 0.7160 - value_acc: 0.7369 - val_loss: 5.2361 - val_policy_loss: 4.1600 - val_value_loss: 0.5380 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11727 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11727/11727 [==============================] - 0s 23us/step - loss: 5.4101 - policy_loss: 4.4459 - value_loss: 0.4821 - policy_acc: 0.7516 - value_acc: 0.7442 - val_loss: 5.2293 - val_policy_loss: 4.1594 - val_value_loss: 0.5350 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11792 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11792/11792 [==============================] - 0s 24us/step - loss: 5.4693 - policy_loss: 4.4992 - value_loss: 0.4850 - policy_acc: 0.7156 - value_acc: 0.7492 - val_loss: 5.2222 - val_policy_loss: 4.1611 - val_value_loss: 0.5306 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11819 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11819/11819 [==============================] - 0s 24us/step - loss: 5.4457 - policy_loss: 4.4535 - value_loss: 0.4961 - policy_acc: 0.7537 - value_acc: 0.7435 - val_loss: 5.2155 - val_policy_loss: 4.1603 - val_value_loss: 0.5276 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11916 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11916/11916 [==============================] - 0s 23us/step - loss: 5.6108 - policy_loss: 4.5837 - value_loss: 0.5136 - policy_acc: 0.7043 - value_acc: 0.7143 - val_loss: 5.2304 - val_policy_loss: 4.1628 - val_value_loss: 0.5338 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11625 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11625/11625 [==============================] - 0s 26us/step - loss: 5.5266 - policy_loss: 4.5459 - value_loss: 0.4903 - policy_acc: 0.7092 - value_acc: 0.7336 - val_loss: 5.2501 - val_policy_loss: 4.1633 - val_value_loss: 0.5434 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11773 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11773/11773 [==============================] - 0s 23us/step - loss: 5.5700 - policy_loss: 4.5670 - value_loss: 0.5015 - policy_acc: 0.7171 - value_acc: 0.7387 - val_loss: 5.2561 - val_policy_loss: 4.1599 - val_value_loss: 0.5481 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11898 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11898/11898 [==============================] - 0s 23us/step - loss: 5.4471 - policy_loss: 4.4563 - value_loss: 0.4954 - policy_acc: 0.7262 - value_acc: 0.7382 - val_loss: 5.2557 - val_policy_loss: 4.1588 - val_value_loss: 0.5484 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11745 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11745/11745 [==============================] - 0s 24us/step - loss: 5.4590 - policy_loss: 4.4759 - value_loss: 0.4916 - policy_acc: 0.7374 - value_acc: 0.7365 - val_loss: 5.2523 - val_policy_loss: 4.1616 - val_value_loss: 0.5453 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11730 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11730/11730 [==============================] - 0s 23us/step - loss: 5.4627 - policy_loss: 4.4279 - value_loss: 0.5174 - policy_acc: 0.7210 - value_acc: 0.7248 - val_loss: 5.2561 - val_policy_loss: 4.1642 - val_value_loss: 0.5460 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11687 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11687/11687 [==============================] - 0s 23us/step - loss: 5.5003 - policy_loss: 4.5281 - value_loss: 0.4861 - policy_acc: 0.7263 - value_acc: 0.7383 - val_loss: 5.2580 - val_policy_loss: 4.1635 - val_value_loss: 0.5473 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11808 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11808/11808 [==============================] - 0s 23us/step - loss: 5.4948 - policy_loss: 4.5334 - value_loss: 0.4807 - policy_acc: 0.7018 - value_acc: 0.7446 - val_loss: 5.2532 - val_policy_loss: 4.1616 - val_value_loss: 0.5458 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11813 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11813/11813 [==============================] - 0s 23us/step - loss: 5.4934 - policy_loss: 4.4625 - value_loss: 0.5155 - policy_acc: 0.7117 - value_acc: 0.7331 - val_loss: 5.2438 - val_policy_loss: 4.1589 - val_value_loss: 0.5424 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11734 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11734/11734 [==============================] - 0s 24us/step - loss: 5.5281 - policy_loss: 4.4880 - value_loss: 0.5200 - policy_acc: 0.7114 - value_acc: 0.7274 - val_loss: 5.2404 - val_policy_loss: 4.1590 - val_value_loss: 0.5407 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11919 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11919/11919 [==============================] - 0s 26us/step - loss: 5.5442 - policy_loss: 4.5516 - value_loss: 0.4963 - policy_acc: 0.7246 - value_acc: 0.7309 - val_loss: 5.2449 - val_policy_loss: 4.1609 - val_value_loss: 0.5420 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11768 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11768/11768 [==============================] - 0s 23us/step - loss: 5.3910 - policy_loss: 4.4299 - value_loss: 0.4806 - policy_acc: 0.7180 - value_acc: 0.7389 - val_loss: 5.2482 - val_policy_loss: 4.1602 - val_value_loss: 0.5440 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11755 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11755/11755 [==============================] - 0s 23us/step - loss: 5.3898 - policy_loss: 4.4083 - value_loss: 0.4907 - policy_acc: 0.7495 - value_acc: 0.7347 - val_loss: 5.2450 - val_policy_loss: 4.1594 - val_value_loss: 0.5428 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11744 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11744/11744 [==============================] - 0s 24us/step - loss: 5.4737 - policy_loss: 4.4378 - value_loss: 0.5179 - policy_acc: 0.7233 - value_acc: 0.7250 - val_loss: 5.2472 - val_policy_loss: 4.1624 - val_value_loss: 0.5424 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11721 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11721/11721 [==============================] - 0s 23us/step - loss: 5.4863 - policy_loss: 4.4631 - value_loss: 0.5116 - policy_acc: 0.7292 - value_acc: 0.7267 - val_loss: 5.2513 - val_policy_loss: 4.1611 - val_value_loss: 0.5451 - val_policy_acc: 0.8003 - val_value_acc: 0.6954\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11848 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11848/11848 [==============================] - 0s 23us/step - loss: 5.5559 - policy_loss: 4.5824 - value_loss: 0.4867 - policy_acc: 0.7221 - value_acc: 0.7411 - val_loss: 5.2567 - val_policy_loss: 4.1584 - val_value_loss: 0.5492 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11788 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11788/11788 [==============================] - 0s 24us/step - loss: 5.4364 - policy_loss: 4.4270 - value_loss: 0.5047 - policy_acc: 0.7363 - value_acc: 0.7350 - val_loss: 5.2587 - val_policy_loss: 4.1595 - val_value_loss: 0.5496 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11950 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11950/11950 [==============================] - 0s 24us/step - loss: 5.4865 - policy_loss: 4.5004 - value_loss: 0.4931 - policy_acc: 0.7254 - value_acc: 0.7398 - val_loss: 5.2544 - val_policy_loss: 4.1602 - val_value_loss: 0.5471 - val_policy_acc: 0.8003 - val_value_acc: 0.7143\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11763 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11763/11763 [==============================] - 0s 23us/step - loss: 5.5400 - policy_loss: 4.4124 - value_loss: 0.5638 - policy_acc: 0.7341 - value_acc: 0.6897 - val_loss: 5.2710 - val_policy_loss: 4.1605 - val_value_loss: 0.5553 - val_policy_acc: 0.8003 - val_value_acc: 0.7057\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11894 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11894/11894 [==============================] - 0s 24us/step - loss: 5.4165 - policy_loss: 4.4561 - value_loss: 0.4802 - policy_acc: 0.7377 - value_acc: 0.7540 - val_loss: 5.2830 - val_policy_loss: 4.1619 - val_value_loss: 0.5605 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11939 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11939/11939 [==============================] - 0s 23us/step - loss: 5.5198 - policy_loss: 4.4656 - value_loss: 0.5271 - policy_acc: 0.7202 - value_acc: 0.7123 - val_loss: 5.2813 - val_policy_loss: 4.1586 - val_value_loss: 0.5613 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11852 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11852/11852 [==============================] - 0s 23us/step - loss: 5.4997 - policy_loss: 4.5262 - value_loss: 0.4867 - policy_acc: 0.7115 - value_acc: 0.7416 - val_loss: 5.2719 - val_policy_loss: 4.1590 - val_value_loss: 0.5565 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11808 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11808/11808 [==============================] - 0s 24us/step - loss: 5.4752 - policy_loss: 4.4898 - value_loss: 0.4927 - policy_acc: 0.7226 - value_acc: 0.7472 - val_loss: 5.2651 - val_policy_loss: 4.1613 - val_value_loss: 0.5519 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11852 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11852/11852 [==============================] - 0s 23us/step - loss: 5.4777 - policy_loss: 4.5131 - value_loss: 0.4823 - policy_acc: 0.7050 - value_acc: 0.7519 - val_loss: 5.2589 - val_policy_loss: 4.1631 - val_value_loss: 0.5479 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11785 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11785/11785 [==============================] - 0s 24us/step - loss: 5.6754 - policy_loss: 4.6001 - value_loss: 0.5377 - policy_acc: 0.6965 - value_acc: 0.6983 - val_loss: 5.2645 - val_policy_loss: 4.1614 - val_value_loss: 0.5515 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11850 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11850/11850 [==============================] - 0s 24us/step - loss: 5.4427 - policy_loss: 4.4555 - value_loss: 0.4936 - policy_acc: 0.7265 - value_acc: 0.7414 - val_loss: 5.2630 - val_policy_loss: 4.1604 - val_value_loss: 0.5513 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11904 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11904/11904 [==============================] - 0s 24us/step - loss: 5.5543 - policy_loss: 4.5460 - value_loss: 0.5042 - policy_acc: 0.6912 - value_acc: 0.7459 - val_loss: 5.2614 - val_policy_loss: 4.1614 - val_value_loss: 0.5500 - val_policy_acc: 0.7969 - val_value_acc: 0.7091\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11833 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11833/11833 [==============================] - 0s 23us/step - loss: 5.5768 - policy_loss: 4.5219 - value_loss: 0.5274 - policy_acc: 0.7079 - value_acc: 0.7300 - val_loss: 5.2692 - val_policy_loss: 4.1609 - val_value_loss: 0.5542 - val_policy_acc: 0.8003 - val_value_acc: 0.6644\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11750 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11750/11750 [==============================] - 0s 24us/step - loss: 5.5379 - policy_loss: 4.4720 - value_loss: 0.5330 - policy_acc: 0.7342 - value_acc: 0.7060 - val_loss: 5.2726 - val_policy_loss: 4.1597 - val_value_loss: 0.5565 - val_policy_acc: 0.8003 - val_value_acc: 0.6902\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11892 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11892/11892 [==============================] - 0s 24us/step - loss: 5.5619 - policy_loss: 4.5433 - value_loss: 0.5093 - policy_acc: 0.7112 - value_acc: 0.7284 - val_loss: 5.2706 - val_policy_loss: 4.1575 - val_value_loss: 0.5565 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11806 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11806/11806 [==============================] - 0s 24us/step - loss: 5.5746 - policy_loss: 4.5141 - value_loss: 0.5303 - policy_acc: 0.7027 - value_acc: 0.7162 - val_loss: 5.2720 - val_policy_loss: 4.1584 - val_value_loss: 0.5568 - val_policy_acc: 0.7969 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11918 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11918/11918 [==============================] - 0s 23us/step - loss: 5.5541 - policy_loss: 4.5148 - value_loss: 0.5196 - policy_acc: 0.7022 - value_acc: 0.7276 - val_loss: 5.2743 - val_policy_loss: 4.1625 - val_value_loss: 0.5559 - val_policy_acc: 0.7969 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11759 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11759/11759 [==============================] - 0s 23us/step - loss: 5.5185 - policy_loss: 4.5166 - value_loss: 0.5009 - policy_acc: 0.7140 - value_acc: 0.7252 - val_loss: 5.2669 - val_policy_loss: 4.1632 - val_value_loss: 0.5519 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11922 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11922/11922 [==============================] - 0s 24us/step - loss: 5.5089 - policy_loss: 4.4990 - value_loss: 0.5049 - policy_acc: 0.7222 - value_acc: 0.7240 - val_loss: 5.2594 - val_policy_loss: 4.1638 - val_value_loss: 0.5478 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11754 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11754/11754 [==============================] - 0s 23us/step - loss: 5.4404 - policy_loss: 4.4565 - value_loss: 0.4919 - policy_acc: 0.7437 - value_acc: 0.7412 - val_loss: 5.2510 - val_policy_loss: 4.1616 - val_value_loss: 0.5447 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11933 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11933/11933 [==============================] - 0s 23us/step - loss: 5.4669 - policy_loss: 4.4856 - value_loss: 0.4907 - policy_acc: 0.7335 - value_acc: 0.7399 - val_loss: 5.2459 - val_policy_loss: 4.1616 - val_value_loss: 0.5422 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11694 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11694/11694 [==============================] - 0s 24us/step - loss: 5.4828 - policy_loss: 4.4760 - value_loss: 0.5034 - policy_acc: 0.7093 - value_acc: 0.7370 - val_loss: 5.2549 - val_policy_loss: 4.1610 - val_value_loss: 0.5470 - val_policy_acc: 0.8003 - val_value_acc: 0.6644\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11949 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11949/11949 [==============================] - 0s 23us/step - loss: 5.5315 - policy_loss: 4.4945 - value_loss: 0.5185 - policy_acc: 0.6975 - value_acc: 0.7205 - val_loss: 5.2600 - val_policy_loss: 4.1571 - val_value_loss: 0.5514 - val_policy_acc: 0.8003 - val_value_acc: 0.6678\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11821 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11821/11821 [==============================] - 0s 24us/step - loss: 5.4400 - policy_loss: 4.5094 - value_loss: 0.4653 - policy_acc: 0.7241 - value_acc: 0.7608 - val_loss: 5.2596 - val_policy_loss: 4.1594 - val_value_loss: 0.5501 - val_policy_acc: 0.8003 - val_value_acc: 0.7212\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11841 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11841/11841 [==============================] - 0s 23us/step - loss: 5.4316 - policy_loss: 4.4534 - value_loss: 0.4891 - policy_acc: 0.7504 - value_acc: 0.7480 - val_loss: 5.2493 - val_policy_loss: 4.1592 - val_value_loss: 0.5450 - val_policy_acc: 0.8003 - val_value_acc: 0.7177\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11905 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11905/11905 [==============================] - 0s 24us/step - loss: 5.4539 - policy_loss: 4.5226 - value_loss: 0.4656 - policy_acc: 0.7359 - value_acc: 0.7543 - val_loss: 5.2423 - val_policy_loss: 4.1606 - val_value_loss: 0.5408 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11784 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11784/11784 [==============================] - 0s 24us/step - loss: 5.4935 - policy_loss: 4.5278 - value_loss: 0.4828 - policy_acc: 0.7198 - value_acc: 0.7459 - val_loss: 5.2432 - val_policy_loss: 4.1623 - val_value_loss: 0.5404 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11880 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11880/11880 [==============================] - 0s 24us/step - loss: 5.4967 - policy_loss: 4.4503 - value_loss: 0.5232 - policy_acc: 0.7238 - value_acc: 0.7229 - val_loss: 5.2425 - val_policy_loss: 4.1646 - val_value_loss: 0.5390 - val_policy_acc: 0.8003 - val_value_acc: 0.7212\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11910 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11910/11910 [==============================] - 0s 25us/step - loss: 5.5513 - policy_loss: 4.4515 - value_loss: 0.5499 - policy_acc: 0.7207 - value_acc: 0.7051 - val_loss: 5.2637 - val_policy_loss: 4.1620 - val_value_loss: 0.5508 - val_policy_acc: 0.8003 - val_value_acc: 0.6592\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11964 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11964/11964 [==============================] - 0s 23us/step - loss: 5.5009 - policy_loss: 4.4642 - value_loss: 0.5184 - policy_acc: 0.7256 - value_acc: 0.7229 - val_loss: 5.2758 - val_policy_loss: 4.1603 - val_value_loss: 0.5577 - val_policy_acc: 0.8003 - val_value_acc: 0.6678\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11775 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11775/11775 [==============================] - 0s 25us/step - loss: 5.4629 - policy_loss: 4.4566 - value_loss: 0.5032 - policy_acc: 0.7370 - value_acc: 0.7434 - val_loss: 5.2734 - val_policy_loss: 4.1606 - val_value_loss: 0.5564 - val_policy_acc: 0.8003 - val_value_acc: 0.6867\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11949 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11949/11949 [==============================] - 0s 27us/step - loss: 5.5100 - policy_loss: 4.5192 - value_loss: 0.4954 - policy_acc: 0.7008 - value_acc: 0.7346 - val_loss: 5.2663 - val_policy_loss: 4.1611 - val_value_loss: 0.5526 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11867 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11867/11867 [==============================] - 0s 24us/step - loss: 5.4505 - policy_loss: 4.3937 - value_loss: 0.5284 - policy_acc: 0.7497 - value_acc: 0.7113 - val_loss: 5.2673 - val_policy_loss: 4.1606 - val_value_loss: 0.5534 - val_policy_acc: 0.8003 - val_value_acc: 0.7315\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11970 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11970/11970 [==============================] - 0s 25us/step - loss: 5.4384 - policy_loss: 4.4522 - value_loss: 0.4931 - policy_acc: 0.7205 - value_acc: 0.7403 - val_loss: 5.2659 - val_policy_loss: 4.1605 - val_value_loss: 0.5527 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11840 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11840/11840 [==============================] - 0s 25us/step - loss: 5.4915 - policy_loss: 4.4604 - value_loss: 0.5155 - policy_acc: 0.7480 - value_acc: 0.7123 - val_loss: 5.2739 - val_policy_loss: 4.1625 - val_value_loss: 0.5557 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11679 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11679/11679 [==============================] - 0s 26us/step - loss: 5.5776 - policy_loss: 4.5618 - value_loss: 0.5079 - policy_acc: 0.7079 - value_acc: 0.7247 - val_loss: 5.2773 - val_policy_loss: 4.1608 - val_value_loss: 0.5583 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11933 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11933/11933 [==============================] - 0s 23us/step - loss: 5.4775 - policy_loss: 4.4749 - value_loss: 0.5013 - policy_acc: 0.7289 - value_acc: 0.7319 - val_loss: 5.2786 - val_policy_loss: 4.1622 - val_value_loss: 0.5582 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11866 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11866/11866 [==============================] - 0s 23us/step - loss: 5.5891 - policy_loss: 4.5788 - value_loss: 0.5052 - policy_acc: 0.7078 - value_acc: 0.7348 - val_loss: 5.2775 - val_policy_loss: 4.1648 - val_value_loss: 0.5563 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11935 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11935/11935 [==============================] - 0s 23us/step - loss: 5.4340 - policy_loss: 4.4553 - value_loss: 0.4893 - policy_acc: 0.7295 - value_acc: 0.7475 - val_loss: 5.2584 - val_policy_loss: 4.1625 - val_value_loss: 0.5479 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11890 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11890/11890 [==============================] - 0s 26us/step - loss: 5.4466 - policy_loss: 4.4463 - value_loss: 0.5002 - policy_acc: 0.7489 - value_acc: 0.7312 - val_loss: 5.2547 - val_policy_loss: 4.1618 - val_value_loss: 0.5464 - val_policy_acc: 0.8003 - val_value_acc: 0.7177\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11853 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11853/11853 [==============================] - 0s 24us/step - loss: 5.4644 - policy_loss: 4.4530 - value_loss: 0.5057 - policy_acc: 0.7393 - value_acc: 0.7327 - val_loss: 5.2571 - val_policy_loss: 4.1612 - val_value_loss: 0.5479 - val_policy_acc: 0.8003 - val_value_acc: 0.7040\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11714 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11714/11714 [==============================] - 0s 24us/step - loss: 5.5475 - policy_loss: 4.5305 - value_loss: 0.5085 - policy_acc: 0.7030 - value_acc: 0.7318 - val_loss: 5.2578 - val_policy_loss: 4.1578 - val_value_loss: 0.5500 - val_policy_acc: 0.8003 - val_value_acc: 0.7229\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11734 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11734/11734 [==============================] - 0s 24us/step - loss: 5.4952 - policy_loss: 4.4778 - value_loss: 0.5087 - policy_acc: 0.7238 - value_acc: 0.7267 - val_loss: 5.2663 - val_policy_loss: 4.1611 - val_value_loss: 0.5526 - val_policy_acc: 0.8003 - val_value_acc: 0.7126\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11890 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11890/11890 [==============================] - 0s 23us/step - loss: 5.5212 - policy_loss: 4.5427 - value_loss: 0.4893 - policy_acc: 0.6979 - value_acc: 0.7362 - val_loss: 5.2710 - val_policy_loss: 4.1608 - val_value_loss: 0.5551 - val_policy_acc: 0.8003 - val_value_acc: 0.7126\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11740 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11740/11740 [==============================] - 0s 26us/step - loss: 5.4062 - policy_loss: 4.3973 - value_loss: 0.5045 - policy_acc: 0.7450 - value_acc: 0.7342 - val_loss: 5.2661 - val_policy_loss: 4.1592 - val_value_loss: 0.5535 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11862 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11862/11862 [==============================] - 0s 23us/step - loss: 5.5802 - policy_loss: 4.4750 - value_loss: 0.5526 - policy_acc: 0.7125 - value_acc: 0.7044 - val_loss: 5.2656 - val_policy_loss: 4.1590 - val_value_loss: 0.5533 - val_policy_acc: 0.8003 - val_value_acc: 0.7091\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11919 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11919/11919 [==============================] - 0s 23us/step - loss: 5.4998 - policy_loss: 4.4470 - value_loss: 0.5264 - policy_acc: 0.6877 - value_acc: 0.7147 - val_loss: 5.2782 - val_policy_loss: 4.1617 - val_value_loss: 0.5583 - val_policy_acc: 0.8003 - val_value_acc: 0.6936\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11816 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11816/11816 [==============================] - 0s 25us/step - loss: 5.5099 - policy_loss: 4.4762 - value_loss: 0.5168 - policy_acc: 0.7431 - value_acc: 0.7098 - val_loss: 5.2775 - val_policy_loss: 4.1592 - val_value_loss: 0.5591 - val_policy_acc: 0.8003 - val_value_acc: 0.7091\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11818 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11818/11818 [==============================] - 0s 24us/step - loss: 5.5042 - policy_loss: 4.4925 - value_loss: 0.5059 - policy_acc: 0.7207 - value_acc: 0.7312 - val_loss: 5.2839 - val_policy_loss: 4.1599 - val_value_loss: 0.5620 - val_policy_acc: 0.8003 - val_value_acc: 0.7194\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11867 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11867/11867 [==============================] - 0s 24us/step - loss: 5.5474 - policy_loss: 4.5654 - value_loss: 0.4910 - policy_acc: 0.7116 - value_acc: 0.7423 - val_loss: 5.2842 - val_policy_loss: 4.1636 - val_value_loss: 0.5603 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11906 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11906/11906 [==============================] - 0s 24us/step - loss: 5.4729 - policy_loss: 4.4581 - value_loss: 0.5074 - policy_acc: 0.7217 - value_acc: 0.7418 - val_loss: 5.2737 - val_policy_loss: 4.1638 - val_value_loss: 0.5550 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11759 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11759/11759 [==============================] - 0s 23us/step - loss: 5.5232 - policy_loss: 4.4953 - value_loss: 0.5139 - policy_acc: 0.7297 - value_acc: 0.7291 - val_loss: 5.2592 - val_policy_loss: 4.1643 - val_value_loss: 0.5475 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11942 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11942/11942 [==============================] - 0s 24us/step - loss: 5.5482 - policy_loss: 4.5736 - value_loss: 0.4873 - policy_acc: 0.7031 - value_acc: 0.7461 - val_loss: 5.2436 - val_policy_loss: 4.1665 - val_value_loss: 0.5385 - val_policy_acc: 0.8003 - val_value_acc: 0.7659\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11597 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11597/11597 [==============================] - 0s 24us/step - loss: 5.5258 - policy_loss: 4.5248 - value_loss: 0.5005 - policy_acc: 0.6999 - value_acc: 0.7331 - val_loss: 5.2315 - val_policy_loss: 4.1611 - val_value_loss: 0.5352 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11732 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11732/11732 [==============================] - 0s 23us/step - loss: 5.3297 - policy_loss: 4.4226 - value_loss: 0.4536 - policy_acc: 0.7571 - value_acc: 0.7584 - val_loss: 5.2253 - val_policy_loss: 4.1601 - val_value_loss: 0.5326 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11819 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11819/11819 [==============================] - 0s 25us/step - loss: 5.5234 - policy_loss: 4.4956 - value_loss: 0.5139 - policy_acc: 0.7248 - value_acc: 0.7267 - val_loss: 5.2187 - val_policy_loss: 4.1598 - val_value_loss: 0.5295 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11891 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11891/11891 [==============================] - 0s 23us/step - loss: 5.4080 - policy_loss: 4.4230 - value_loss: 0.4925 - policy_acc: 0.7272 - value_acc: 0.7413 - val_loss: 5.2214 - val_policy_loss: 4.1602 - val_value_loss: 0.5306 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11879 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11879/11879 [==============================] - 0s 23us/step - loss: 5.5541 - policy_loss: 4.5320 - value_loss: 0.5110 - policy_acc: 0.7120 - value_acc: 0.7326 - val_loss: 5.2290 - val_policy_loss: 4.1595 - val_value_loss: 0.5347 - val_policy_acc: 0.8003 - val_value_acc: 0.7676\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11841 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11841/11841 [==============================] - 0s 28us/step - loss: 5.4966 - policy_loss: 4.4752 - value_loss: 0.5107 - policy_acc: 0.7102 - value_acc: 0.7232 - val_loss: 5.2366 - val_policy_loss: 4.1580 - val_value_loss: 0.5393 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11824 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11824/11824 [==============================] - 0s 23us/step - loss: 5.5486 - policy_loss: 4.5372 - value_loss: 0.5057 - policy_acc: 0.6950 - value_acc: 0.7355 - val_loss: 5.2386 - val_policy_loss: 4.1582 - val_value_loss: 0.5402 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11840 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11840/11840 [==============================] - 0s 23us/step - loss: 5.4964 - policy_loss: 4.5311 - value_loss: 0.4827 - policy_acc: 0.7257 - value_acc: 0.7478 - val_loss: 5.2304 - val_policy_loss: 4.1575 - val_value_loss: 0.5365 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11711 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11711/11711 [==============================] - 0s 24us/step - loss: 5.4235 - policy_loss: 4.4697 - value_loss: 0.4769 - policy_acc: 0.7158 - value_acc: 0.7520 - val_loss: 5.2286 - val_policy_loss: 4.1591 - val_value_loss: 0.5348 - val_policy_acc: 0.8003 - val_value_acc: 0.7143\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11714 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11714/11714 [==============================] - 0s 23us/step - loss: 5.5414 - policy_loss: 4.5561 - value_loss: 0.4926 - policy_acc: 0.7272 - value_acc: 0.7351 - val_loss: 5.2361 - val_policy_loss: 4.1638 - val_value_loss: 0.5361 - val_policy_acc: 0.8003 - val_value_acc: 0.7005\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11996 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11996/11996 [==============================] - 0s 25us/step - loss: 5.4343 - policy_loss: 4.4765 - value_loss: 0.4789 - policy_acc: 0.7268 - value_acc: 0.7543 - val_loss: 5.2376 - val_policy_loss: 4.1626 - val_value_loss: 0.5375 - val_policy_acc: 0.8003 - val_value_acc: 0.6971\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11882 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11882/11882 [==============================] - 0s 23us/step - loss: 5.4334 - policy_loss: 4.4775 - value_loss: 0.4780 - policy_acc: 0.7265 - value_acc: 0.7617 - val_loss: 5.2329 - val_policy_loss: 4.1623 - val_value_loss: 0.5353 - val_policy_acc: 0.8003 - val_value_acc: 0.6902\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11790 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11790/11790 [==============================] - 0s 24us/step - loss: 5.5534 - policy_loss: 4.5168 - value_loss: 0.5183 - policy_acc: 0.7147 - value_acc: 0.7256 - val_loss: 5.2349 - val_policy_loss: 4.1630 - val_value_loss: 0.5359 - val_policy_acc: 0.8003 - val_value_acc: 0.6954\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11813 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11813/11813 [==============================] - 0s 23us/step - loss: 5.4847 - policy_loss: 4.4605 - value_loss: 0.5121 - policy_acc: 0.7245 - value_acc: 0.7149 - val_loss: 5.2428 - val_policy_loss: 4.1646 - val_value_loss: 0.5391 - val_policy_acc: 0.8003 - val_value_acc: 0.7108\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11644 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11644/11644 [==============================] - 0s 25us/step - loss: 5.4696 - policy_loss: 4.5015 - value_loss: 0.4840 - policy_acc: 0.7260 - value_acc: 0.7508 - val_loss: 5.2432 - val_policy_loss: 4.1625 - val_value_loss: 0.5404 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11788 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11788/11788 [==============================] - 0s 23us/step - loss: 5.4064 - policy_loss: 4.4359 - value_loss: 0.4853 - policy_acc: 0.7229 - value_acc: 0.7441 - val_loss: 5.2398 - val_policy_loss: 4.1596 - val_value_loss: 0.5401 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11882 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11882/11882 [==============================] - 0s 24us/step - loss: 5.5639 - policy_loss: 4.5317 - value_loss: 0.5161 - policy_acc: 0.7319 - value_acc: 0.7268 - val_loss: 5.2409 - val_policy_loss: 4.1644 - val_value_loss: 0.5383 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11768 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11768/11768 [==============================] - 0s 24us/step - loss: 5.5641 - policy_loss: 4.5348 - value_loss: 0.5147 - policy_acc: 0.7090 - value_acc: 0.7259 - val_loss: 5.2397 - val_policy_loss: 4.1626 - val_value_loss: 0.5385 - val_policy_acc: 0.8003 - val_value_acc: 0.7126\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11738 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11738/11738 [==============================] - 0s 24us/step - loss: 5.4446 - policy_loss: 4.4159 - value_loss: 0.5144 - policy_acc: 0.7379 - value_acc: 0.7235 - val_loss: 5.2426 - val_policy_loss: 4.1622 - val_value_loss: 0.5402 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11666 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11666/11666 [==============================] - 0s 23us/step - loss: 5.3937 - policy_loss: 4.4345 - value_loss: 0.4796 - policy_acc: 0.7369 - value_acc: 0.7437 - val_loss: 5.2487 - val_policy_loss: 4.1636 - val_value_loss: 0.5425 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11930 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11930/11930 [==============================] - 0s 24us/step - loss: 5.4355 - policy_loss: 4.4290 - value_loss: 0.5033 - policy_acc: 0.7111 - value_acc: 0.7433 - val_loss: 5.2464 - val_policy_loss: 4.1614 - val_value_loss: 0.5425 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11951 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11951/11951 [==============================] - 0s 26us/step - loss: 5.5418 - policy_loss: 4.4842 - value_loss: 0.5288 - policy_acc: 0.7354 - value_acc: 0.7121 - val_loss: 5.2499 - val_policy_loss: 4.1604 - val_value_loss: 0.5448 - val_policy_acc: 0.8003 - val_value_acc: 0.7126\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11750 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11750/11750 [==============================] - 0s 23us/step - loss: 5.3867 - policy_loss: 4.3881 - value_loss: 0.4993 - policy_acc: 0.7203 - value_acc: 0.7338 - val_loss: 5.2519 - val_policy_loss: 4.1595 - val_value_loss: 0.5462 - val_policy_acc: 0.8003 - val_value_acc: 0.7108\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11854 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11854/11854 [==============================] - 0s 24us/step - loss: 5.5723 - policy_loss: 4.5406 - value_loss: 0.5159 - policy_acc: 0.7121 - value_acc: 0.7226 - val_loss: 5.2555 - val_policy_loss: 4.1600 - val_value_loss: 0.5478 - val_policy_acc: 0.8003 - val_value_acc: 0.7040\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11973 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11973/11973 [==============================] - 0s 24us/step - loss: 5.4401 - policy_loss: 4.4753 - value_loss: 0.4824 - policy_acc: 0.7182 - value_acc: 0.7486 - val_loss: 5.2581 - val_policy_loss: 4.1623 - val_value_loss: 0.5479 - val_policy_acc: 0.8003 - val_value_acc: 0.6971\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11894 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11894/11894 [==============================] - 0s 23us/step - loss: 5.4899 - policy_loss: 4.4529 - value_loss: 0.5185 - policy_acc: 0.7226 - value_acc: 0.7194 - val_loss: 5.2584 - val_policy_loss: 4.1616 - val_value_loss: 0.5484 - val_policy_acc: 0.8003 - val_value_acc: 0.6971\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11823 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11823/11823 [==============================] - 0s 25us/step - loss: 5.4929 - policy_loss: 4.5428 - value_loss: 0.4751 - policy_acc: 0.7005 - value_acc: 0.7640 - val_loss: 5.2566 - val_policy_loss: 4.1608 - val_value_loss: 0.5479 - val_policy_acc: 0.8003 - val_value_acc: 0.6885\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11918 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11918/11918 [==============================] - 0s 23us/step - loss: 5.5624 - policy_loss: 4.5548 - value_loss: 0.5038 - policy_acc: 0.6874 - value_acc: 0.7258 - val_loss: 5.2533 - val_policy_loss: 4.1604 - val_value_loss: 0.5465 - val_policy_acc: 0.8003 - val_value_acc: 0.6902\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11813 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11813/11813 [==============================] - 0s 24us/step - loss: 5.4228 - policy_loss: 4.4564 - value_loss: 0.4832 - policy_acc: 0.7319 - value_acc: 0.7582 - val_loss: 5.2439 - val_policy_loss: 4.1583 - val_value_loss: 0.5428 - val_policy_acc: 0.8003 - val_value_acc: 0.7194\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11910 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11910/11910 [==============================] - 0s 23us/step - loss: 5.5731 - policy_loss: 4.5503 - value_loss: 0.5114 - policy_acc: 0.7040 - value_acc: 0.7347 - val_loss: 5.2438 - val_policy_loss: 4.1581 - val_value_loss: 0.5428 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11891 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11891/11891 [==============================] - 0s 24us/step - loss: 5.5654 - policy_loss: 4.5511 - value_loss: 0.5071 - policy_acc: 0.7031 - value_acc: 0.7158 - val_loss: 5.2572 - val_policy_loss: 4.1609 - val_value_loss: 0.5482 - val_policy_acc: 0.8003 - val_value_acc: 0.7229\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11577 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11577/11577 [==============================] - 0s 23us/step - loss: 5.5260 - policy_loss: 4.5503 - value_loss: 0.4879 - policy_acc: 0.7061 - value_acc: 0.7438 - val_loss: 5.2660 - val_policy_loss: 4.1582 - val_value_loss: 0.5539 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11779 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11779/11779 [==============================] - 0s 27us/step - loss: 5.4154 - policy_loss: 4.4336 - value_loss: 0.4909 - policy_acc: 0.7415 - value_acc: 0.7427 - val_loss: 5.2586 - val_policy_loss: 4.1580 - val_value_loss: 0.5503 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11916 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11916/11916 [==============================] - 0s 23us/step - loss: 5.5348 - policy_loss: 4.5476 - value_loss: 0.4936 - policy_acc: 0.7054 - value_acc: 0.7423 - val_loss: 5.2475 - val_policy_loss: 4.1604 - val_value_loss: 0.5435 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11819 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11819/11819 [==============================] - 0s 25us/step - loss: 5.5390 - policy_loss: 4.5237 - value_loss: 0.5076 - policy_acc: 0.7172 - value_acc: 0.7367 - val_loss: 5.2456 - val_policy_loss: 4.1597 - val_value_loss: 0.5430 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11846 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11846/11846 [==============================] - 0s 24us/step - loss: 5.5785 - policy_loss: 4.5102 - value_loss: 0.5341 - policy_acc: 0.7343 - value_acc: 0.7202 - val_loss: 5.2519 - val_policy_loss: 4.1601 - val_value_loss: 0.5459 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11732 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11732/11732 [==============================] - 0s 23us/step - loss: 5.5374 - policy_loss: 4.5041 - value_loss: 0.5166 - policy_acc: 0.7191 - value_acc: 0.7239 - val_loss: 5.2520 - val_policy_loss: 4.1596 - val_value_loss: 0.5462 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11788 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11788/11788 [==============================] - 0s 23us/step - loss: 5.5947 - policy_loss: 4.5299 - value_loss: 0.5324 - policy_acc: 0.7245 - value_acc: 0.7269 - val_loss: 5.2596 - val_policy_loss: 4.1617 - val_value_loss: 0.5490 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11858 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11858/11858 [==============================] - 0s 24us/step - loss: 5.5120 - policy_loss: 4.4915 - value_loss: 0.5103 - policy_acc: 0.7144 - value_acc: 0.7413 - val_loss: 5.2611 - val_policy_loss: 4.1628 - val_value_loss: 0.5491 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11973 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11973/11973 [==============================] - 0s 23us/step - loss: 5.5439 - policy_loss: 4.4721 - value_loss: 0.5359 - policy_acc: 0.7205 - value_acc: 0.7043 - val_loss: 5.2657 - val_policy_loss: 4.1608 - val_value_loss: 0.5524 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11731 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11731/11731 [==============================] - 0s 24us/step - loss: 5.4706 - policy_loss: 4.4263 - value_loss: 0.5222 - policy_acc: 0.7364 - value_acc: 0.7240 - val_loss: 5.2684 - val_policy_loss: 4.1598 - val_value_loss: 0.5543 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11648 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11648/11648 [==============================] - 0s 24us/step - loss: 5.4829 - policy_loss: 4.4738 - value_loss: 0.5046 - policy_acc: 0.7444 - value_acc: 0.7355 - val_loss: 5.2635 - val_policy_loss: 4.1598 - val_value_loss: 0.5518 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11933 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11933/11933 [==============================] - 0s 24us/step - loss: 5.4425 - policy_loss: 4.4530 - value_loss: 0.4947 - policy_acc: 0.7223 - value_acc: 0.7457 - val_loss: 5.2610 - val_policy_loss: 4.1617 - val_value_loss: 0.5496 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11859 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11859/11859 [==============================] - 0s 23us/step - loss: 5.5081 - policy_loss: 4.5189 - value_loss: 0.4946 - policy_acc: 0.7044 - value_acc: 0.7340 - val_loss: 5.2598 - val_policy_loss: 4.1642 - val_value_loss: 0.5478 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11932 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11932/11932 [==============================] - 0s 23us/step - loss: 5.4160 - policy_loss: 4.4096 - value_loss: 0.5032 - policy_acc: 0.7373 - value_acc: 0.7356 - val_loss: 5.2527 - val_policy_loss: 4.1633 - val_value_loss: 0.5447 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11900 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11900/11900 [==============================] - 0s 25us/step - loss: 5.5367 - policy_loss: 4.5798 - value_loss: 0.4785 - policy_acc: 0.7243 - value_acc: 0.7512 - val_loss: 5.2484 - val_policy_loss: 4.1612 - val_value_loss: 0.5436 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11897 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11897/11897 [==============================] - 0s 24us/step - loss: 5.4866 - policy_loss: 4.5218 - value_loss: 0.4824 - policy_acc: 0.7198 - value_acc: 0.7536 - val_loss: 5.2439 - val_policy_loss: 4.1605 - val_value_loss: 0.5417 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11865 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11865/11865 [==============================] - 0s 23us/step - loss: 5.4429 - policy_loss: 4.4193 - value_loss: 0.5118 - policy_acc: 0.7375 - value_acc: 0.7313 - val_loss: 5.2406 - val_policy_loss: 4.1615 - val_value_loss: 0.5396 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11858 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11858/11858 [==============================] - 0s 23us/step - loss: 5.5503 - policy_loss: 4.5048 - value_loss: 0.5227 - policy_acc: 0.7196 - value_acc: 0.7260 - val_loss: 5.2563 - val_policy_loss: 4.1648 - val_value_loss: 0.5458 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11850 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11850/11850 [==============================] - 0s 24us/step - loss: 5.5054 - policy_loss: 4.4761 - value_loss: 0.5147 - policy_acc: 0.6988 - value_acc: 0.7203 - val_loss: 5.2714 - val_policy_loss: 4.1632 - val_value_loss: 0.5541 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11810 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11810/11810 [==============================] - 0s 24us/step - loss: 5.5002 - policy_loss: 4.4963 - value_loss: 0.5020 - policy_acc: 0.7185 - value_acc: 0.7412 - val_loss: 5.2693 - val_policy_loss: 4.1598 - val_value_loss: 0.5548 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11992 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11992/11992 [==============================] - 0s 24us/step - loss: 5.4305 - policy_loss: 4.4748 - value_loss: 0.4778 - policy_acc: 0.7221 - value_acc: 0.7467 - val_loss: 5.2585 - val_policy_loss: 4.1627 - val_value_loss: 0.5479 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11584 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11584/11584 [==============================] - 0s 23us/step - loss: 5.3827 - policy_loss: 4.4627 - value_loss: 0.4600 - policy_acc: 0.7285 - value_acc: 0.7648 - val_loss: 5.2403 - val_policy_loss: 4.1621 - val_value_loss: 0.5391 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11769 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11769/11769 [==============================] - 0s 23us/step - loss: 5.5563 - policy_loss: 4.5420 - value_loss: 0.5071 - policy_acc: 0.7243 - value_acc: 0.7323 - val_loss: 5.2259 - val_policy_loss: 4.1615 - val_value_loss: 0.5322 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11549 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11549/11549 [==============================] - 0s 24us/step - loss: 5.4540 - policy_loss: 4.4531 - value_loss: 0.5004 - policy_acc: 0.7295 - value_acc: 0.7304 - val_loss: 5.2336 - val_policy_loss: 4.1612 - val_value_loss: 0.5362 - val_policy_acc: 0.8003 - val_value_acc: 0.7298\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11932 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11932/11932 [==============================] - 0s 23us/step - loss: 5.4498 - policy_loss: 4.4517 - value_loss: 0.4990 - policy_acc: 0.7171 - value_acc: 0.7351 - val_loss: 5.2517 - val_policy_loss: 4.1628 - val_value_loss: 0.5444 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11923 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11923/11923 [==============================] - 0s 24us/step - loss: 5.4352 - policy_loss: 4.4256 - value_loss: 0.5048 - policy_acc: 0.7457 - value_acc: 0.7373 - val_loss: 5.2612 - val_policy_loss: 4.1615 - val_value_loss: 0.5499 - val_policy_acc: 0.8003 - val_value_acc: 0.7126\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11905 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11905/11905 [==============================] - 0s 25us/step - loss: 5.4412 - policy_loss: 4.4530 - value_loss: 0.4941 - policy_acc: 0.7414 - value_acc: 0.7436 - val_loss: 5.2571 - val_policy_loss: 4.1605 - val_value_loss: 0.5483 - val_policy_acc: 0.8003 - val_value_acc: 0.7212\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11749 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11749/11749 [==============================] - 0s 24us/step - loss: 5.4053 - policy_loss: 4.5015 - value_loss: 0.4519 - policy_acc: 0.6941 - value_acc: 0.7726 - val_loss: 5.2432 - val_policy_loss: 4.1581 - val_value_loss: 0.5426 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11874 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11874/11874 [==============================] - 0s 24us/step - loss: 5.4179 - policy_loss: 4.4349 - value_loss: 0.4915 - policy_acc: 0.7580 - value_acc: 0.7431 - val_loss: 5.2362 - val_policy_loss: 4.1606 - val_value_loss: 0.5378 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11804 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11804/11804 [==============================] - 0s 24us/step - loss: 5.6000 - policy_loss: 4.5101 - value_loss: 0.5450 - policy_acc: 0.7264 - value_acc: 0.7061 - val_loss: 5.2472 - val_policy_loss: 4.1644 - val_value_loss: 0.5414 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11787 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11787/11787 [==============================] - 0s 23us/step - loss: 5.4999 - policy_loss: 4.5136 - value_loss: 0.4932 - policy_acc: 0.6995 - value_acc: 0.7374 - val_loss: 5.2559 - val_policy_loss: 4.1615 - val_value_loss: 0.5472 - val_policy_acc: 0.8003 - val_value_acc: 0.7229\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11892 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11892/11892 [==============================] - 0s 23us/step - loss: 5.4505 - policy_loss: 4.4490 - value_loss: 0.5007 - policy_acc: 0.7110 - value_acc: 0.7371 - val_loss: 5.2538 - val_policy_loss: 4.1600 - val_value_loss: 0.5469 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11810 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11810/11810 [==============================] - 0s 26us/step - loss: 5.5059 - policy_loss: 4.5006 - value_loss: 0.5026 - policy_acc: 0.7336 - value_acc: 0.7342 - val_loss: 5.2593 - val_policy_loss: 4.1622 - val_value_loss: 0.5485 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11977 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11977/11977 [==============================] - 0s 23us/step - loss: 5.5353 - policy_loss: 4.5058 - value_loss: 0.5147 - policy_acc: 0.7359 - value_acc: 0.7281 - val_loss: 5.2679 - val_policy_loss: 4.1638 - val_value_loss: 0.5521 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11882 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11882/11882 [==============================] - 0s 24us/step - loss: 5.4317 - policy_loss: 4.4626 - value_loss: 0.4845 - policy_acc: 0.7236 - value_acc: 0.7515 - val_loss: 5.2650 - val_policy_loss: 4.1618 - val_value_loss: 0.5516 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11853 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11853/11853 [==============================] - 0s 23us/step - loss: 5.4084 - policy_loss: 4.4366 - value_loss: 0.4859 - policy_acc: 0.7250 - value_acc: 0.7595 - val_loss: 5.2533 - val_policy_loss: 4.1621 - val_value_loss: 0.5456 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11885 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11885/11885 [==============================] - 0s 24us/step - loss: 5.5851 - policy_loss: 4.5945 - value_loss: 0.4953 - policy_acc: 0.7031 - value_acc: 0.7435 - val_loss: 5.2472 - val_policy_loss: 4.1628 - val_value_loss: 0.5422 - val_policy_acc: 0.8003 - val_value_acc: 0.7074\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11890 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11890/11890 [==============================] - 0s 24us/step - loss: 5.4720 - policy_loss: 4.5027 - value_loss: 0.4846 - policy_acc: 0.7143 - value_acc: 0.7468 - val_loss: 5.2419 - val_policy_loss: 4.1615 - val_value_loss: 0.5402 - val_policy_acc: 0.8003 - val_value_acc: 0.7298\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11783 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11783/11783 [==============================] - 0s 23us/step - loss: 5.4059 - policy_loss: 4.4895 - value_loss: 0.4582 - policy_acc: 0.7135 - value_acc: 0.7675 - val_loss: 5.2443 - val_policy_loss: 4.1604 - val_value_loss: 0.5419 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11673 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11673/11673 [==============================] - 0s 24us/step - loss: 5.4284 - policy_loss: 4.4865 - value_loss: 0.4709 - policy_acc: 0.7305 - value_acc: 0.7561 - val_loss: 5.2338 - val_policy_loss: 4.1584 - val_value_loss: 0.5377 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11957 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11957/11957 [==============================] - 0s 23us/step - loss: 5.5414 - policy_loss: 4.5352 - value_loss: 0.5031 - policy_acc: 0.7128 - value_acc: 0.7336 - val_loss: 5.2293 - val_policy_loss: 4.1595 - val_value_loss: 0.5349 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11787 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11787/11787 [==============================] - 0s 25us/step - loss: 5.5918 - policy_loss: 4.5336 - value_loss: 0.5291 - policy_acc: 0.7124 - value_acc: 0.7051 - val_loss: 5.2512 - val_policy_loss: 4.1620 - val_value_loss: 0.5446 - val_policy_acc: 0.8003 - val_value_acc: 0.7177\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11864 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11864/11864 [==============================] - 0s 23us/step - loss: 5.6074 - policy_loss: 4.5975 - value_loss: 0.5050 - policy_acc: 0.6685 - value_acc: 0.7364 - val_loss: 5.2657 - val_policy_loss: 4.1607 - val_value_loss: 0.5525 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11850 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11850/11850 [==============================] - 0s 23us/step - loss: 5.4860 - policy_loss: 4.4757 - value_loss: 0.5052 - policy_acc: 0.7324 - value_acc: 0.7262 - val_loss: 5.2716 - val_policy_loss: 4.1586 - val_value_loss: 0.5565 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11701 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11701/11701 [==============================] - 0s 24us/step - loss: 5.5511 - policy_loss: 4.5621 - value_loss: 0.4945 - policy_acc: 0.6941 - value_acc: 0.7307 - val_loss: 5.2697 - val_policy_loss: 4.1604 - val_value_loss: 0.5547 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11769 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11769/11769 [==============================] - 0s 23us/step - loss: 5.5452 - policy_loss: 4.5441 - value_loss: 0.5006 - policy_acc: 0.7141 - value_acc: 0.7394 - val_loss: 5.2627 - val_policy_loss: 4.1611 - val_value_loss: 0.5508 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11836 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11836/11836 [==============================] - 0s 25us/step - loss: 5.3636 - policy_loss: 4.3995 - value_loss: 0.4821 - policy_acc: 0.7421 - value_acc: 0.7564 - val_loss: 5.2521 - val_policy_loss: 4.1609 - val_value_loss: 0.5456 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11971 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11971/11971 [==============================] - 0s 24us/step - loss: 5.4867 - policy_loss: 4.4694 - value_loss: 0.5087 - policy_acc: 0.7510 - value_acc: 0.7343 - val_loss: 5.2439 - val_policy_loss: 4.1605 - val_value_loss: 0.5417 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11718 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11718/11718 [==============================] - 0s 24us/step - loss: 5.4062 - policy_loss: 4.4469 - value_loss: 0.4796 - policy_acc: 0.7209 - value_acc: 0.7500 - val_loss: 5.2405 - val_policy_loss: 4.1591 - val_value_loss: 0.5407 - val_policy_acc: 0.8003 - val_value_acc: 0.7177\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11884 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11884/11884 [==============================] - 0s 24us/step - loss: 5.5067 - policy_loss: 4.5330 - value_loss: 0.4869 - policy_acc: 0.7126 - value_acc: 0.7470 - val_loss: 5.2383 - val_policy_loss: 4.1581 - val_value_loss: 0.5401 - val_policy_acc: 0.8003 - val_value_acc: 0.7177\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11925 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11925/11925 [==============================] - 0s 24us/step - loss: 5.3899 - policy_loss: 4.4637 - value_loss: 0.4631 - policy_acc: 0.7026 - value_acc: 0.7674 - val_loss: 5.2350 - val_policy_loss: 4.1603 - val_value_loss: 0.5373 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11690 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11690/11690 [==============================] - 0s 23us/step - loss: 5.4636 - policy_loss: 4.5347 - value_loss: 0.4645 - policy_acc: 0.7092 - value_acc: 0.7630 - val_loss: 5.2276 - val_policy_loss: 4.1599 - val_value_loss: 0.5339 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11889 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11889/11889 [==============================] - 0s 24us/step - loss: 5.5325 - policy_loss: 4.4533 - value_loss: 0.5396 - policy_acc: 0.7272 - value_acc: 0.7116 - val_loss: 5.2334 - val_policy_loss: 4.1600 - val_value_loss: 0.5367 - val_policy_acc: 0.8003 - val_value_acc: 0.7315\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11947 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11947/11947 [==============================] - 0s 24us/step - loss: 5.5273 - policy_loss: 4.6010 - value_loss: 0.4631 - policy_acc: 0.6887 - value_acc: 0.7614 - val_loss: 5.2453 - val_policy_loss: 4.1605 - val_value_loss: 0.5424 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11552 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11552/11552 [==============================] - 0s 24us/step - loss: 5.4726 - policy_loss: 4.4887 - value_loss: 0.4919 - policy_acc: 0.7017 - value_acc: 0.7406 - val_loss: 5.2499 - val_policy_loss: 4.1601 - val_value_loss: 0.5449 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11710 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11710/11710 [==============================] - 0s 23us/step - loss: 5.5575 - policy_loss: 4.4953 - value_loss: 0.5311 - policy_acc: 0.7164 - value_acc: 0.7173 - val_loss: 5.2518 - val_policy_loss: 4.1632 - val_value_loss: 0.5443 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11768 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11768/11768 [==============================] - 0s 24us/step - loss: 5.5239 - policy_loss: 4.5811 - value_loss: 0.4714 - policy_acc: 0.7113 - value_acc: 0.7572 - val_loss: 5.2514 - val_policy_loss: 4.1619 - val_value_loss: 0.5448 - val_policy_acc: 0.8003 - val_value_acc: 0.7177\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11975 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11975/11975 [==============================] - 0s 23us/step - loss: 5.4895 - policy_loss: 4.5010 - value_loss: 0.4943 - policy_acc: 0.7322 - value_acc: 0.7300 - val_loss: 5.2440 - val_policy_loss: 4.1610 - val_value_loss: 0.5415 - val_policy_acc: 0.8003 - val_value_acc: 0.7212\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11887 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11887/11887 [==============================] - 0s 23us/step - loss: 5.5590 - policy_loss: 4.5181 - value_loss: 0.5204 - policy_acc: 0.7163 - value_acc: 0.7133 - val_loss: 5.2396 - val_policy_loss: 4.1617 - val_value_loss: 0.5390 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11800 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11800/11800 [==============================] - 0s 23us/step - loss: 5.4690 - policy_loss: 4.5188 - value_loss: 0.4751 - policy_acc: 0.6961 - value_acc: 0.7615 - val_loss: 5.2364 - val_policy_loss: 4.1598 - val_value_loss: 0.5383 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11868 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11868/11868 [==============================] - 0s 25us/step - loss: 5.4988 - policy_loss: 4.4885 - value_loss: 0.5052 - policy_acc: 0.7156 - value_acc: 0.7235 - val_loss: 5.2389 - val_policy_loss: 4.1579 - val_value_loss: 0.5405 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11992 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11992/11992 [==============================] - 0s 23us/step - loss: 5.5114 - policy_loss: 4.5405 - value_loss: 0.4855 - policy_acc: 0.7293 - value_acc: 0.7382 - val_loss: 5.2378 - val_policy_loss: 4.1585 - val_value_loss: 0.5396 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11898 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11898/11898 [==============================] - 0s 23us/step - loss: 5.6466 - policy_loss: 4.6334 - value_loss: 0.5066 - policy_acc: 0.6691 - value_acc: 0.7260 - val_loss: 5.2402 - val_policy_loss: 4.1600 - val_value_loss: 0.5401 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11954 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11954/11954 [==============================] - 0s 23us/step - loss: 5.5866 - policy_loss: 4.5595 - value_loss: 0.5136 - policy_acc: 0.6952 - value_acc: 0.7200 - val_loss: 5.2494 - val_policy_loss: 4.1620 - val_value_loss: 0.5437 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11858 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11858/11858 [==============================] - 0s 24us/step - loss: 5.4834 - policy_loss: 4.4679 - value_loss: 0.5077 - policy_acc: 0.7181 - value_acc: 0.7267 - val_loss: 5.2527 - val_policy_loss: 4.1620 - val_value_loss: 0.5454 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11722 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11722/11722 [==============================] - 0s 24us/step - loss: 5.4667 - policy_loss: 4.5044 - value_loss: 0.4811 - policy_acc: 0.7188 - value_acc: 0.7433 - val_loss: 5.2459 - val_policy_loss: 4.1614 - val_value_loss: 0.5422 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11907 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11907/11907 [==============================] - 0s 23us/step - loss: 5.5907 - policy_loss: 4.5410 - value_loss: 0.5248 - policy_acc: 0.7077 - value_acc: 0.7176 - val_loss: 5.2468 - val_policy_loss: 4.1622 - val_value_loss: 0.5423 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11864 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11864/11864 [==============================] - 0s 23us/step - loss: 5.5659 - policy_loss: 4.5155 - value_loss: 0.5252 - policy_acc: 0.7022 - value_acc: 0.7186 - val_loss: 5.2535 - val_policy_loss: 4.1596 - val_value_loss: 0.5470 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11973 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11973/11973 [==============================] - 0s 24us/step - loss: 5.4772 - policy_loss: 4.5049 - value_loss: 0.4861 - policy_acc: 0.7148 - value_acc: 0.7505 - val_loss: 5.2524 - val_policy_loss: 4.1583 - val_value_loss: 0.5470 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11943 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11943/11943 [==============================] - 0s 24us/step - loss: 5.4837 - policy_loss: 4.4653 - value_loss: 0.5092 - policy_acc: 0.7090 - value_acc: 0.7141 - val_loss: 5.2485 - val_policy_loss: 4.1603 - val_value_loss: 0.5441 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11824 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11824/11824 [==============================] - 0s 24us/step - loss: 5.5970 - policy_loss: 4.4855 - value_loss: 0.5558 - policy_acc: 0.7259 - value_acc: 0.6980 - val_loss: 5.2508 - val_policy_loss: 4.1611 - val_value_loss: 0.5448 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11946 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11946/11946 [==============================] - 0s 25us/step - loss: 5.4960 - policy_loss: 4.4578 - value_loss: 0.5191 - policy_acc: 0.7366 - value_acc: 0.7294 - val_loss: 5.2491 - val_policy_loss: 4.1606 - val_value_loss: 0.5443 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11802 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11802/11802 [==============================] - 0s 24us/step - loss: 5.4554 - policy_loss: 4.5028 - value_loss: 0.4763 - policy_acc: 0.7016 - value_acc: 0.7527 - val_loss: 5.2427 - val_policy_loss: 4.1591 - val_value_loss: 0.5418 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11954 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11954/11954 [==============================] - 0s 23us/step - loss: 5.5456 - policy_loss: 4.5077 - value_loss: 0.5190 - policy_acc: 0.7193 - value_acc: 0.7251 - val_loss: 5.2378 - val_policy_loss: 4.1593 - val_value_loss: 0.5392 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11688 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11688/11688 [==============================] - 0s 25us/step - loss: 5.4851 - policy_loss: 4.5187 - value_loss: 0.4832 - policy_acc: 0.7098 - value_acc: 0.7555 - val_loss: 5.2301 - val_policy_loss: 4.1597 - val_value_loss: 0.5352 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11746 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11746/11746 [==============================] - 0s 23us/step - loss: 5.4673 - policy_loss: 4.4880 - value_loss: 0.4896 - policy_acc: 0.7232 - value_acc: 0.7476 - val_loss: 5.2190 - val_policy_loss: 4.1596 - val_value_loss: 0.5297 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11819 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11819/11819 [==============================] - 0s 23us/step - loss: 5.5790 - policy_loss: 4.5510 - value_loss: 0.5140 - policy_acc: 0.7063 - value_acc: 0.7303 - val_loss: 5.2235 - val_policy_loss: 4.1603 - val_value_loss: 0.5316 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11859 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11859/11859 [==============================] - 0s 23us/step - loss: 5.4786 - policy_loss: 4.4357 - value_loss: 0.5215 - policy_acc: 0.7262 - value_acc: 0.7211 - val_loss: 5.2319 - val_policy_loss: 4.1605 - val_value_loss: 0.5357 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11576 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11576/11576 [==============================] - 0s 25us/step - loss: 5.4017 - policy_loss: 4.3935 - value_loss: 0.5041 - policy_acc: 0.7268 - value_acc: 0.7344 - val_loss: 5.2376 - val_policy_loss: 4.1596 - val_value_loss: 0.5390 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11785 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11785/11785 [==============================] - 0s 23us/step - loss: 5.6016 - policy_loss: 4.5825 - value_loss: 0.5095 - policy_acc: 0.7090 - value_acc: 0.7338 - val_loss: 5.2479 - val_policy_loss: 4.1627 - val_value_loss: 0.5426 - val_policy_acc: 0.8003 - val_value_acc: 0.7315\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11856 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11856/11856 [==============================] - 0s 23us/step - loss: 5.4521 - policy_loss: 4.4722 - value_loss: 0.4899 - policy_acc: 0.7158 - value_acc: 0.7470 - val_loss: 5.2487 - val_policy_loss: 4.1620 - val_value_loss: 0.5434 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11882 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11882/11882 [==============================] - 0s 23us/step - loss: 5.4739 - policy_loss: 4.4660 - value_loss: 0.5040 - policy_acc: 0.7424 - value_acc: 0.7463 - val_loss: 5.2451 - val_policy_loss: 4.1595 - val_value_loss: 0.5428 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11880 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11880/11880 [==============================] - 0s 24us/step - loss: 5.5343 - policy_loss: 4.5181 - value_loss: 0.5081 - policy_acc: 0.7139 - value_acc: 0.7241 - val_loss: 5.2440 - val_policy_loss: 4.1573 - val_value_loss: 0.5433 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11898 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11898/11898 [==============================] - 0s 26us/step - loss: 5.5439 - policy_loss: 4.5467 - value_loss: 0.4986 - policy_acc: 0.7148 - value_acc: 0.7466 - val_loss: 5.2494 - val_policy_loss: 4.1589 - val_value_loss: 0.5453 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11817 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11817/11817 [==============================] - 0s 23us/step - loss: 5.5455 - policy_loss: 4.5238 - value_loss: 0.5108 - policy_acc: 0.7215 - value_acc: 0.7267 - val_loss: 5.2525 - val_policy_loss: 4.1588 - val_value_loss: 0.5468 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11768 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11768/11768 [==============================] - 0s 25us/step - loss: 5.5146 - policy_loss: 4.4634 - value_loss: 0.5256 - policy_acc: 0.7260 - value_acc: 0.7235 - val_loss: 5.2490 - val_policy_loss: 4.1573 - val_value_loss: 0.5458 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11861 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11861/11861 [==============================] - 0s 24us/step - loss: 5.5058 - policy_loss: 4.5164 - value_loss: 0.4947 - policy_acc: 0.7327 - value_acc: 0.7417 - val_loss: 5.2469 - val_policy_loss: 4.1588 - val_value_loss: 0.5440 - val_policy_acc: 0.8003 - val_value_acc: 0.7229\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11774 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11774/11774 [==============================] - 0s 26us/step - loss: 5.5888 - policy_loss: 4.5551 - value_loss: 0.5168 - policy_acc: 0.6847 - value_acc: 0.7270 - val_loss: 5.2454 - val_policy_loss: 4.1609 - val_value_loss: 0.5423 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11912 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11912/11912 [==============================] - 0s 23us/step - loss: 5.5149 - policy_loss: 4.4901 - value_loss: 0.5124 - policy_acc: 0.7177 - value_acc: 0.7280 - val_loss: 5.2508 - val_policy_loss: 4.1598 - val_value_loss: 0.5455 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11875 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11875/11875 [==============================] - 0s 24us/step - loss: 5.4041 - policy_loss: 4.4482 - value_loss: 0.4780 - policy_acc: 0.7469 - value_acc: 0.7597 - val_loss: 5.2493 - val_policy_loss: 4.1592 - val_value_loss: 0.5451 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11891 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11891/11891 [==============================] - 0s 23us/step - loss: 5.5729 - policy_loss: 4.5711 - value_loss: 0.5009 - policy_acc: 0.7014 - value_acc: 0.7280 - val_loss: 5.2384 - val_policy_loss: 4.1607 - val_value_loss: 0.5388 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11894 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11894/11894 [==============================] - 0s 25us/step - loss: 5.4624 - policy_loss: 4.4816 - value_loss: 0.4904 - policy_acc: 0.7380 - value_acc: 0.7533 - val_loss: 5.2430 - val_policy_loss: 4.1615 - val_value_loss: 0.5407 - val_policy_acc: 0.8003 - val_value_acc: 0.7194\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11982 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11982/11982 [==============================] - 0s 24us/step - loss: 5.5671 - policy_loss: 4.4936 - value_loss: 0.5367 - policy_acc: 0.7199 - value_acc: 0.7101 - val_loss: 5.2534 - val_policy_loss: 4.1609 - val_value_loss: 0.5462 - val_policy_acc: 0.8003 - val_value_acc: 0.6919\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11893 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11893/11893 [==============================] - 0s 25us/step - loss: 5.5565 - policy_loss: 4.5227 - value_loss: 0.5169 - policy_acc: 0.6971 - value_acc: 0.7238 - val_loss: 5.2695 - val_policy_loss: 4.1621 - val_value_loss: 0.5537 - val_policy_acc: 0.8003 - val_value_acc: 0.6867\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11712 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11712/11712 [==============================] - 0s 24us/step - loss: 5.5074 - policy_loss: 4.5193 - value_loss: 0.4940 - policy_acc: 0.6993 - value_acc: 0.7403 - val_loss: 5.2728 - val_policy_loss: 4.1600 - val_value_loss: 0.5564 - val_policy_acc: 0.8003 - val_value_acc: 0.6919\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11727 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11727/11727 [==============================] - 0s 24us/step - loss: 5.4976 - policy_loss: 4.4987 - value_loss: 0.4995 - policy_acc: 0.7214 - value_acc: 0.7236 - val_loss: 5.2669 - val_policy_loss: 4.1601 - val_value_loss: 0.5534 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11889 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11889/11889 [==============================] - 0s 24us/step - loss: 5.5149 - policy_loss: 4.5323 - value_loss: 0.4913 - policy_acc: 0.7164 - value_acc: 0.7361 - val_loss: 5.2571 - val_policy_loss: 4.1617 - val_value_loss: 0.5477 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11913 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11913/11913 [==============================] - 0s 23us/step - loss: 5.5127 - policy_loss: 4.5250 - value_loss: 0.4939 - policy_acc: 0.7112 - value_acc: 0.7439 - val_loss: 5.2492 - val_policy_loss: 4.1617 - val_value_loss: 0.5438 - val_policy_acc: 0.8003 - val_value_acc: 0.7298\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11811 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11811/11811 [==============================] - 0s 23us/step - loss: 5.4816 - policy_loss: 4.4934 - value_loss: 0.4941 - policy_acc: 0.7051 - value_acc: 0.7510 - val_loss: 5.2416 - val_policy_loss: 4.1601 - val_value_loss: 0.5408 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11910 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11910/11910 [==============================] - 0s 24us/step - loss: 5.3098 - policy_loss: 4.3909 - value_loss: 0.4595 - policy_acc: 0.7335 - value_acc: 0.7746 - val_loss: 5.2301 - val_policy_loss: 4.1583 - val_value_loss: 0.5359 - val_policy_acc: 0.8003 - val_value_acc: 0.7194\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11926 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11926/11926 [==============================] - 0s 24us/step - loss: 5.5210 - policy_loss: 4.4887 - value_loss: 0.5161 - policy_acc: 0.7068 - value_acc: 0.7193 - val_loss: 5.2325 - val_policy_loss: 4.1598 - val_value_loss: 0.5363 - val_policy_acc: 0.8003 - val_value_acc: 0.7005\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11886 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11886/11886 [==============================] - 0s 24us/step - loss: 5.5583 - policy_loss: 4.4808 - value_loss: 0.5387 - policy_acc: 0.6875 - value_acc: 0.7099 - val_loss: 5.2383 - val_policy_loss: 4.1578 - val_value_loss: 0.5402 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11844 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11844/11844 [==============================] - 0s 24us/step - loss: 5.5087 - policy_loss: 4.4504 - value_loss: 0.5291 - policy_acc: 0.7367 - value_acc: 0.7177 - val_loss: 5.2601 - val_policy_loss: 4.1578 - val_value_loss: 0.5512 - val_policy_acc: 0.8003 - val_value_acc: 0.7108\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11804 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11804/11804 [==============================] - 0s 23us/step - loss: 5.3418 - policy_loss: 4.3939 - value_loss: 0.4739 - policy_acc: 0.7309 - value_acc: 0.7595 - val_loss: 5.2563 - val_policy_loss: 4.1578 - val_value_loss: 0.5493 - val_policy_acc: 0.8003 - val_value_acc: 0.7108\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11868 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11868/11868 [==============================] - 0s 23us/step - loss: 5.3813 - policy_loss: 4.3884 - value_loss: 0.4964 - policy_acc: 0.7299 - value_acc: 0.7387 - val_loss: 5.2404 - val_policy_loss: 4.1577 - val_value_loss: 0.5414 - val_policy_acc: 0.8003 - val_value_acc: 0.7143\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11835 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11835/11835 [==============================] - 0s 24us/step - loss: 5.5049 - policy_loss: 4.5414 - value_loss: 0.4817 - policy_acc: 0.7323 - value_acc: 0.7472 - val_loss: 5.2334 - val_policy_loss: 4.1599 - val_value_loss: 0.5368 - val_policy_acc: 0.8003 - val_value_acc: 0.7074\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11717 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11717/11717 [==============================] - 0s 24us/step - loss: 5.5582 - policy_loss: 4.5404 - value_loss: 0.5089 - policy_acc: 0.7110 - value_acc: 0.7288 - val_loss: 5.2325 - val_policy_loss: 4.1605 - val_value_loss: 0.5360 - val_policy_acc: 0.8003 - val_value_acc: 0.7229\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11807 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11807/11807 [==============================] - 0s 23us/step - loss: 5.4814 - policy_loss: 4.5028 - value_loss: 0.4893 - policy_acc: 0.7241 - value_acc: 0.7440 - val_loss: 5.2317 - val_policy_loss: 4.1587 - val_value_loss: 0.5365 - val_policy_acc: 0.8003 - val_value_acc: 0.7229\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11812 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11812/11812 [==============================] - 0s 25us/step - loss: 5.3876 - policy_loss: 4.4292 - value_loss: 0.4792 - policy_acc: 0.7500 - value_acc: 0.7470 - val_loss: 5.2277 - val_policy_loss: 4.1560 - val_value_loss: 0.5358 - val_policy_acc: 0.8003 - val_value_acc: 0.7194\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11779 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11779/11779 [==============================] - 0s 23us/step - loss: 5.5118 - policy_loss: 4.4970 - value_loss: 0.5074 - policy_acc: 0.7248 - value_acc: 0.7338 - val_loss: 5.2334 - val_policy_loss: 4.1579 - val_value_loss: 0.5377 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11936 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11936/11936 [==============================] - 0s 24us/step - loss: 5.4823 - policy_loss: 4.4710 - value_loss: 0.5056 - policy_acc: 0.7288 - value_acc: 0.7257 - val_loss: 5.2422 - val_policy_loss: 4.1590 - val_value_loss: 0.5416 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11765 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11765/11765 [==============================] - 0s 24us/step - loss: 5.5036 - policy_loss: 4.4762 - value_loss: 0.5137 - policy_acc: 0.7406 - value_acc: 0.7170 - val_loss: 5.2498 - val_policy_loss: 4.1600 - val_value_loss: 0.5449 - val_policy_acc: 0.8003 - val_value_acc: 0.7194\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11690 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11690/11690 [==============================] - 0s 24us/step - loss: 5.4305 - policy_loss: 4.4502 - value_loss: 0.4902 - policy_acc: 0.7361 - value_acc: 0.7411 - val_loss: 5.2565 - val_policy_loss: 4.1607 - val_value_loss: 0.5479 - val_policy_acc: 0.8003 - val_value_acc: 0.7022\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11867 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11867/11867 [==============================] - 0s 23us/step - loss: 5.4478 - policy_loss: 4.4261 - value_loss: 0.5109 - policy_acc: 0.7492 - value_acc: 0.7318 - val_loss: 5.2570 - val_policy_loss: 4.1611 - val_value_loss: 0.5479 - val_policy_acc: 0.8003 - val_value_acc: 0.7091\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11720 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11720/11720 [==============================] - 0s 24us/step - loss: 5.4761 - policy_loss: 4.5056 - value_loss: 0.4853 - policy_acc: 0.7239 - value_acc: 0.7475 - val_loss: 5.2475 - val_policy_loss: 4.1590 - val_value_loss: 0.5443 - val_policy_acc: 0.8003 - val_value_acc: 0.7074\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11821 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11821/11821 [==============================] - 0s 23us/step - loss: 5.5221 - policy_loss: 4.5723 - value_loss: 0.4749 - policy_acc: 0.7076 - value_acc: 0.7628 - val_loss: 5.2431 - val_policy_loss: 4.1590 - val_value_loss: 0.5420 - val_policy_acc: 0.8003 - val_value_acc: 0.6988\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11853 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11853/11853 [==============================] - 0s 23us/step - loss: 5.5640 - policy_loss: 4.5384 - value_loss: 0.5128 - policy_acc: 0.7024 - value_acc: 0.7267 - val_loss: 5.2488 - val_policy_loss: 4.1621 - val_value_loss: 0.5433 - val_policy_acc: 0.8003 - val_value_acc: 0.6850\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11639 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11639/11639 [==============================] - 0s 24us/step - loss: 5.5945 - policy_loss: 4.5720 - value_loss: 0.5113 - policy_acc: 0.6936 - value_acc: 0.7295 - val_loss: 5.2486 - val_policy_loss: 4.1611 - val_value_loss: 0.5437 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11787 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11787/11787 [==============================] - 0s 25us/step - loss: 5.6276 - policy_loss: 4.5703 - value_loss: 0.5287 - policy_acc: 0.6956 - value_acc: 0.7131 - val_loss: 5.2605 - val_policy_loss: 4.1590 - val_value_loss: 0.5508 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11789 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11789/11789 [==============================] - 0s 25us/step - loss: 5.4226 - policy_loss: 4.4122 - value_loss: 0.5052 - policy_acc: 0.7349 - value_acc: 0.7376 - val_loss: 5.2674 - val_policy_loss: 4.1602 - val_value_loss: 0.5536 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11835 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11835/11835 [==============================] - 0s 24us/step - loss: 5.4945 - policy_loss: 4.5085 - value_loss: 0.4930 - policy_acc: 0.7242 - value_acc: 0.7437 - val_loss: 5.2619 - val_policy_loss: 4.1600 - val_value_loss: 0.5510 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11821 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11821/11821 [==============================] - 0s 24us/step - loss: 5.4638 - policy_loss: 4.4830 - value_loss: 0.4904 - policy_acc: 0.7139 - value_acc: 0.7478 - val_loss: 5.2494 - val_policy_loss: 4.1595 - val_value_loss: 0.5450 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11900 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11900/11900 [==============================] - 0s 23us/step - loss: 5.4608 - policy_loss: 4.5002 - value_loss: 0.4803 - policy_acc: 0.7342 - value_acc: 0.7545 - val_loss: 5.2404 - val_policy_loss: 4.1605 - val_value_loss: 0.5400 - val_policy_acc: 0.8003 - val_value_acc: 0.7074\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11937 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11937/11937 [==============================] - 0s 23us/step - loss: 5.6299 - policy_loss: 4.5689 - value_loss: 0.5305 - policy_acc: 0.7243 - value_acc: 0.6989 - val_loss: 5.2384 - val_policy_loss: 4.1635 - val_value_loss: 0.5374 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11787 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11787/11787 [==============================] - 0s 24us/step - loss: 5.4886 - policy_loss: 4.5104 - value_loss: 0.4891 - policy_acc: 0.6927 - value_acc: 0.7527 - val_loss: 5.2433 - val_policy_loss: 4.1625 - val_value_loss: 0.5404 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11676 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11676/11676 [==============================] - 0s 24us/step - loss: 5.4470 - policy_loss: 4.4744 - value_loss: 0.4863 - policy_acc: 0.7077 - value_acc: 0.7437 - val_loss: 5.2410 - val_policy_loss: 4.1581 - val_value_loss: 0.5414 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11678 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11678/11678 [==============================] - 0s 23us/step - loss: 5.5466 - policy_loss: 4.5833 - value_loss: 0.4817 - policy_acc: 0.6940 - value_acc: 0.7458 - val_loss: 5.2373 - val_policy_loss: 4.1587 - val_value_loss: 0.5393 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11855 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11855/11855 [==============================] - 0s 24us/step - loss: 5.5370 - policy_loss: 4.4778 - value_loss: 0.5296 - policy_acc: 0.7138 - value_acc: 0.7120 - val_loss: 5.2499 - val_policy_loss: 4.1624 - val_value_loss: 0.5437 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11721 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11721/11721 [==============================] - 0s 26us/step - loss: 5.4251 - policy_loss: 4.4417 - value_loss: 0.4917 - policy_acc: 0.7398 - value_acc: 0.7440 - val_loss: 5.2590 - val_policy_loss: 4.1639 - val_value_loss: 0.5475 - val_policy_acc: 0.8003 - val_value_acc: 0.7212\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11815 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11815/11815 [==============================] - 0s 24us/step - loss: 5.5204 - policy_loss: 4.5506 - value_loss: 0.4849 - policy_acc: 0.7177 - value_acc: 0.7499 - val_loss: 5.2506 - val_policy_loss: 4.1599 - val_value_loss: 0.5453 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11869 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11869/11869 [==============================] - 0s 24us/step - loss: 5.5658 - policy_loss: 4.4896 - value_loss: 0.5381 - policy_acc: 0.7195 - value_acc: 0.7046 - val_loss: 5.2502 - val_policy_loss: 4.1569 - val_value_loss: 0.5467 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11727 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11727/11727 [==============================] - 0s 23us/step - loss: 5.4912 - policy_loss: 4.4820 - value_loss: 0.5046 - policy_acc: 0.7408 - value_acc: 0.7334 - val_loss: 5.2467 - val_policy_loss: 4.1564 - val_value_loss: 0.5451 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11880 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11880/11880 [==============================] - 0s 23us/step - loss: 5.5281 - policy_loss: 4.5465 - value_loss: 0.4908 - policy_acc: 0.7251 - value_acc: 0.7479 - val_loss: 5.2416 - val_policy_loss: 4.1587 - val_value_loss: 0.5415 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11664 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11664/11664 [==============================] - 0s 24us/step - loss: 5.5406 - policy_loss: 4.4813 - value_loss: 0.5296 - policy_acc: 0.7103 - value_acc: 0.7162 - val_loss: 5.2447 - val_policy_loss: 4.1603 - val_value_loss: 0.5422 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11983 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11983/11983 [==============================] - 0s 23us/step - loss: 5.4594 - policy_loss: 4.4941 - value_loss: 0.4826 - policy_acc: 0.7038 - value_acc: 0.7555 - val_loss: 5.2432 - val_policy_loss: 4.1578 - val_value_loss: 0.5427 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11901 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11901/11901 [==============================] - 0s 23us/step - loss: 5.4122 - policy_loss: 4.4603 - value_loss: 0.4760 - policy_acc: 0.7251 - value_acc: 0.7537 - val_loss: 5.2349 - val_policy_loss: 4.1584 - val_value_loss: 0.5382 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11806 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11806/11806 [==============================] - 0s 24us/step - loss: 5.4965 - policy_loss: 4.4986 - value_loss: 0.4990 - policy_acc: 0.7103 - value_acc: 0.7311 - val_loss: 5.2349 - val_policy_loss: 4.1596 - val_value_loss: 0.5376 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11726 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11726/11726 [==============================] - 0s 25us/step - loss: 5.4455 - policy_loss: 4.4697 - value_loss: 0.4879 - policy_acc: 0.7192 - value_acc: 0.7413 - val_loss: 5.2387 - val_policy_loss: 4.1603 - val_value_loss: 0.5392 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11806 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11806/11806 [==============================] - 0s 23us/step - loss: 5.4923 - policy_loss: 4.4471 - value_loss: 0.5226 - policy_acc: 0.7256 - value_acc: 0.7331 - val_loss: 5.2462 - val_policy_loss: 4.1617 - val_value_loss: 0.5423 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11929 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11929/11929 [==============================] - 0s 26us/step - loss: 5.4244 - policy_loss: 4.4951 - value_loss: 0.4646 - policy_acc: 0.7098 - value_acc: 0.7576 - val_loss: 5.2548 - val_policy_loss: 4.1625 - val_value_loss: 0.5462 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11692 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11692/11692 [==============================] - 0s 23us/step - loss: 5.4078 - policy_loss: 4.4049 - value_loss: 0.5014 - policy_acc: 0.7337 - value_acc: 0.7345 - val_loss: 5.2541 - val_policy_loss: 4.1586 - val_value_loss: 0.5478 - val_policy_acc: 0.8003 - val_value_acc: 0.7229\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11810 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11810/11810 [==============================] - 0s 23us/step - loss: 5.4636 - policy_loss: 4.4571 - value_loss: 0.5033 - policy_acc: 0.7397 - value_acc: 0.7285 - val_loss: 5.2543 - val_policy_loss: 4.1580 - val_value_loss: 0.5481 - val_policy_acc: 0.8003 - val_value_acc: 0.7212\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11908 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11908/11908 [==============================] - 0s 24us/step - loss: 5.4504 - policy_loss: 4.4554 - value_loss: 0.4975 - policy_acc: 0.7344 - value_acc: 0.7330 - val_loss: 5.2527 - val_policy_loss: 4.1569 - val_value_loss: 0.5479 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11863 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11863/11863 [==============================] - 0s 24us/step - loss: 5.5149 - policy_loss: 4.4989 - value_loss: 0.5080 - policy_acc: 0.6970 - value_acc: 0.7268 - val_loss: 5.2525 - val_policy_loss: 4.1565 - val_value_loss: 0.5480 - val_policy_acc: 0.8003 - val_value_acc: 0.7143\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11794 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11794/11794 [==============================] - 0s 23us/step - loss: 5.4553 - policy_loss: 4.4844 - value_loss: 0.4855 - policy_acc: 0.7179 - value_acc: 0.7395 - val_loss: 5.2521 - val_policy_loss: 4.1582 - val_value_loss: 0.5470 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11896 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11896/11896 [==============================] - 0s 24us/step - loss: 5.5055 - policy_loss: 4.4711 - value_loss: 0.5172 - policy_acc: 0.7287 - value_acc: 0.7253 - val_loss: 5.2614 - val_policy_loss: 4.1613 - val_value_loss: 0.5501 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11824 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11824/11824 [==============================] - 0s 25us/step - loss: 5.5284 - policy_loss: 4.5259 - value_loss: 0.5013 - policy_acc: 0.7116 - value_acc: 0.7424 - val_loss: 5.2775 - val_policy_loss: 4.1607 - val_value_loss: 0.5584 - val_policy_acc: 0.8003 - val_value_acc: 0.6833\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11844 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11844/11844 [==============================] - 0s 23us/step - loss: 5.3898 - policy_loss: 4.4313 - value_loss: 0.4792 - policy_acc: 0.7422 - value_acc: 0.7588 - val_loss: 5.2818 - val_policy_loss: 4.1582 - val_value_loss: 0.5618 - val_policy_acc: 0.8003 - val_value_acc: 0.6678\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11876 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11876/11876 [==============================] - 0s 24us/step - loss: 5.4980 - policy_loss: 4.4800 - value_loss: 0.5090 - policy_acc: 0.7308 - value_acc: 0.7251 - val_loss: 5.2700 - val_policy_loss: 4.1574 - val_value_loss: 0.5563 - val_policy_acc: 0.8003 - val_value_acc: 0.7212\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11835 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11835/11835 [==============================] - 0s 24us/step - loss: 5.4527 - policy_loss: 4.4976 - value_loss: 0.4776 - policy_acc: 0.7069 - value_acc: 0.7529 - val_loss: 5.2632 - val_policy_loss: 4.1578 - val_value_loss: 0.5527 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11748 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11748/11748 [==============================] - 0s 24us/step - loss: 5.4326 - policy_loss: 4.4435 - value_loss: 0.4946 - policy_acc: 0.7279 - value_acc: 0.7473 - val_loss: 5.2561 - val_policy_loss: 4.1594 - val_value_loss: 0.5484 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11798 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11798/11798 [==============================] - 0s 24us/step - loss: 5.4897 - policy_loss: 4.5041 - value_loss: 0.4928 - policy_acc: 0.7192 - value_acc: 0.7421 - val_loss: 5.2572 - val_policy_loss: 4.1601 - val_value_loss: 0.5485 - val_policy_acc: 0.8003 - val_value_acc: 0.7022\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11889 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11889/11889 [==============================] - 0s 24us/step - loss: 5.5728 - policy_loss: 4.5317 - value_loss: 0.5206 - policy_acc: 0.6936 - value_acc: 0.7179 - val_loss: 5.2625 - val_policy_loss: 4.1599 - val_value_loss: 0.5513 - val_policy_acc: 0.8003 - val_value_acc: 0.7040\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11864 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11864/11864 [==============================] - 0s 24us/step - loss: 5.3764 - policy_loss: 4.4235 - value_loss: 0.4765 - policy_acc: 0.7339 - value_acc: 0.7460 - val_loss: 5.2615 - val_policy_loss: 4.1614 - val_value_loss: 0.5500 - val_policy_acc: 0.8003 - val_value_acc: 0.7074\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11982 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11982/11982 [==============================] - 0s 24us/step - loss: 5.6275 - policy_loss: 4.5490 - value_loss: 0.5392 - policy_acc: 0.7009 - value_acc: 0.6969 - val_loss: 5.2639 - val_policy_loss: 4.1641 - val_value_loss: 0.5499 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11890 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11890/11890 [==============================] - 0s 23us/step - loss: 5.4456 - policy_loss: 4.4730 - value_loss: 0.4863 - policy_acc: 0.7108 - value_acc: 0.7479 - val_loss: 5.2608 - val_policy_loss: 4.1615 - val_value_loss: 0.5497 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11815 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11815/11815 [==============================] - 0s 24us/step - loss: 5.5632 - policy_loss: 4.5044 - value_loss: 0.5294 - policy_acc: 0.7118 - value_acc: 0.7248 - val_loss: 5.2582 - val_policy_loss: 4.1600 - val_value_loss: 0.5491 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11879 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11879/11879 [==============================] - 0s 23us/step - loss: 5.5086 - policy_loss: 4.4621 - value_loss: 0.5232 - policy_acc: 0.7325 - value_acc: 0.7208 - val_loss: 5.2618 - val_policy_loss: 4.1601 - val_value_loss: 0.5509 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11966 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11966/11966 [==============================] - 0s 23us/step - loss: 5.4715 - policy_loss: 4.4546 - value_loss: 0.5085 - policy_acc: 0.7209 - value_acc: 0.7246 - val_loss: 5.2592 - val_policy_loss: 4.1590 - val_value_loss: 0.5501 - val_policy_acc: 0.8003 - val_value_acc: 0.7212\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11704 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11704/11704 [==============================] - 0s 24us/step - loss: 5.5612 - policy_loss: 4.4975 - value_loss: 0.5319 - policy_acc: 0.7227 - value_acc: 0.7059 - val_loss: 5.2661 - val_policy_loss: 4.1612 - val_value_loss: 0.5525 - val_policy_acc: 0.8003 - val_value_acc: 0.7298\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11810 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11810/11810 [==============================] - 0s 24us/step - loss: 5.4218 - policy_loss: 4.3938 - value_loss: 0.5140 - policy_acc: 0.7441 - value_acc: 0.7358 - val_loss: 5.2702 - val_policy_loss: 4.1601 - val_value_loss: 0.5551 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11854 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11854/11854 [==============================] - 0s 23us/step - loss: 5.4500 - policy_loss: 4.4907 - value_loss: 0.4797 - policy_acc: 0.7148 - value_acc: 0.7441 - val_loss: 5.2615 - val_policy_loss: 4.1611 - val_value_loss: 0.5502 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11711 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11711/11711 [==============================] - 0s 23us/step - loss: 5.4479 - policy_loss: 4.4543 - value_loss: 0.4968 - policy_acc: 0.7000 - value_acc: 0.7386 - val_loss: 5.2492 - val_policy_loss: 4.1609 - val_value_loss: 0.5442 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11791 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11791/11791 [==============================] - 0s 23us/step - loss: 5.5205 - policy_loss: 4.5017 - value_loss: 0.5094 - policy_acc: 0.6937 - value_acc: 0.7380 - val_loss: 5.2330 - val_policy_loss: 4.1586 - val_value_loss: 0.5372 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11786 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11786/11786 [==============================] - 0s 25us/step - loss: 5.4643 - policy_loss: 4.4813 - value_loss: 0.4915 - policy_acc: 0.7238 - value_acc: 0.7451 - val_loss: 5.2355 - val_policy_loss: 4.1605 - val_value_loss: 0.5375 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11633 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11633/11633 [==============================] - 0s 23us/step - loss: 5.5207 - policy_loss: 4.5187 - value_loss: 0.5010 - policy_acc: 0.7303 - value_acc: 0.7377 - val_loss: 5.2335 - val_policy_loss: 4.1610 - val_value_loss: 0.5362 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11893 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11893/11893 [==============================] - 0s 24us/step - loss: 5.5293 - policy_loss: 4.5114 - value_loss: 0.5090 - policy_acc: 0.7154 - value_acc: 0.7324 - val_loss: 5.2345 - val_policy_loss: 4.1608 - val_value_loss: 0.5369 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11901 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11901/11901 [==============================] - 0s 23us/step - loss: 5.3631 - policy_loss: 4.3808 - value_loss: 0.4911 - policy_acc: 0.7450 - value_acc: 0.7474 - val_loss: 5.2459 - val_policy_loss: 4.1599 - val_value_loss: 0.5430 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11848 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11848/11848 [==============================] - 0s 23us/step - loss: 5.5478 - policy_loss: 4.4762 - value_loss: 0.5358 - policy_acc: 0.7187 - value_acc: 0.7134 - val_loss: 5.2545 - val_policy_loss: 4.1579 - val_value_loss: 0.5483 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11755 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11755/11755 [==============================] - 0s 28us/step - loss: 5.4372 - policy_loss: 4.4405 - value_loss: 0.4983 - policy_acc: 0.7228 - value_acc: 0.7427 - val_loss: 5.2627 - val_policy_loss: 4.1592 - val_value_loss: 0.5518 - val_policy_acc: 0.8003 - val_value_acc: 0.7298\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11814 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11814/11814 [==============================] - 0s 24us/step - loss: 5.5279 - policy_loss: 4.4889 - value_loss: 0.5195 - policy_acc: 0.6830 - value_acc: 0.7235 - val_loss: 5.2592 - val_policy_loss: 4.1593 - val_value_loss: 0.5500 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11759 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11759/11759 [==============================] - 0s 23us/step - loss: 5.4585 - policy_loss: 4.4851 - value_loss: 0.4867 - policy_acc: 0.7152 - value_acc: 0.7439 - val_loss: 5.2551 - val_policy_loss: 4.1589 - val_value_loss: 0.5481 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11893 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11893/11893 [==============================] - 0s 25us/step - loss: 5.4660 - policy_loss: 4.4699 - value_loss: 0.4980 - policy_acc: 0.7133 - value_acc: 0.7452 - val_loss: 5.2478 - val_policy_loss: 4.1575 - val_value_loss: 0.5451 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11713 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11713/11713 [==============================] - 0s 24us/step - loss: 5.3587 - policy_loss: 4.4214 - value_loss: 0.4687 - policy_acc: 0.7347 - value_acc: 0.7558 - val_loss: 5.2376 - val_policy_loss: 4.1592 - val_value_loss: 0.5392 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11934 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11934/11934 [==============================] - 0s 24us/step - loss: 5.5632 - policy_loss: 4.4813 - value_loss: 0.5410 - policy_acc: 0.7235 - value_acc: 0.7030 - val_loss: 5.2442 - val_policy_loss: 4.1617 - val_value_loss: 0.5413 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11816 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11816/11816 [==============================] - 0s 24us/step - loss: 5.5309 - policy_loss: 4.4735 - value_loss: 0.5287 - policy_acc: 0.7496 - value_acc: 0.7095 - val_loss: 5.2634 - val_policy_loss: 4.1631 - val_value_loss: 0.5501 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11811 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11811/11811 [==============================] - 0s 25us/step - loss: 5.5514 - policy_loss: 4.4871 - value_loss: 0.5321 - policy_acc: 0.7225 - value_acc: 0.7129 - val_loss: 5.2776 - val_policy_loss: 4.1606 - val_value_loss: 0.5585 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11783 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11783/11783 [==============================] - 0s 24us/step - loss: 5.4616 - policy_loss: 4.4410 - value_loss: 0.5103 - policy_acc: 0.7266 - value_acc: 0.7303 - val_loss: 5.2798 - val_policy_loss: 4.1611 - val_value_loss: 0.5594 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11962 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11962/11962 [==============================] - 0s 23us/step - loss: 5.5886 - policy_loss: 4.5333 - value_loss: 0.5277 - policy_acc: 0.6933 - value_acc: 0.7153 - val_loss: 5.2855 - val_policy_loss: 4.1641 - val_value_loss: 0.5607 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11941 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11941/11941 [==============================] - 0s 25us/step - loss: 5.4909 - policy_loss: 4.4956 - value_loss: 0.4977 - policy_acc: 0.7152 - value_acc: 0.7389 - val_loss: 5.2831 - val_policy_loss: 4.1655 - val_value_loss: 0.5588 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11861 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11861/11861 [==============================] - 0s 23us/step - loss: 5.3354 - policy_loss: 4.4745 - value_loss: 0.4305 - policy_acc: 0.7383 - value_acc: 0.7889 - val_loss: 5.2596 - val_policy_loss: 4.1637 - val_value_loss: 0.5480 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11759 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11759/11759 [==============================] - 0s 28us/step - loss: 5.5490 - policy_loss: 4.5168 - value_loss: 0.5161 - policy_acc: 0.7240 - value_acc: 0.7177 - val_loss: 5.2458 - val_policy_loss: 4.1602 - val_value_loss: 0.5428 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11780 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11780/11780 [==============================] - 0s 24us/step - loss: 5.6481 - policy_loss: 4.5885 - value_loss: 0.5298 - policy_acc: 0.7145 - value_acc: 0.7048 - val_loss: 5.2512 - val_policy_loss: 4.1603 - val_value_loss: 0.5454 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11853 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11853/11853 [==============================] - 0s 24us/step - loss: 5.4458 - policy_loss: 4.4287 - value_loss: 0.5086 - policy_acc: 0.7378 - value_acc: 0.7299 - val_loss: 5.2598 - val_policy_loss: 4.1591 - val_value_loss: 0.5503 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11820 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11820/11820 [==============================] - 0s 24us/step - loss: 5.4881 - policy_loss: 4.5058 - value_loss: 0.4912 - policy_acc: 0.7007 - value_acc: 0.7445 - val_loss: 5.2662 - val_policy_loss: 4.1612 - val_value_loss: 0.5525 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11841 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11841/11841 [==============================] - 0s 23us/step - loss: 5.4470 - policy_loss: 4.5390 - value_loss: 0.4540 - policy_acc: 0.7141 - value_acc: 0.7680 - val_loss: 5.2584 - val_policy_loss: 4.1619 - val_value_loss: 0.5483 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11842 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11842/11842 [==============================] - 0s 23us/step - loss: 5.4320 - policy_loss: 4.4095 - value_loss: 0.5113 - policy_acc: 0.7284 - value_acc: 0.7297 - val_loss: 5.2470 - val_policy_loss: 4.1600 - val_value_loss: 0.5435 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11877 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11877/11877 [==============================] - 0s 25us/step - loss: 5.4218 - policy_loss: 4.4840 - value_loss: 0.4689 - policy_acc: 0.7274 - value_acc: 0.7570 - val_loss: 5.2401 - val_policy_loss: 4.1584 - val_value_loss: 0.5409 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11900 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11900/11900 [==============================] - 0s 24us/step - loss: 5.5320 - policy_loss: 4.5342 - value_loss: 0.4989 - policy_acc: 0.7043 - value_acc: 0.7340 - val_loss: 5.2469 - val_policy_loss: 4.1595 - val_value_loss: 0.5437 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11771 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11771/11771 [==============================] - 0s 24us/step - loss: 5.4573 - policy_loss: 4.5336 - value_loss: 0.4618 - policy_acc: 0.7106 - value_acc: 0.7672 - val_loss: 5.2430 - val_policy_loss: 4.1617 - val_value_loss: 0.5406 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11886 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11886/11886 [==============================] - 0s 24us/step - loss: 5.5254 - policy_loss: 4.5097 - value_loss: 0.5078 - policy_acc: 0.7081 - value_acc: 0.7314 - val_loss: 5.2412 - val_policy_loss: 4.1617 - val_value_loss: 0.5397 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11964 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11964/11964 [==============================] - 0s 24us/step - loss: 5.4890 - policy_loss: 4.5348 - value_loss: 0.4771 - policy_acc: 0.7034 - value_acc: 0.7431 - val_loss: 5.2481 - val_policy_loss: 4.1607 - val_value_loss: 0.5437 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11686 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11686/11686 [==============================] - 0s 26us/step - loss: 5.4973 - policy_loss: 4.4629 - value_loss: 0.5172 - policy_acc: 0.7380 - value_acc: 0.7272 - val_loss: 5.2509 - val_policy_loss: 4.1592 - val_value_loss: 0.5459 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11822 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11822/11822 [==============================] - 0s 25us/step - loss: 5.5751 - policy_loss: 4.5471 - value_loss: 0.5140 - policy_acc: 0.7107 - value_acc: 0.7211 - val_loss: 5.2647 - val_policy_loss: 4.1598 - val_value_loss: 0.5525 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11878 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11878/11878 [==============================] - 0s 23us/step - loss: 5.3829 - policy_loss: 4.4258 - value_loss: 0.4786 - policy_acc: 0.7174 - value_acc: 0.7455 - val_loss: 5.2692 - val_policy_loss: 4.1582 - val_value_loss: 0.5555 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11798 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11798/11798 [==============================] - 0s 25us/step - loss: 5.4628 - policy_loss: 4.5077 - value_loss: 0.4775 - policy_acc: 0.7165 - value_acc: 0.7536 - val_loss: 5.2687 - val_policy_loss: 4.1580 - val_value_loss: 0.5553 - val_policy_acc: 0.8003 - val_value_acc: 0.7177\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11904 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11904/11904 [==============================] - 0s 23us/step - loss: 5.4845 - policy_loss: 4.4617 - value_loss: 0.5114 - policy_acc: 0.7368 - value_acc: 0.7282 - val_loss: 5.2677 - val_policy_loss: 4.1588 - val_value_loss: 0.5545 - val_policy_acc: 0.8003 - val_value_acc: 0.7212\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11801 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11801/11801 [==============================] - 0s 24us/step - loss: 5.5598 - policy_loss: 4.5385 - value_loss: 0.5107 - policy_acc: 0.7047 - value_acc: 0.7225 - val_loss: 5.2686 - val_policy_loss: 4.1611 - val_value_loss: 0.5537 - val_policy_acc: 0.8003 - val_value_acc: 0.7212\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11923 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11923/11923 [==============================] - 0s 25us/step - loss: 5.4373 - policy_loss: 4.3617 - value_loss: 0.5378 - policy_acc: 0.7275 - value_acc: 0.7118 - val_loss: 5.2728 - val_policy_loss: 4.1599 - val_value_loss: 0.5564 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11894 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11894/11894 [==============================] - 0s 24us/step - loss: 5.5381 - policy_loss: 4.5246 - value_loss: 0.5067 - policy_acc: 0.7120 - value_acc: 0.7303 - val_loss: 5.2729 - val_policy_loss: 4.1581 - val_value_loss: 0.5574 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11877 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11877/11877 [==============================] - 0s 26us/step - loss: 5.5074 - policy_loss: 4.5566 - value_loss: 0.4754 - policy_acc: 0.7230 - value_acc: 0.7469 - val_loss: 5.2753 - val_policy_loss: 4.1586 - val_value_loss: 0.5583 - val_policy_acc: 0.8003 - val_value_acc: 0.7091\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11823 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11823/11823 [==============================] - 0s 25us/step - loss: 5.4627 - policy_loss: 4.4837 - value_loss: 0.4895 - policy_acc: 0.7087 - value_acc: 0.7450 - val_loss: 5.2727 - val_policy_loss: 4.1599 - val_value_loss: 0.5564 - val_policy_acc: 0.8003 - val_value_acc: 0.7212\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11776 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11776/11776 [==============================] - 0s 26us/step - loss: 5.5194 - policy_loss: 4.5338 - value_loss: 0.4928 - policy_acc: 0.7075 - value_acc: 0.7407 - val_loss: 5.2710 - val_policy_loss: 4.1613 - val_value_loss: 0.5549 - val_policy_acc: 0.8003 - val_value_acc: 0.7126\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11742 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11742/11742 [==============================] - 0s 24us/step - loss: 5.3931 - policy_loss: 4.3869 - value_loss: 0.5031 - policy_acc: 0.7413 - value_acc: 0.7313 - val_loss: 5.2716 - val_policy_loss: 4.1596 - val_value_loss: 0.5560 - val_policy_acc: 0.8003 - val_value_acc: 0.7194\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11707 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11707/11707 [==============================] - 0s 24us/step - loss: 5.4825 - policy_loss: 4.5197 - value_loss: 0.4814 - policy_acc: 0.6899 - value_acc: 0.7423 - val_loss: 5.2685 - val_policy_loss: 4.1574 - val_value_loss: 0.5556 - val_policy_acc: 0.8003 - val_value_acc: 0.7315\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11834 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11834/11834 [==============================] - 0s 24us/step - loss: 5.5110 - policy_loss: 4.5027 - value_loss: 0.5041 - policy_acc: 0.7143 - value_acc: 0.7347 - val_loss: 5.2665 - val_policy_loss: 4.1572 - val_value_loss: 0.5547 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11970 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11970/11970 [==============================] - 0s 27us/step - loss: 5.5129 - policy_loss: 4.4772 - value_loss: 0.5179 - policy_acc: 0.7089 - value_acc: 0.7280 - val_loss: 5.2706 - val_policy_loss: 4.1595 - val_value_loss: 0.5555 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11816 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11816/11816 [==============================] - 0s 24us/step - loss: 5.3446 - policy_loss: 4.4316 - value_loss: 0.4565 - policy_acc: 0.7151 - value_acc: 0.7704 - val_loss: 5.2750 - val_policy_loss: 4.1621 - val_value_loss: 0.5565 - val_policy_acc: 0.8003 - val_value_acc: 0.7212\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11760 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11760/11760 [==============================] - 0s 26us/step - loss: 5.4069 - policy_loss: 4.4776 - value_loss: 0.4647 - policy_acc: 0.7215 - value_acc: 0.7628 - val_loss: 5.2678 - val_policy_loss: 4.1588 - val_value_loss: 0.5545 - val_policy_acc: 0.8003 - val_value_acc: 0.6919\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11832 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11832/11832 [==============================] - 0s 26us/step - loss: 5.4972 - policy_loss: 4.5508 - value_loss: 0.4732 - policy_acc: 0.7054 - value_acc: 0.7659 - val_loss: 5.2510 - val_policy_loss: 4.1571 - val_value_loss: 0.5470 - val_policy_acc: 0.8003 - val_value_acc: 0.7194\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11652 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11652/11652 [==============================] - 0s 25us/step - loss: 5.5315 - policy_loss: 4.5753 - value_loss: 0.4781 - policy_acc: 0.6976 - value_acc: 0.7375 - val_loss: 5.2509 - val_policy_loss: 4.1587 - val_value_loss: 0.5461 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11916 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11916/11916 [==============================] - 0s 25us/step - loss: 5.5130 - policy_loss: 4.5387 - value_loss: 0.4872 - policy_acc: 0.7223 - value_acc: 0.7453 - val_loss: 5.2581 - val_policy_loss: 4.1569 - val_value_loss: 0.5506 - val_policy_acc: 0.8003 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11865 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11865/11865 [==============================] - 0s 25us/step - loss: 5.6033 - policy_loss: 4.5457 - value_loss: 0.5288 - policy_acc: 0.7105 - value_acc: 0.7081 - val_loss: 5.2798 - val_policy_loss: 4.1590 - val_value_loss: 0.5604 - val_policy_acc: 0.8003 - val_value_acc: 0.7022\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11921 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11921/11921 [==============================] - 0s 27us/step - loss: 5.3515 - policy_loss: 4.3815 - value_loss: 0.4850 - policy_acc: 0.7322 - value_acc: 0.7480 - val_loss: 5.2932 - val_policy_loss: 4.1601 - val_value_loss: 0.5665 - val_policy_acc: 0.8003 - val_value_acc: 0.6954\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11902 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11902/11902 [==============================] - 0s 24us/step - loss: 5.3853 - policy_loss: 4.3780 - value_loss: 0.5036 - policy_acc: 0.7231 - value_acc: 0.7407 - val_loss: 5.2959 - val_policy_loss: 4.1610 - val_value_loss: 0.5675 - val_policy_acc: 0.8003 - val_value_acc: 0.6713\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11813 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11813/11813 [==============================] - 0s 24us/step - loss: 5.5227 - policy_loss: 4.4876 - value_loss: 0.5175 - policy_acc: 0.7068 - value_acc: 0.7166 - val_loss: 5.2846 - val_policy_loss: 4.1608 - val_value_loss: 0.5619 - val_policy_acc: 0.8003 - val_value_acc: 0.6850\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11672 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11672/11672 [==============================] - 0s 24us/step - loss: 5.4925 - policy_loss: 4.4778 - value_loss: 0.5074 - policy_acc: 0.7083 - value_acc: 0.7309 - val_loss: 5.2720 - val_policy_loss: 4.1614 - val_value_loss: 0.5553 - val_policy_acc: 0.8003 - val_value_acc: 0.7108\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11690 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11690/11690 [==============================] - 0s 25us/step - loss: 5.5489 - policy_loss: 4.5212 - value_loss: 0.5138 - policy_acc: 0.7133 - value_acc: 0.7249 - val_loss: 5.2695 - val_policy_loss: 4.1594 - val_value_loss: 0.5550 - val_policy_acc: 0.8003 - val_value_acc: 0.7177\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11838 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11838/11838 [==============================] - 0s 25us/step - loss: 5.5029 - policy_loss: 4.4775 - value_loss: 0.5127 - policy_acc: 0.7201 - value_acc: 0.7313 - val_loss: 5.2737 - val_policy_loss: 4.1588 - val_value_loss: 0.5575 - val_policy_acc: 0.8003 - val_value_acc: 0.7040\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11937 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11937/11937 [==============================] - 0s 28us/step - loss: 5.5746 - policy_loss: 4.5689 - value_loss: 0.5028 - policy_acc: 0.7027 - value_acc: 0.7281 - val_loss: 5.2784 - val_policy_loss: 4.1593 - val_value_loss: 0.5596 - val_policy_acc: 0.8003 - val_value_acc: 0.6885\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11917 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11917/11917 [==============================] - 0s 24us/step - loss: 5.5336 - policy_loss: 4.5029 - value_loss: 0.5153 - policy_acc: 0.7063 - value_acc: 0.7304 - val_loss: 5.2715 - val_policy_loss: 4.1583 - val_value_loss: 0.5566 - val_policy_acc: 0.8003 - val_value_acc: 0.7005\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11846 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11846/11846 [==============================] - 0s 25us/step - loss: 5.4230 - policy_loss: 4.4500 - value_loss: 0.4865 - policy_acc: 0.7252 - value_acc: 0.7611 - val_loss: 5.2594 - val_policy_loss: 4.1577 - val_value_loss: 0.5509 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11833 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11833/11833 [==============================] - 0s 25us/step - loss: 5.4533 - policy_loss: 4.4717 - value_loss: 0.4908 - policy_acc: 0.7239 - value_acc: 0.7466 - val_loss: 5.2552 - val_policy_loss: 4.1562 - val_value_loss: 0.5495 - val_policy_acc: 0.8003 - val_value_acc: 0.7126\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11801 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11801/11801 [==============================] - 0s 24us/step - loss: 5.4920 - policy_loss: 4.4389 - value_loss: 0.5265 - policy_acc: 0.7473 - value_acc: 0.7228 - val_loss: 5.2535 - val_policy_loss: 4.1563 - val_value_loss: 0.5486 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11931 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11931/11931 [==============================] - 0s 24us/step - loss: 5.5884 - policy_loss: 4.5084 - value_loss: 0.5400 - policy_acc: 0.7323 - value_acc: 0.7049 - val_loss: 5.2738 - val_policy_loss: 4.1579 - val_value_loss: 0.5579 - val_policy_acc: 0.8003 - val_value_acc: 0.7194\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11738 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11738/11738 [==============================] - 0s 26us/step - loss: 5.5140 - policy_loss: 4.4797 - value_loss: 0.5171 - policy_acc: 0.7307 - value_acc: 0.7208 - val_loss: 5.2882 - val_policy_loss: 4.1595 - val_value_loss: 0.5644 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11811 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11811/11811 [==============================] - 0s 24us/step - loss: 5.5283 - policy_loss: 4.5192 - value_loss: 0.5046 - policy_acc: 0.7272 - value_acc: 0.7478 - val_loss: 5.2769 - val_policy_loss: 4.1585 - val_value_loss: 0.5592 - val_policy_acc: 0.8003 - val_value_acc: 0.7126\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11840 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11840/11840 [==============================] - 0s 24us/step - loss: 5.4364 - policy_loss: 4.3810 - value_loss: 0.5277 - policy_acc: 0.7446 - value_acc: 0.7177 - val_loss: 5.2718 - val_policy_loss: 4.1606 - val_value_loss: 0.5556 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11706 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11706/11706 [==============================] - 0s 25us/step - loss: 5.5066 - policy_loss: 4.4919 - value_loss: 0.5074 - policy_acc: 0.7393 - value_acc: 0.7217 - val_loss: 5.2760 - val_policy_loss: 4.1628 - val_value_loss: 0.5566 - val_policy_acc: 0.8003 - val_value_acc: 0.7281\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11770 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11770/11770 [==============================] - 0s 24us/step - loss: 5.4468 - policy_loss: 4.4890 - value_loss: 0.4789 - policy_acc: 0.7138 - value_acc: 0.7499 - val_loss: 5.2698 - val_policy_loss: 4.1632 - val_value_loss: 0.5533 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11934 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11934/11934 [==============================] - 0s 23us/step - loss: 5.5722 - policy_loss: 4.5314 - value_loss: 0.5204 - policy_acc: 0.7295 - value_acc: 0.7198 - val_loss: 5.2597 - val_policy_loss: 4.1586 - val_value_loss: 0.5505 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11941 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11941/11941 [==============================] - 0s 25us/step - loss: 5.6366 - policy_loss: 4.5767 - value_loss: 0.5299 - policy_acc: 0.6951 - value_acc: 0.7163 - val_loss: 5.2662 - val_policy_loss: 4.1583 - val_value_loss: 0.5539 - val_policy_acc: 0.8003 - val_value_acc: 0.7315\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11914 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11914/11914 [==============================] - 0s 24us/step - loss: 5.4458 - policy_loss: 4.4867 - value_loss: 0.4795 - policy_acc: 0.7385 - value_acc: 0.7559 - val_loss: 5.2701 - val_policy_loss: 4.1590 - val_value_loss: 0.5556 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11662 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11662/11662 [==============================] - 0s 23us/step - loss: 5.4958 - policy_loss: 4.4539 - value_loss: 0.5209 - policy_acc: 0.7148 - value_acc: 0.7322 - val_loss: 5.2666 - val_policy_loss: 4.1601 - val_value_loss: 0.5532 - val_policy_acc: 0.8003 - val_value_acc: 0.7298\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11846 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11846/11846 [==============================] - 0s 25us/step - loss: 5.3346 - policy_loss: 4.3822 - value_loss: 0.4762 - policy_acc: 0.7479 - value_acc: 0.7627 - val_loss: 5.2670 - val_policy_loss: 4.1617 - val_value_loss: 0.5526 - val_policy_acc: 0.8003 - val_value_acc: 0.7040\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11922 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11922/11922 [==============================] - 0s 23us/step - loss: 5.5823 - policy_loss: 4.5455 - value_loss: 0.5184 - policy_acc: 0.7235 - value_acc: 0.7172 - val_loss: 5.2646 - val_policy_loss: 4.1601 - val_value_loss: 0.5522 - val_policy_acc: 0.8003 - val_value_acc: 0.7022\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11782 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11782/11782 [==============================] - 0s 24us/step - loss: 5.4033 - policy_loss: 4.4197 - value_loss: 0.4918 - policy_acc: 0.7366 - value_acc: 0.7388 - val_loss: 5.2571 - val_policy_loss: 4.1568 - val_value_loss: 0.5501 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11885 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11885/11885 [==============================] - 0s 24us/step - loss: 5.4862 - policy_loss: 4.5080 - value_loss: 0.4891 - policy_acc: 0.7244 - value_acc: 0.7435 - val_loss: 5.2560 - val_policy_loss: 4.1602 - val_value_loss: 0.5479 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11807 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11807/11807 [==============================] - 0s 23us/step - loss: 5.4350 - policy_loss: 4.4464 - value_loss: 0.4943 - policy_acc: 0.7281 - value_acc: 0.7425 - val_loss: 5.2461 - val_policy_loss: 4.1618 - val_value_loss: 0.5421 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11790 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11790/11790 [==============================] - 0s 24us/step - loss: 5.4365 - policy_loss: 4.4644 - value_loss: 0.4861 - policy_acc: 0.7233 - value_acc: 0.7401 - val_loss: 5.2398 - val_policy_loss: 4.1631 - val_value_loss: 0.5383 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11860 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11860/11860 [==============================] - 0s 24us/step - loss: 5.4247 - policy_loss: 4.4358 - value_loss: 0.4945 - policy_acc: 0.7153 - value_acc: 0.7407 - val_loss: 5.2388 - val_policy_loss: 4.1628 - val_value_loss: 0.5380 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11830 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11830/11830 [==============================] - 0s 24us/step - loss: 5.3376 - policy_loss: 4.3452 - value_loss: 0.4962 - policy_acc: 0.7611 - value_acc: 0.7462 - val_loss: 5.2372 - val_policy_loss: 4.1593 - val_value_loss: 0.5389 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11780 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11780/11780 [==============================] - 0s 29us/step - loss: 5.5006 - policy_loss: 4.4828 - value_loss: 0.5089 - policy_acc: 0.7259 - value_acc: 0.7357 - val_loss: 5.2414 - val_policy_loss: 4.1606 - val_value_loss: 0.5404 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11850 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11850/11850 [==============================] - 0s 24us/step - loss: 5.5707 - policy_loss: 4.5363 - value_loss: 0.5172 - policy_acc: 0.7043 - value_acc: 0.7164 - val_loss: 5.2508 - val_policy_loss: 4.1606 - val_value_loss: 0.5451 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11893 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11893/11893 [==============================] - 0s 23us/step - loss: 5.5157 - policy_loss: 4.4947 - value_loss: 0.5105 - policy_acc: 0.6995 - value_acc: 0.7150 - val_loss: 5.2674 - val_policy_loss: 4.1598 - val_value_loss: 0.5538 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11749 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11749/11749 [==============================] - 0s 25us/step - loss: 5.4878 - policy_loss: 4.5029 - value_loss: 0.4925 - policy_acc: 0.7101 - value_acc: 0.7510 - val_loss: 5.2754 - val_policy_loss: 4.1605 - val_value_loss: 0.5574 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11782 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11782/11782 [==============================] - 0s 24us/step - loss: 5.4565 - policy_loss: 4.4710 - value_loss: 0.4928 - policy_acc: 0.7437 - value_acc: 0.7450 - val_loss: 5.2615 - val_policy_loss: 4.1623 - val_value_loss: 0.5496 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11758 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11758/11758 [==============================] - 0s 23us/step - loss: 5.5039 - policy_loss: 4.5296 - value_loss: 0.4871 - policy_acc: 0.6983 - value_acc: 0.7473 - val_loss: 5.2591 - val_policy_loss: 4.1616 - val_value_loss: 0.5488 - val_policy_acc: 0.8003 - val_value_acc: 0.7040\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11857 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11857/11857 [==============================] - 0s 26us/step - loss: 5.4137 - policy_loss: 4.4524 - value_loss: 0.4806 - policy_acc: 0.7192 - value_acc: 0.7460 - val_loss: 5.2697 - val_policy_loss: 4.1626 - val_value_loss: 0.5536 - val_policy_acc: 0.8003 - val_value_acc: 0.6713\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11737 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11737/11737 [==============================] - 0s 24us/step - loss: 5.5988 - policy_loss: 4.5766 - value_loss: 0.5111 - policy_acc: 0.7069 - value_acc: 0.7295 - val_loss: 5.2709 - val_policy_loss: 4.1629 - val_value_loss: 0.5540 - val_policy_acc: 0.8003 - val_value_acc: 0.6971\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11857 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11857/11857 [==============================] - 0s 24us/step - loss: 5.4456 - policy_loss: 4.4698 - value_loss: 0.4879 - policy_acc: 0.7305 - value_acc: 0.7382 - val_loss: 5.2657 - val_policy_loss: 4.1588 - val_value_loss: 0.5535 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11776 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11776/11776 [==============================] - 0s 24us/step - loss: 5.4138 - policy_loss: 4.4046 - value_loss: 0.5046 - policy_acc: 0.7621 - value_acc: 0.7337 - val_loss: 5.2675 - val_policy_loss: 4.1585 - val_value_loss: 0.5545 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11778 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11778/11778 [==============================] - 0s 26us/step - loss: 5.4649 - policy_loss: 4.4694 - value_loss: 0.4978 - policy_acc: 0.7119 - value_acc: 0.7481 - val_loss: 5.2638 - val_policy_loss: 4.1599 - val_value_loss: 0.5519 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11808 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11808/11808 [==============================] - 0s 24us/step - loss: 5.4839 - policy_loss: 4.5127 - value_loss: 0.4856 - policy_acc: 0.6844 - value_acc: 0.7434 - val_loss: 5.2571 - val_policy_loss: 4.1611 - val_value_loss: 0.5480 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11903 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11903/11903 [==============================] - 0s 24us/step - loss: 5.4795 - policy_loss: 4.4863 - value_loss: 0.4966 - policy_acc: 0.7365 - value_acc: 0.7390 - val_loss: 5.2511 - val_policy_loss: 4.1609 - val_value_loss: 0.5451 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11966 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11966/11966 [==============================] - 0s 25us/step - loss: 5.4691 - policy_loss: 4.4544 - value_loss: 0.5073 - policy_acc: 0.7334 - value_acc: 0.7276 - val_loss: 5.2535 - val_policy_loss: 4.1596 - val_value_loss: 0.5469 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11748 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11748/11748 [==============================] - 0s 28us/step - loss: 5.5161 - policy_loss: 4.5432 - value_loss: 0.4865 - policy_acc: 0.7268 - value_acc: 0.7481 - val_loss: 5.2553 - val_policy_loss: 4.1592 - val_value_loss: 0.5481 - val_policy_acc: 0.8003 - val_value_acc: 0.7367\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11912 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11912/11912 [==============================] - 0s 28us/step - loss: 5.5786 - policy_loss: 4.5546 - value_loss: 0.5120 - policy_acc: 0.6703 - value_acc: 0.7272 - val_loss: 5.2586 - val_policy_loss: 4.1590 - val_value_loss: 0.5498 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11692 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11692/11692 [==============================] - 0s 26us/step - loss: 5.4631 - policy_loss: 4.4325 - value_loss: 0.5153 - policy_acc: 0.7369 - value_acc: 0.7257 - val_loss: 5.2630 - val_policy_loss: 4.1609 - val_value_loss: 0.5510 - val_policy_acc: 0.8003 - val_value_acc: 0.7332\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11954 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11954/11954 [==============================] - 0s 24us/step - loss: 5.5135 - policy_loss: 4.5284 - value_loss: 0.4926 - policy_acc: 0.7197 - value_acc: 0.7492 - val_loss: 5.2622 - val_policy_loss: 4.1633 - val_value_loss: 0.5494 - val_policy_acc: 0.8003 - val_value_acc: 0.7315\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11759 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11759/11759 [==============================] - 0s 24us/step - loss: 5.5267 - policy_loss: 4.4893 - value_loss: 0.5187 - policy_acc: 0.7070 - value_acc: 0.7132 - val_loss: 5.2570 - val_policy_loss: 4.1605 - val_value_loss: 0.5483 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11968 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11968/11968 [==============================] - 0s 24us/step - loss: 5.5167 - policy_loss: 4.4699 - value_loss: 0.5234 - policy_acc: 0.7339 - value_acc: 0.7171 - val_loss: 5.2624 - val_policy_loss: 4.1588 - val_value_loss: 0.5518 - val_policy_acc: 0.8003 - val_value_acc: 0.7418\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11852 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11852/11852 [==============================] - 0s 24us/step - loss: 5.6076 - policy_loss: 4.5062 - value_loss: 0.5507 - policy_acc: 0.7257 - value_acc: 0.6974 - val_loss: 5.2758 - val_policy_loss: 4.1624 - val_value_loss: 0.5567 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11760 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11760/11760 [==============================] - 0s 25us/step - loss: 5.4217 - policy_loss: 4.4436 - value_loss: 0.4891 - policy_acc: 0.7076 - value_acc: 0.7537 - val_loss: 5.2702 - val_policy_loss: 4.1621 - val_value_loss: 0.5541 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11806 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11806/11806 [==============================] - 0s 24us/step - loss: 5.4690 - policy_loss: 4.4594 - value_loss: 0.5048 - policy_acc: 0.7249 - value_acc: 0.7338 - val_loss: 5.2610 - val_policy_loss: 4.1624 - val_value_loss: 0.5493 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11876 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11876/11876 [==============================] - 0s 23us/step - loss: 5.5681 - policy_loss: 4.5554 - value_loss: 0.5064 - policy_acc: 0.7103 - value_acc: 0.7365 - val_loss: 5.2561 - val_policy_loss: 4.1622 - val_value_loss: 0.5470 - val_policy_acc: 0.7969 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11834 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11834/11834 [==============================] - 0s 25us/step - loss: 5.4332 - policy_loss: 4.4553 - value_loss: 0.4890 - policy_acc: 0.7171 - value_acc: 0.7526 - val_loss: 5.2467 - val_policy_loss: 4.1572 - val_value_loss: 0.5448 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11862 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11862/11862 [==============================] - 0s 25us/step - loss: 5.5850 - policy_loss: 4.5474 - value_loss: 0.5188 - policy_acc: 0.7119 - value_acc: 0.7215 - val_loss: 5.2474 - val_policy_loss: 4.1579 - val_value_loss: 0.5448 - val_policy_acc: 0.8003 - val_value_acc: 0.7435\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11928 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11928/11928 [==============================] - 0s 25us/step - loss: 5.4269 - policy_loss: 4.4001 - value_loss: 0.5134 - policy_acc: 0.7431 - value_acc: 0.7365 - val_loss: 5.2523 - val_policy_loss: 4.1600 - val_value_loss: 0.5462 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11781 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11781/11781 [==============================] - 0s 24us/step - loss: 5.5038 - policy_loss: 4.5138 - value_loss: 0.4950 - policy_acc: 0.7001 - value_acc: 0.7477 - val_loss: 5.2560 - val_policy_loss: 4.1586 - val_value_loss: 0.5487 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11783 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11783/11783 [==============================] - 0s 25us/step - loss: 5.4045 - policy_loss: 4.4319 - value_loss: 0.4863 - policy_acc: 0.7394 - value_acc: 0.7352 - val_loss: 5.2568 - val_policy_loss: 4.1583 - val_value_loss: 0.5492 - val_policy_acc: 0.8003 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11958 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11958/11958 [==============================] - 0s 24us/step - loss: 5.5227 - policy_loss: 4.5282 - value_loss: 0.4973 - policy_acc: 0.7505 - value_acc: 0.7304 - val_loss: 5.2604 - val_policy_loss: 4.1639 - val_value_loss: 0.5483 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11937 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11937/11937 [==============================] - 0s 24us/step - loss: 5.5353 - policy_loss: 4.5139 - value_loss: 0.5107 - policy_acc: 0.7112 - value_acc: 0.7286 - val_loss: 5.2573 - val_policy_loss: 4.1599 - val_value_loss: 0.5487 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11742 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11742/11742 [==============================] - 0s 24us/step - loss: 5.5802 - policy_loss: 4.5781 - value_loss: 0.5010 - policy_acc: 0.7085 - value_acc: 0.7319 - val_loss: 5.2587 - val_policy_loss: 4.1588 - val_value_loss: 0.5500 - val_policy_acc: 0.8003 - val_value_acc: 0.7556\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11710 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11710/11710 [==============================] - 0s 24us/step - loss: 5.4825 - policy_loss: 4.4308 - value_loss: 0.5259 - policy_acc: 0.7209 - value_acc: 0.7052 - val_loss: 5.2645 - val_policy_loss: 4.1602 - val_value_loss: 0.5521 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11926 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11926/11926 [==============================] - 0s 26us/step - loss: 5.4817 - policy_loss: 4.4630 - value_loss: 0.5094 - policy_acc: 0.7165 - value_acc: 0.7360 - val_loss: 5.2653 - val_policy_loss: 4.1602 - val_value_loss: 0.5526 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11824 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11824/11824 [==============================] - 0s 26us/step - loss: 5.4267 - policy_loss: 4.4240 - value_loss: 0.5014 - policy_acc: 0.7273 - value_acc: 0.7380 - val_loss: 5.2647 - val_policy_loss: 4.1600 - val_value_loss: 0.5524 - val_policy_acc: 0.8003 - val_value_acc: 0.7487\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11886 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11886/11886 [==============================] - 0s 23us/step - loss: 5.5294 - policy_loss: 4.4823 - value_loss: 0.5236 - policy_acc: 0.7116 - value_acc: 0.7123 - val_loss: 5.2660 - val_policy_loss: 4.1595 - val_value_loss: 0.5532 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11767 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11767/11767 [==============================] - 0s 24us/step - loss: 5.5290 - policy_loss: 4.4850 - value_loss: 0.5220 - policy_acc: 0.7346 - value_acc: 0.7216 - val_loss: 5.2749 - val_policy_loss: 4.1589 - val_value_loss: 0.5580 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11877 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11877/11877 [==============================] - 0s 27us/step - loss: 5.5623 - policy_loss: 4.5146 - value_loss: 0.5238 - policy_acc: 0.7001 - value_acc: 0.7287 - val_loss: 5.2727 - val_policy_loss: 4.1579 - val_value_loss: 0.5574 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11618 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11618/11618 [==============================] - 0s 29us/step - loss: 5.4818 - policy_loss: 4.4892 - value_loss: 0.4963 - policy_acc: 0.7277 - value_acc: 0.7392 - val_loss: 5.2672 - val_policy_loss: 4.1589 - val_value_loss: 0.5542 - val_policy_acc: 0.8003 - val_value_acc: 0.7470\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11911 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11911/11911 [==============================] - 0s 28us/step - loss: 5.5148 - policy_loss: 4.5212 - value_loss: 0.4968 - policy_acc: 0.7145 - value_acc: 0.7301 - val_loss: 5.2567 - val_policy_loss: 4.1595 - val_value_loss: 0.5486 - val_policy_acc: 0.8003 - val_value_acc: 0.7453\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11943 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11943/11943 [==============================] - 0s 28us/step - loss: 5.5799 - policy_loss: 4.5889 - value_loss: 0.4955 - policy_acc: 0.7096 - value_acc: 0.7338 - val_loss: 5.2483 - val_policy_loss: 4.1589 - val_value_loss: 0.5447 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11624 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11624/11624 [==============================] - 0s 29us/step - loss: 5.4942 - policy_loss: 4.5183 - value_loss: 0.4879 - policy_acc: 0.6925 - value_acc: 0.7263 - val_loss: 5.2459 - val_policy_loss: 4.1577 - val_value_loss: 0.5441 - val_policy_acc: 0.8003 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11844 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11844/11844 [==============================] - 0s 29us/step - loss: 5.4360 - policy_loss: 4.5385 - value_loss: 0.4488 - policy_acc: 0.7242 - value_acc: 0.7698 - val_loss: 5.2484 - val_policy_loss: 4.1597 - val_value_loss: 0.5443 - val_policy_acc: 0.8003 - val_value_acc: 0.7384\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11850 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11850/11850 [==============================] - 0s 24us/step - loss: 5.5991 - policy_loss: 4.5375 - value_loss: 0.5308 - policy_acc: 0.7191 - value_acc: 0.7164 - val_loss: 5.2512 - val_policy_loss: 4.1604 - val_value_loss: 0.5454 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11840 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11840/11840 [==============================] - 0s 26us/step - loss: 5.4017 - policy_loss: 4.3590 - value_loss: 0.5213 - policy_acc: 0.7526 - value_acc: 0.7299 - val_loss: 5.2380 - val_policy_loss: 4.1585 - val_value_loss: 0.5397 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11950 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11950/11950 [==============================] - 0s 24us/step - loss: 5.4742 - policy_loss: 4.5089 - value_loss: 0.4826 - policy_acc: 0.7332 - value_acc: 0.7458 - val_loss: 5.2402 - val_policy_loss: 4.1585 - val_value_loss: 0.5409 - val_policy_acc: 0.8003 - val_value_acc: 0.7298\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11974 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11974/11974 [==============================] - 0s 26us/step - loss: 5.4542 - policy_loss: 4.4823 - value_loss: 0.4860 - policy_acc: 0.7135 - value_acc: 0.7447 - val_loss: 5.2445 - val_policy_loss: 4.1570 - val_value_loss: 0.5437 - val_policy_acc: 0.8003 - val_value_acc: 0.7091\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11838 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11838/11838 [==============================] - 0s 28us/step - loss: 5.6271 - policy_loss: 4.5958 - value_loss: 0.5157 - policy_acc: 0.6907 - value_acc: 0.7320 - val_loss: 5.2520 - val_policy_loss: 4.1599 - val_value_loss: 0.5460 - val_policy_acc: 0.8003 - val_value_acc: 0.7246\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11724 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11724/11724 [==============================] - 0s 26us/step - loss: 5.4934 - policy_loss: 4.5081 - value_loss: 0.4927 - policy_acc: 0.7188 - value_acc: 0.7403 - val_loss: 5.2568 - val_policy_loss: 4.1611 - val_value_loss: 0.5479 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11770 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11770/11770 [==============================] - 0s 29us/step - loss: 5.4042 - policy_loss: 4.4679 - value_loss: 0.4681 - policy_acc: 0.7157 - value_acc: 0.7706 - val_loss: 5.2516 - val_policy_loss: 4.1600 - val_value_loss: 0.5458 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11842 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11842/11842 [==============================] - 0s 29us/step - loss: 5.4449 - policy_loss: 4.4626 - value_loss: 0.4912 - policy_acc: 0.7355 - value_acc: 0.7458 - val_loss: 5.2335 - val_policy_loss: 4.1600 - val_value_loss: 0.5367 - val_policy_acc: 0.8003 - val_value_acc: 0.7539\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11868 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11868/11868 [==============================] - 0s 27us/step - loss: 5.4415 - policy_loss: 4.4979 - value_loss: 0.4718 - policy_acc: 0.7435 - value_acc: 0.7570 - val_loss: 5.2280 - val_policy_loss: 4.1637 - val_value_loss: 0.5321 - val_policy_acc: 0.8003 - val_value_acc: 0.7590\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11807 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11807/11807 [==============================] - 0s 28us/step - loss: 5.4788 - policy_loss: 4.4713 - value_loss: 0.5038 - policy_acc: 0.6856 - value_acc: 0.7390 - val_loss: 5.2362 - val_policy_loss: 4.1637 - val_value_loss: 0.5363 - val_policy_acc: 0.8003 - val_value_acc: 0.7177\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11811 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11811/11811 [==============================] - 0s 28us/step - loss: 5.5001 - policy_loss: 4.4685 - value_loss: 0.5158 - policy_acc: 0.7419 - value_acc: 0.7261 - val_loss: 5.2421 - val_policy_loss: 4.1617 - val_value_loss: 0.5402 - val_policy_acc: 0.8003 - val_value_acc: 0.7177\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11950 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11950/11950 [==============================] - 0s 29us/step - loss: 5.5998 - policy_loss: 4.5917 - value_loss: 0.5040 - policy_acc: 0.6910 - value_acc: 0.7290 - val_loss: 5.2535 - val_policy_loss: 4.1607 - val_value_loss: 0.5464 - val_policy_acc: 0.8003 - val_value_acc: 0.7349\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11904 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11904/11904 [==============================] - 0s 27us/step - loss: 5.4435 - policy_loss: 4.5235 - value_loss: 0.4600 - policy_acc: 0.7314 - value_acc: 0.7576 - val_loss: 5.2568 - val_policy_loss: 4.1594 - val_value_loss: 0.5487 - val_policy_acc: 0.8003 - val_value_acc: 0.7522\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11988 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11988/11988 [==============================] - 0s 29us/step - loss: 5.4550 - policy_loss: 4.4869 - value_loss: 0.4841 - policy_acc: 0.6949 - value_acc: 0.7536 - val_loss: 5.2508 - val_policy_loss: 4.1590 - val_value_loss: 0.5459 - val_policy_acc: 0.8003 - val_value_acc: 0.7625\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11790 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11790/11790 [==============================] - 0s 28us/step - loss: 5.4790 - policy_loss: 4.4595 - value_loss: 0.5097 - policy_acc: 0.7355 - value_acc: 0.7342 - val_loss: 5.2424 - val_policy_loss: 4.1614 - val_value_loss: 0.5405 - val_policy_acc: 0.8003 - val_value_acc: 0.7608\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11824 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11824/11824 [==============================] - 0s 28us/step - loss: 5.4063 - policy_loss: 4.4150 - value_loss: 0.4957 - policy_acc: 0.7177 - value_acc: 0.7420 - val_loss: 5.2371 - val_policy_loss: 4.1590 - val_value_loss: 0.5391 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11770 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11770/11770 [==============================] - 0s 28us/step - loss: 5.4939 - policy_loss: 4.4622 - value_loss: 0.5159 - policy_acc: 0.7081 - value_acc: 0.7140 - val_loss: 5.2431 - val_policy_loss: 4.1579 - val_value_loss: 0.5426 - val_policy_acc: 0.8003 - val_value_acc: 0.7573\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11964 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11964/11964 [==============================] - 0s 28us/step - loss: 5.5348 - policy_loss: 4.5186 - value_loss: 0.5081 - policy_acc: 0.7150 - value_acc: 0.7230 - val_loss: 5.2599 - val_policy_loss: 4.1630 - val_value_loss: 0.5484 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11917 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11917/11917 [==============================] - 0s 27us/step - loss: 5.4743 - policy_loss: 4.4964 - value_loss: 0.4890 - policy_acc: 0.7204 - value_acc: 0.7426 - val_loss: 5.2593 - val_policy_loss: 4.1599 - val_value_loss: 0.5497 - val_policy_acc: 0.8003 - val_value_acc: 0.7504\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11868 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11868/11868 [==============================] - 0s 27us/step - loss: 5.5980 - policy_loss: 4.5868 - value_loss: 0.5056 - policy_acc: 0.6732 - value_acc: 0.7249 - val_loss: 5.2669 - val_policy_loss: 4.1591 - val_value_loss: 0.5539 - val_policy_acc: 0.8003 - val_value_acc: 0.7143\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11920 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11920/11920 [==============================] - 0s 26us/step - loss: 5.5049 - policy_loss: 4.4974 - value_loss: 0.5038 - policy_acc: 0.7251 - value_acc: 0.7287 - val_loss: 5.2732 - val_policy_loss: 4.1617 - val_value_loss: 0.5558 - val_policy_acc: 0.8003 - val_value_acc: 0.6971\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11881 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11881/11881 [==============================] - 0s 27us/step - loss: 5.3905 - policy_loss: 4.4255 - value_loss: 0.4825 - policy_acc: 0.7424 - value_acc: 0.7504 - val_loss: 5.2741 - val_policy_loss: 4.1612 - val_value_loss: 0.5564 - val_policy_acc: 0.8003 - val_value_acc: 0.6988\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11982 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11982/11982 [==============================] - 0s 29us/step - loss: 5.4685 - policy_loss: 4.4626 - value_loss: 0.5030 - policy_acc: 0.7386 - value_acc: 0.7330 - val_loss: 5.2681 - val_policy_loss: 4.2723 - val_value_loss: 0.4979 - val_policy_acc: 0.7315 - val_value_acc: 0.7831\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11840 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11840/11840 [==============================] - 0s 34us/step - loss: 5.5414 - policy_loss: 4.5415 - value_loss: 0.4999 - policy_acc: 0.7101 - value_acc: 0.7371 - val_loss: 5.2666 - val_policy_loss: 4.2716 - val_value_loss: 0.4975 - val_policy_acc: 0.7315 - val_value_acc: 0.7883\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11792 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11792/11792 [==============================] - 0s 28us/step - loss: 5.4537 - policy_loss: 4.4852 - value_loss: 0.4842 - policy_acc: 0.7012 - value_acc: 0.7561 - val_loss: 5.2762 - val_policy_loss: 4.2717 - val_value_loss: 0.5022 - val_policy_acc: 0.7315 - val_value_acc: 0.7401\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11874 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11874/11874 [==============================] - 0s 26us/step - loss: 5.4894 - policy_loss: 4.5126 - value_loss: 0.4884 - policy_acc: 0.6936 - value_acc: 0.7443 - val_loss: 5.2933 - val_policy_loss: 4.2734 - val_value_loss: 0.5099 - val_policy_acc: 0.7315 - val_value_acc: 0.7160\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11836 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11836/11836 [==============================] - 0s 24us/step - loss: 5.4963 - policy_loss: 4.4928 - value_loss: 0.5018 - policy_acc: 0.6973 - value_acc: 0.7264 - val_loss: 5.2857 - val_policy_loss: 4.2780 - val_value_loss: 0.5038 - val_policy_acc: 0.7315 - val_value_acc: 0.7263\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11750 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11750/11750 [==============================] - 0s 24us/step - loss: 5.4802 - policy_loss: 4.4742 - value_loss: 0.5030 - policy_acc: 0.7098 - value_acc: 0.7298 - val_loss: 5.2805 - val_policy_loss: 4.2846 - val_value_loss: 0.4979 - val_policy_acc: 0.7315 - val_value_acc: 0.7900\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11891 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11891/11891 [==============================] - 0s 24us/step - loss: 5.5807 - policy_loss: 4.5501 - value_loss: 0.5153 - policy_acc: 0.7047 - value_acc: 0.7196 - val_loss: 5.2816 - val_policy_loss: 4.2834 - val_value_loss: 0.4991 - val_policy_acc: 0.7315 - val_value_acc: 0.7935\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11912 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11912/11912 [==============================] - 0s 25us/step - loss: 5.5681 - policy_loss: 4.5816 - value_loss: 0.4932 - policy_acc: 0.6808 - value_acc: 0.7448 - val_loss: 5.2811 - val_policy_loss: 4.2755 - val_value_loss: 0.5028 - val_policy_acc: 0.7315 - val_value_acc: 0.7849\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11832 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11832/11832 [==============================] - 0s 24us/step - loss: 5.5222 - policy_loss: 4.5053 - value_loss: 0.5085 - policy_acc: 0.7147 - value_acc: 0.7269 - val_loss: 5.2773 - val_policy_loss: 4.2716 - val_value_loss: 0.5028 - val_policy_acc: 0.7315 - val_value_acc: 0.7866\n",
      "Finished loading 100 training files and 10 validation files\n",
      "Train on 11739 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "11739/11739 [==============================] - 0s 24us/step - loss: 5.5092 - policy_loss: 4.4811 - value_loss: 0.5141 - policy_acc: 0.7157 - value_acc: 0.7335 - val_loss: 5.2735 - val_policy_loss: 4.2725 - val_value_loss: 0.5005 - val_policy_acc: 0.7315 - val_value_acc: 0.7986\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-b07826f71045>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# for some dumb reason, this fails the first time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdoTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-afabc71968cf>\u001b[0m in \u001b[0;36mdoTrain\u001b[1;34m(num_loops, numGamesPerLoop)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdoTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_loops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumGamesPerLoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_loops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainingLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumGamesPerLoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mhistoryPolicyValAcc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_policy_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-4e862020605f>\u001b[0m in \u001b[0;36mtrainingLoop\u001b[1;34m(numGamesPerLoop)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrainingLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumGamesPerLoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m     \u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrainYPolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainYValue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalTrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalYPolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalYValue\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetTrainingDataForNumGames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumGamesPerLoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-4e862020605f>\u001b[0m in \u001b[0;36mgetTrainingDataForNumGames\u001b[1;34m(num)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;31m#twice, once for regular, once for flipped Y values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnextTrainX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetXAxisReflectedTrainingData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnextTrainX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;31m#twice, once for regular, once for flipped Y values (reflecting over x axis does not change policy or value)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-4e862020605f>\u001b[0m in \u001b[0;36mgetXAxisReflectedTrainingData\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for some dumb reason, this fails the first time\n",
    "doTrain(1000, 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1296 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "    \n",
    "plt.figure(1, figsize=(18, 18))\n",
    "   \n",
    "# summarize history for accuracy  \n",
    "   \n",
    "plt.subplot(211)  \n",
    "# plt.plot(history.history['policy_acc'])  \n",
    "plt.plot(historyPolicyValAcc)  \n",
    "# plt.plot(history.history['value_acc'])  \n",
    "plt.plot(historyValueValAcc)  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "# plt.legend(['policy_categorical_accuracy', 'val_policy_categorical_accuracy', 'value_categorical_accuracy', 'val_value_categorical_accuracy'], loc='upper left')  \n",
    "plt.legend(['Validation Policy Accuracy','Validation Value Accuracy'], loc='upper left')  \n",
    "   \n",
    "# summarize history for loss  \n",
    "   \n",
    "plt.subplot(212)  \n",
    "# plt.plot(history.history['policy_loss'])  \n",
    "#plt.plot(historyPolicyValLoss)  \n",
    "# plt.plot(history.history['value_loss'])  \n",
    "plt.plot(historyValueValLoss)  \n",
    "# plt.plot(history.history['loss'])  \n",
    "#plt.plot(historyValLoss)  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "# plt.legend(['policy_loss', 'val_policy_loss', 'value_loss','val_value_loss','loss','val_loss',], loc='upper left')  \n",
    "plt.legend(['val_policy_loss','val_value_loss','val_loss'], loc='upper left')  \n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# save model and proceed to next iteration\n",
    "\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# find highest iteration model \n",
    "\n",
    "filepath = '.'\n",
    "\n",
    "onlyFiles = [f for f in listdir(filepath) if isfile(join(filepath, f)) and 'iter' in f]\n",
    "highestIteration = max([re.findall(r'\\d+', filename)[0] for filename in onlyFiles], key=lambda iterNum: int(iterNum))\n",
    "\n",
    "model.save(\"gz_dev.model\")\n",
    "model.save(\"gz_dev.iter{}.model\".format(highestIteration + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
