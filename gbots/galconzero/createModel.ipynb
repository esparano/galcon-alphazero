{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 22, 14)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 22, 14)       0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 22, 10)       150         dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 22, 10)       0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 22, 10)       0           leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 22, 8)        88          dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 22, 8)        0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 176)          0           leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 176)          0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 20)           3540        dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 20)           0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 20)           0           leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 15)           315         dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 15)           0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 15)           0           leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 176)          0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 7)            112         dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 100)          17700       dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 7)            0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 100)          0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 7)            0           leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "policy (Dense)                  (None, 925)          93425       leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "value (Dense)                   (None, 1)            8           dropout_31[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 115,338\n",
      "Trainable params: 115,338\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, Flatten, LeakyReLU, Dropout\n",
    "from keras.utils import plot_model\n",
    "from nnSetup import NUM_PLANETS, NUM_FEATURES, NUM_OUTPUTS\n",
    "\n",
    "RELU_ALPHA = 0.05\n",
    "\n",
    "# INPUTS\n",
    "inputs = Input(shape=(NUM_PLANETS, NUM_FEATURES))\n",
    "\n",
    "# BODY\n",
    "# TODO: insert residual GCNNs layers here\n",
    "body = Dropout(0.2)(inputs)\n",
    "body = Dense(10)(body)\n",
    "body = LeakyReLU(alpha=RELU_ALPHA)(body)\n",
    "\n",
    "body = Dropout(0.2)(body)\n",
    "body = Dense(8)(body)\n",
    "body = LeakyReLU(alpha=RELU_ALPHA)(body)\n",
    "\n",
    "body = Flatten()(body)\n",
    "\n",
    "# POLICY HEAD\n",
    "policyHead = Dropout(0.2)(body)\n",
    "policyHead = Dense(100, activation='relu')(policyHead)\n",
    "policyHead = LeakyReLU(alpha=RELU_ALPHA)(policyHead)\n",
    "\n",
    "policyHead = Dropout(0.2)(body)\n",
    "policyHead = Dense(100, activation='relu')(policyHead)\n",
    "policyHead = LeakyReLU(alpha=RELU_ALPHA)(policyHead)\n",
    "\n",
    "policyHead = Dropout(0.2)(body)\n",
    "policyHead = Dense(100, activation='relu')(policyHead)\n",
    "policyHead = LeakyReLU(alpha=RELU_ALPHA)(policyHead)\n",
    "\n",
    "policyHead = Dense(NUM_OUTPUTS, activation='softmax', name='policy')(policyHead)\n",
    "\n",
    "# VALUE HEAD\n",
    "valueHead = Dropout(0.2)(body)\n",
    "valueHead = Dense(20, activation='relu')(valueHead)\n",
    "valueHead = LeakyReLU(alpha=RELU_ALPHA)(valueHead)\n",
    "\n",
    "valueHead = Dropout(0.2)(valueHead)\n",
    "valueHead = Dense(15, activation='relu')(valueHead)\n",
    "valueHead = LeakyReLU(alpha=RELU_ALPHA)(valueHead)\n",
    "\n",
    "valueHead = Dropout(0.2)(valueHead)\n",
    "valueHead = Dense(7, activation='relu')(valueHead)\n",
    "valueHead = LeakyReLU(alpha=RELU_ALPHA)(valueHead)\n",
    "\n",
    "valueHead = Dropout(0.2)(valueHead)\n",
    "valueHead = Dense(1, activation='sigmoid', name='value')(valueHead)\n",
    "\n",
    "# TODO: multiple percentages\n",
    "model = Model(inputs=inputs, outputs=[policyHead, valueHead], name='GZ_DenseNetwork')\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "plot_model(model, to_file='model_graph.png')\n",
    "\n",
    "# TODO: are these losses right??\n",
    "# TODO: measure losses to get better loss weights?\n",
    "# TODO: are these metrics right?\n",
    "model.compile(loss=['categorical_crossentropy', 'binary_crossentropy'], loss_weights=[1, 1], optimizer='adam', metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainingGame import loadTrainingGame\n",
    "from trainingHelper import TrainingHelper\n",
    "\n",
    "game = loadTrainingGame(\"testGame.pickle\")\n",
    "helper = TrainingHelper(game) \n",
    "\n",
    "trainX = helper.getTrainX()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.00086641, 0.00124602, 0.00113013, 0.00125453, 0.00133645,\n",
       "         0.00115943, 0.00125927, 0.00095524, 0.00113272, 0.00116916,\n",
       "         0.00113839, 0.00111776, 0.00085939, 0.00096704, 0.00129532,\n",
       "         0.00092745, 0.00104399, 0.00098818, 0.00094498, 0.00119968,\n",
       "         0.00129664, 0.00117851, 0.00111395, 0.00111022, 0.00103191,\n",
       "         0.00104598, 0.00096852, 0.00111688, 0.00107779, 0.00089883,\n",
       "         0.00095581, 0.00139404, 0.00096113, 0.00118084, 0.00132648,\n",
       "         0.00115629, 0.0010503 , 0.00098642, 0.00115407, 0.00121786,\n",
       "         0.00129573, 0.00124556, 0.00115791, 0.00087006, 0.00109562,\n",
       "         0.00094222, 0.00089171, 0.00093918, 0.00122977, 0.00101586,\n",
       "         0.00098969, 0.000932  , 0.00117283, 0.00107994, 0.00129764,\n",
       "         0.00099654, 0.00111881, 0.00096335, 0.00118384, 0.0011532 ,\n",
       "         0.00105848, 0.00092949, 0.00126869, 0.0010024 , 0.00109638,\n",
       "         0.00110924, 0.0011122 , 0.00101492, 0.00100625, 0.0010496 ,\n",
       "         0.00104149, 0.00085481, 0.001076  , 0.00102475, 0.00101892,\n",
       "         0.00097058, 0.00123451, 0.00110183, 0.00093889, 0.00094909,\n",
       "         0.00128837, 0.0011134 , 0.00108327, 0.00104659, 0.00101354,\n",
       "         0.00112289, 0.00106169, 0.00102997, 0.00095978, 0.00114139,\n",
       "         0.00111495, 0.00109892, 0.0011255 , 0.00106531, 0.00110069,\n",
       "         0.00102072, 0.00115059, 0.00109868, 0.0011028 , 0.00095103,\n",
       "         0.00105364, 0.00104378, 0.00102027, 0.00080064, 0.00079839,\n",
       "         0.00109016, 0.00112232, 0.00101574, 0.00105704, 0.0010466 ,\n",
       "         0.00116766, 0.0010763 , 0.00111986, 0.00087744, 0.00086268,\n",
       "         0.00088785, 0.00124528, 0.00098342, 0.00124247, 0.00113916,\n",
       "         0.00107573, 0.0010152 , 0.00133327, 0.00122385, 0.00110663,\n",
       "         0.00122638, 0.0010151 , 0.00115598, 0.0010312 , 0.00138491,\n",
       "         0.0009438 , 0.00100062, 0.00110064, 0.00089775, 0.00094064,\n",
       "         0.00094384, 0.00099145, 0.00117578, 0.00112486, 0.00117127,\n",
       "         0.00122819, 0.00099986, 0.00099182, 0.00117742, 0.00117469,\n",
       "         0.00120055, 0.00124102, 0.00103145, 0.00109453, 0.00100314,\n",
       "         0.00109522, 0.00122828, 0.00093269, 0.00089551, 0.00122463,\n",
       "         0.00098643, 0.00123565, 0.00115555, 0.00096943, 0.00096475,\n",
       "         0.00111321, 0.00103728, 0.0012307 , 0.00097801, 0.00098861,\n",
       "         0.0009534 , 0.0012147 , 0.0012078 , 0.00115105, 0.00110643,\n",
       "         0.00120775, 0.00101136, 0.0010798 , 0.00087054, 0.00118477,\n",
       "         0.00084218, 0.00101059, 0.00122369, 0.00105676, 0.00123741,\n",
       "         0.00114276, 0.00119231, 0.00113857, 0.00102409, 0.0010053 ,\n",
       "         0.00108884, 0.00141104, 0.00097229, 0.00100178, 0.00107046,\n",
       "         0.00107921, 0.00099234, 0.00125716, 0.00127526, 0.00091165,\n",
       "         0.00116456, 0.00101382, 0.00115378, 0.00097301, 0.00093196,\n",
       "         0.00118499, 0.00129722, 0.00097672, 0.00090473, 0.0011768 ,\n",
       "         0.00106437, 0.00125081, 0.00116978, 0.00118338, 0.00083616,\n",
       "         0.00111463, 0.00107886, 0.00112625, 0.00096781, 0.00102857,\n",
       "         0.00109192, 0.00116884, 0.00111193, 0.00094863, 0.00113007,\n",
       "         0.00113733, 0.00139974, 0.00115332, 0.00119649, 0.00104388,\n",
       "         0.00099966, 0.00128914, 0.00100552, 0.00099207, 0.00102699,\n",
       "         0.00089545, 0.00093898, 0.00103665, 0.00102464, 0.00097083,\n",
       "         0.00093768, 0.00102755, 0.00117661, 0.00102692, 0.00109143,\n",
       "         0.00094257, 0.00103966, 0.00121615, 0.00114215, 0.00123916,\n",
       "         0.00099161, 0.00119224, 0.00103575, 0.0011389 , 0.00121125,\n",
       "         0.00095382, 0.00106254, 0.00096424, 0.00103574, 0.00107787,\n",
       "         0.00098466, 0.00107319, 0.000867  , 0.00132914, 0.00099973,\n",
       "         0.00124865, 0.00101726, 0.00115794, 0.00130232, 0.00101234,\n",
       "         0.00102237, 0.00094713, 0.00113362, 0.00096244, 0.00129686,\n",
       "         0.0010725 , 0.00090331, 0.00090499, 0.0011436 , 0.00117666,\n",
       "         0.00111751, 0.00103232, 0.00105829, 0.00118576, 0.00090834,\n",
       "         0.00096722, 0.00113991, 0.0010743 , 0.00089667, 0.0011412 ,\n",
       "         0.00116392, 0.0012873 , 0.00093615, 0.00083678, 0.00082201,\n",
       "         0.00137602, 0.00100055, 0.00118211, 0.00118682, 0.00118991,\n",
       "         0.00111285, 0.00116076, 0.00122492, 0.0009486 , 0.00108042,\n",
       "         0.00111167, 0.00119067, 0.00113398, 0.00096644, 0.00123377,\n",
       "         0.00102369, 0.00106083, 0.00097142, 0.00106162, 0.00121975,\n",
       "         0.00113005, 0.00107721, 0.00109213, 0.0013558 , 0.00133109,\n",
       "         0.00125594, 0.00109995, 0.00125864, 0.00099118, 0.00102566,\n",
       "         0.00092912, 0.00110132, 0.00111068, 0.00114345, 0.00100004,\n",
       "         0.00104807, 0.00125869, 0.00098019, 0.00097541, 0.00107886,\n",
       "         0.00109667, 0.00091044, 0.00106582, 0.00111892, 0.00131543,\n",
       "         0.00108847, 0.00098243, 0.00098049, 0.0010352 , 0.0010224 ,\n",
       "         0.00098984, 0.00106442, 0.00126878, 0.00111728, 0.0010749 ,\n",
       "         0.00108818, 0.00116556, 0.0011286 , 0.00092101, 0.00122725,\n",
       "         0.00119607, 0.00098438, 0.00131435, 0.00098991, 0.00101896,\n",
       "         0.0012101 , 0.00116588, 0.00139874, 0.00086429, 0.00100576,\n",
       "         0.00107258, 0.00110729, 0.00132771, 0.00107464, 0.00105243,\n",
       "         0.00098149, 0.00112099, 0.00099288, 0.00110197, 0.00106036,\n",
       "         0.00126188, 0.00110046, 0.00098777, 0.00099524, 0.00105677,\n",
       "         0.00102293, 0.00113264, 0.00107842, 0.00092637, 0.00118777,\n",
       "         0.00104468, 0.00113602, 0.00109932, 0.00116024, 0.00112285,\n",
       "         0.00117389, 0.00101765, 0.00105909, 0.00098285, 0.00130972,\n",
       "         0.00127002, 0.00111689, 0.00107318, 0.00101404, 0.00104255,\n",
       "         0.00101912, 0.0013021 , 0.00149718, 0.00086993, 0.00105386,\n",
       "         0.00087072, 0.000946  , 0.0011939 , 0.00114902, 0.00083973,\n",
       "         0.00095505, 0.00112188, 0.00142084, 0.00098487, 0.00097079,\n",
       "         0.00122338, 0.00116924, 0.00117898, 0.00115271, 0.00137405,\n",
       "         0.00106046, 0.00095157, 0.00093283, 0.00104425, 0.00116335,\n",
       "         0.00098531, 0.00109456, 0.00112487, 0.00091746, 0.00077811,\n",
       "         0.00098283, 0.00133282, 0.00128276, 0.00128502, 0.00104542,\n",
       "         0.00110383, 0.00119166, 0.0013309 , 0.00109972, 0.00112016,\n",
       "         0.00121075, 0.00100758, 0.00110587, 0.00114386, 0.0011975 ,\n",
       "         0.00092871, 0.00112217, 0.00102827, 0.00099526, 0.00104856,\n",
       "         0.00100024, 0.00099361, 0.00114321, 0.00104411, 0.00094502,\n",
       "         0.00094158, 0.00100854, 0.00113904, 0.00104813, 0.00109441,\n",
       "         0.0011093 , 0.00095993, 0.0012204 , 0.00119885, 0.00095373,\n",
       "         0.00121634, 0.00090384, 0.00122075, 0.00108049, 0.00108076,\n",
       "         0.0008905 , 0.0011706 , 0.00114839, 0.00107275, 0.0009004 ,\n",
       "         0.00097677, 0.00133673, 0.00095336, 0.00096546, 0.00098215,\n",
       "         0.00108414, 0.00097774, 0.00115902, 0.00091106, 0.00101766,\n",
       "         0.00106241, 0.0010757 , 0.00111349, 0.00117476, 0.00123798,\n",
       "         0.00112814, 0.00103717, 0.00111914, 0.00120886, 0.00093672,\n",
       "         0.00113675, 0.00113482, 0.00113326, 0.00103935, 0.00126479,\n",
       "         0.00102407, 0.00088725, 0.00092916, 0.00117802, 0.00117162,\n",
       "         0.00098461, 0.00110526, 0.00110395, 0.00104911, 0.00116232,\n",
       "         0.00117012, 0.00121781, 0.00093288, 0.00095661, 0.00114063,\n",
       "         0.0010178 , 0.00105085, 0.00117354, 0.00104376, 0.0009555 ,\n",
       "         0.00119742, 0.0008959 , 0.00107161, 0.00110472, 0.00100546,\n",
       "         0.00099783, 0.00108078, 0.00102027, 0.00112975, 0.0011854 ,\n",
       "         0.00095847, 0.00101744, 0.00121342, 0.00112312, 0.00100041,\n",
       "         0.00097425, 0.00117738, 0.00107328, 0.00095035, 0.00101171,\n",
       "         0.00117867, 0.00121709, 0.00101628, 0.00130482, 0.00115054,\n",
       "         0.00112362, 0.00108768, 0.00139649, 0.00109262, 0.00094355,\n",
       "         0.0010512 , 0.00112323, 0.00116068, 0.00088594, 0.00106336,\n",
       "         0.00092221, 0.00124586, 0.00103838, 0.00125808, 0.00129976,\n",
       "         0.00109343, 0.00122989, 0.0009309 , 0.00097521, 0.00115438,\n",
       "         0.00100693, 0.00105686, 0.00121784, 0.0012221 , 0.00096147,\n",
       "         0.00105131, 0.0011796 , 0.00121093, 0.00100007, 0.00100871,\n",
       "         0.00103482, 0.0011662 , 0.00093351, 0.00088292, 0.00109747,\n",
       "         0.00106391, 0.00090975, 0.00114604, 0.00123394, 0.00101388,\n",
       "         0.00111801, 0.00102239, 0.00103224, 0.00124084, 0.00116912,\n",
       "         0.00119162, 0.00101178, 0.00093536, 0.00090666, 0.00116877,\n",
       "         0.00107985, 0.00099019, 0.00125275, 0.00123288, 0.00113593,\n",
       "         0.00100895, 0.00121086, 0.00121982, 0.00118725, 0.00073647,\n",
       "         0.0011816 , 0.00095975, 0.00115046, 0.00091103, 0.00115739,\n",
       "         0.00105512, 0.00101542, 0.00116188, 0.00110847, 0.00098353,\n",
       "         0.0011825 , 0.00095239, 0.0009633 , 0.00111206, 0.00109928,\n",
       "         0.00108351, 0.00107044, 0.00103421, 0.00116837, 0.00111996,\n",
       "         0.00107055, 0.00110999, 0.00110011, 0.00095018, 0.00121471,\n",
       "         0.00113546, 0.00108382, 0.00110605, 0.00090309, 0.00097138,\n",
       "         0.00106796, 0.00103322, 0.00097829, 0.00101758, 0.00112295,\n",
       "         0.00113205, 0.00115678, 0.00112475, 0.00133921, 0.00088276,\n",
       "         0.00090797, 0.00107473, 0.00132146, 0.00109792, 0.00113467,\n",
       "         0.00123457, 0.00097026, 0.00093635, 0.00087933, 0.00103933,\n",
       "         0.00111816, 0.00098486, 0.00111198, 0.00109925, 0.00107674,\n",
       "         0.00106266, 0.00114984, 0.00100771, 0.00107886, 0.00108666,\n",
       "         0.00121752, 0.00118423, 0.00117437, 0.00095179, 0.00129473,\n",
       "         0.0010226 , 0.00093537, 0.00092582, 0.00116252, 0.00112913,\n",
       "         0.001002  , 0.00100134, 0.00092148, 0.00111225, 0.00092259,\n",
       "         0.00134922, 0.000891  , 0.00103658, 0.00115246, 0.00097364,\n",
       "         0.0009176 , 0.00104975, 0.00101798, 0.00112626, 0.00103488,\n",
       "         0.00102877, 0.00125115, 0.00101921, 0.00106205, 0.00099727,\n",
       "         0.00103801, 0.00124398, 0.00110248, 0.00105237, 0.00116395,\n",
       "         0.00121476, 0.00099201, 0.0010143 , 0.00102036, 0.00093098,\n",
       "         0.00126565, 0.00095725, 0.0010703 , 0.00093063, 0.00128993,\n",
       "         0.00105801, 0.0011242 , 0.00129734, 0.00102532, 0.00102824,\n",
       "         0.00107933, 0.00110405, 0.00091404, 0.00113275, 0.00105454,\n",
       "         0.00093004, 0.00107515, 0.00113661, 0.00100752, 0.00100792,\n",
       "         0.00093521, 0.00114157, 0.00089934, 0.00103723, 0.00106386,\n",
       "         0.0013884 , 0.00122989, 0.00118957, 0.00116198, 0.00120517,\n",
       "         0.0011596 , 0.00130461, 0.00109687, 0.00112889, 0.00104221,\n",
       "         0.00104502, 0.00112361, 0.001206  , 0.00093734, 0.00132639,\n",
       "         0.00101297, 0.00112012, 0.00103422, 0.00114934, 0.00136638,\n",
       "         0.00106193, 0.00096799, 0.00115655, 0.00137119, 0.00108187,\n",
       "         0.00115339, 0.00126041, 0.00092222, 0.00123367, 0.00094396,\n",
       "         0.00094242, 0.00105013, 0.00114113, 0.0013174 , 0.00092582,\n",
       "         0.00113344, 0.00085623, 0.00104254, 0.00106205, 0.00112227,\n",
       "         0.00109286, 0.00102034, 0.00089103, 0.00084861, 0.00113736,\n",
       "         0.00107543, 0.00103018, 0.00107239, 0.00108614, 0.0011124 ,\n",
       "         0.00105488, 0.00101478, 0.0011866 , 0.0011019 , 0.00091829,\n",
       "         0.00115087, 0.00109095, 0.00085578, 0.00091946, 0.00105241,\n",
       "         0.00124035, 0.00104169, 0.00119177, 0.00110611, 0.00104821,\n",
       "         0.00099466, 0.00113117, 0.00116075, 0.0010124 , 0.00097363,\n",
       "         0.00099544, 0.00105735, 0.00100563, 0.00098283, 0.00124245,\n",
       "         0.00102402, 0.00114487, 0.00100474, 0.001028  , 0.00099122,\n",
       "         0.00084765, 0.00106135, 0.00087728, 0.00095114, 0.00091072,\n",
       "         0.00121065, 0.00102523, 0.00099139, 0.00108756, 0.00104312,\n",
       "         0.00115159, 0.00112013, 0.00104403, 0.00088943, 0.00113846,\n",
       "         0.00116327, 0.00107253, 0.00107099, 0.00125214, 0.00113853,\n",
       "         0.0010045 , 0.00118944, 0.00105989, 0.00105118, 0.00123886,\n",
       "         0.00104202, 0.00093012, 0.00103521, 0.00092169, 0.00116604,\n",
       "         0.00086743, 0.00094918, 0.00094892, 0.00099657, 0.00104896,\n",
       "         0.00124659, 0.0009071 , 0.00093792, 0.00126911, 0.0008965 ,\n",
       "         0.00108747, 0.00146315, 0.00107251, 0.00118445, 0.00105678,\n",
       "         0.00089147, 0.00111136, 0.00120763, 0.00087261, 0.00104611,\n",
       "         0.00093904, 0.00112293, 0.00098916, 0.001324  , 0.00129474,\n",
       "         0.00111391, 0.00112949, 0.00152239, 0.0010412 , 0.00120878,\n",
       "         0.00098464, 0.00098381, 0.00114904, 0.00122932, 0.00099621,\n",
       "         0.00100003, 0.00106959, 0.00107932, 0.00108132, 0.00101174,\n",
       "         0.00107847, 0.00098262, 0.00118033, 0.00110366, 0.00126947,\n",
       "         0.00114848, 0.00082642, 0.00099783, 0.00096373, 0.00104084,\n",
       "         0.00088503, 0.00110673, 0.00088093, 0.00114797, 0.00102724,\n",
       "         0.00109585, 0.00104082, 0.00096946, 0.00105058, 0.00111528,\n",
       "         0.00118071, 0.00089545, 0.00089878, 0.00106396, 0.00117844,\n",
       "         0.00113972, 0.0011014 , 0.0011859 , 0.00080634, 0.00143957,\n",
       "         0.00114398, 0.00091994, 0.00095355, 0.00115732, 0.00115983,\n",
       "         0.00101406, 0.00106544, 0.00091973, 0.00098333, 0.00097984,\n",
       "         0.0011628 , 0.00119888, 0.00097023, 0.00105659, 0.0010632 ,\n",
       "         0.00113104, 0.00136198, 0.0013637 , 0.00123149, 0.00104031]],\n",
       "       dtype=float32), array([[0.4865731]], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.predict(np.array([trainX[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"gz_dev.model.new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
