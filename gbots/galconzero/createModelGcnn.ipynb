{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 22, 14)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 22, 14)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 22, 10)       150         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 22, 10)       0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 22, 10)       0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 22, 8)        88          dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 22, 8)        0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 176)          0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 176)          0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 20)           3540        dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 20)           0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 20)           0           leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 15)           315         dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 15)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 15)           0           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 176)          0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 7)            112         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 100)          17700       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 7)            0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 100)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 7)            0           leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "policy (Dense)                  (None, 925)          93425       leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "value (Dense)                   (None, 1)            8           dropout_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 115,338\n",
      "Trainable params: 115,338\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, Flatten, LeakyReLU, Dropout\n",
    "from keras.utils import plot_model\n",
    "from nnSetup import NUM_PLANETS, NUM_FEATURES, NUM_OUTPUTS\n",
    "\n",
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import *\n",
    "\n",
    "FILTER = 'localpool'  # 'chebyshev'\n",
    "MAX_DEGREE = 2  # maximum polynomial degree\n",
    "SYM_NORM = True  # symmetric (True) vs. left-only (False) normalization\n",
    "\n",
    "RELU_ALPHA = 0.05\n",
    "\n",
    "# INPUTS\n",
    "inputs = Input(shape=(NUM_PLANETS, NUM_FEATURES))\n",
    "\n",
    "# BODY\n",
    "# TODO: insert residual GCNNs layers here\n",
    "body = Dropout(0.2)(inputs)\n",
    "body = Dense(10)(body)\n",
    "body = LeakyReLU(alpha=RELU_ALPHA)(body)\n",
    "\n",
    "body = Dropout(0.2)(body)\n",
    "body = Dense(8)(body)\n",
    "body = LeakyReLU(alpha=RELU_ALPHA)(body)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "body = Flatten()(body)\n",
    "\n",
    "# POLICY HEAD\n",
    "policyHead = Dropout(0.2)(body)\n",
    "policyHead = Dense(100)(policyHead)\n",
    "policyHead = LeakyReLU(alpha=RELU_ALPHA)(policyHead)\n",
    "\n",
    "policyHead = Dropout(0.2)(body)\n",
    "policyHead = Dense(100)(policyHead)\n",
    "policyHead = LeakyReLU(alpha=RELU_ALPHA)(policyHead)\n",
    "\n",
    "policyHead = Dropout(0.2)(body)\n",
    "policyHead = Dense(100)(policyHead)\n",
    "policyHead = LeakyReLU(alpha=RELU_ALPHA)(policyHead)\n",
    "\n",
    "policyHead = Dense(NUM_OUTPUTS, activation='softmax', name='policy')(policyHead)\n",
    "\n",
    "# VALUE HEAD\n",
    "valueHead = Dropout(0.3)(body)\n",
    "valueHead = Dense(20)(valueHead)\n",
    "valueHead = LeakyReLU(alpha=RELU_ALPHA)(valueHead)\n",
    "\n",
    "valueHead = Dropout(0.3)(valueHead)\n",
    "valueHead = Dense(15)(valueHead)\n",
    "valueHead = LeakyReLU(alpha=RELU_ALPHA)(valueHead)\n",
    "\n",
    "valueHead = Dropout(0.2)(valueHead)\n",
    "valueHead = Dense(7)(valueHead)\n",
    "valueHead = LeakyReLU(alpha=RELU_ALPHA)(valueHead)\n",
    "\n",
    "valueHead = Dropout(0.2)(valueHead)\n",
    "valueHead = Dense(1, activation='sigmoid', name='value')(valueHead)\n",
    "\n",
    "# TODO: multiple percentages\n",
    "model = Model(inputs=inputs, outputs=[policyHead, valueHead], name='GZ_DenseNetwork')\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "plot_model(model, to_file='model_graph.png')\n",
    "\n",
    "# TODO: are these losses right??\n",
    "# TODO: measure losses to get better loss weights?\n",
    "# TODO: are these metrics right?\n",
    "model.compile(loss=['categorical_crossentropy', 'binary_crossentropy'], loss_weights=[1, 2], optimizer='adam', metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainingGame import loadTrainingGame\n",
    "from trainingHelper import TrainingHelper\n",
    "\n",
    "game = loadTrainingGame(\"testGame.pickle\")\n",
    "helper = TrainingHelper(game) \n",
    "\n",
    "trainX = helper.getTrainX()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.00107294, 0.00093284, 0.00107461, 0.00113132, 0.00107199,\n",
       "         0.00107634, 0.00128456, 0.00097383, 0.00121425, 0.0012838 ,\n",
       "         0.00137838, 0.00125878, 0.00115916, 0.00088388, 0.00107319,\n",
       "         0.00091255, 0.00113062, 0.00101098, 0.00128123, 0.00096877,\n",
       "         0.00108837, 0.00119957, 0.00112611, 0.00118664, 0.00091671,\n",
       "         0.00092098, 0.00118476, 0.0011504 , 0.0009681 , 0.00108217,\n",
       "         0.00094565, 0.00118002, 0.00107051, 0.00112769, 0.00108426,\n",
       "         0.00125077, 0.00123236, 0.00101   , 0.00110811, 0.00117735,\n",
       "         0.00092882, 0.00105772, 0.00118676, 0.00108165, 0.00110044,\n",
       "         0.00118064, 0.00110189, 0.00100813, 0.00134755, 0.00098648,\n",
       "         0.00093789, 0.0011036 , 0.00097268, 0.00094883, 0.00113756,\n",
       "         0.00105065, 0.00121832, 0.00109778, 0.00115205, 0.001259  ,\n",
       "         0.00115686, 0.00101418, 0.00094448, 0.00102198, 0.0011504 ,\n",
       "         0.00123028, 0.00107131, 0.00099855, 0.00100464, 0.00104993,\n",
       "         0.00128492, 0.00094269, 0.00110943, 0.00133263, 0.00074755,\n",
       "         0.0010612 , 0.00097201, 0.00106771, 0.00109363, 0.00097862,\n",
       "         0.00098393, 0.00103497, 0.00098724, 0.00114305, 0.00099364,\n",
       "         0.001046  , 0.00107636, 0.0009093 , 0.00125334, 0.00101524,\n",
       "         0.00115788, 0.00134374, 0.00091373, 0.00120089, 0.00094586,\n",
       "         0.00119092, 0.00103993, 0.00111357, 0.0009778 , 0.00118004,\n",
       "         0.00091754, 0.00104235, 0.00112314, 0.00130523, 0.00102533,\n",
       "         0.0013137 , 0.00117223, 0.00098564, 0.00107025, 0.0012078 ,\n",
       "         0.0010193 , 0.00109682, 0.00108911, 0.00113007, 0.00106927,\n",
       "         0.00117336, 0.00095228, 0.00095721, 0.00115146, 0.00104923,\n",
       "         0.00113017, 0.00140392, 0.00109773, 0.0009681 , 0.00104852,\n",
       "         0.00095727, 0.0011778 , 0.00096212, 0.00088057, 0.00089838,\n",
       "         0.00083793, 0.00094404, 0.00123555, 0.0010367 , 0.00118612,\n",
       "         0.00097259, 0.00092734, 0.00108405, 0.00108572, 0.00098876,\n",
       "         0.00092689, 0.00103682, 0.00097904, 0.00105145, 0.00118034,\n",
       "         0.00088232, 0.00106917, 0.00092075, 0.00108343, 0.00130135,\n",
       "         0.00114698, 0.00094621, 0.0008937 , 0.00095026, 0.00118094,\n",
       "         0.00106843, 0.00093524, 0.00116523, 0.00121461, 0.00088295,\n",
       "         0.00101588, 0.00122733, 0.00095544, 0.00089824, 0.00095475,\n",
       "         0.00089174, 0.00110316, 0.000873  , 0.00092865, 0.00093787,\n",
       "         0.00121344, 0.00126972, 0.00109496, 0.00092744, 0.00102695,\n",
       "         0.00085302, 0.00122607, 0.0012104 , 0.00114383, 0.00134091,\n",
       "         0.00113258, 0.0009225 , 0.00113321, 0.00086589, 0.00072553,\n",
       "         0.00089134, 0.00121217, 0.00114031, 0.00100904, 0.00101853,\n",
       "         0.00120966, 0.00095271, 0.00115275, 0.00134686, 0.00095985,\n",
       "         0.00115115, 0.00105881, 0.0010108 , 0.0011723 , 0.00099846,\n",
       "         0.00108055, 0.00093325, 0.00098422, 0.00104416, 0.00096653,\n",
       "         0.00157416, 0.0013458 , 0.00085761, 0.00093086, 0.00101932,\n",
       "         0.00109959, 0.00085747, 0.00104672, 0.00097335, 0.00092755,\n",
       "         0.0010488 , 0.00116082, 0.00096049, 0.00094259, 0.00097618,\n",
       "         0.00119875, 0.00110174, 0.00115955, 0.00111388, 0.00110513,\n",
       "         0.0012757 , 0.00094591, 0.00116971, 0.00113583, 0.00103969,\n",
       "         0.00097112, 0.00130613, 0.00112584, 0.00122749, 0.00090082,\n",
       "         0.00119785, 0.00110475, 0.00114249, 0.00107159, 0.00102872,\n",
       "         0.0011249 , 0.00098805, 0.0011971 , 0.00128986, 0.00092679,\n",
       "         0.0012998 , 0.00106665, 0.00105641, 0.00110132, 0.00102539,\n",
       "         0.0010538 , 0.00122086, 0.00087702, 0.00091972, 0.00107955,\n",
       "         0.00096073, 0.00092771, 0.0009486 , 0.00094505, 0.00090044,\n",
       "         0.00098288, 0.00090856, 0.00109102, 0.00117888, 0.0010194 ,\n",
       "         0.00114809, 0.00109916, 0.00118795, 0.0011576 , 0.00098239,\n",
       "         0.00138139, 0.0010415 , 0.00110487, 0.00105691, 0.00105053,\n",
       "         0.00109073, 0.00126941, 0.00080416, 0.00108857, 0.00098573,\n",
       "         0.00115731, 0.00121245, 0.00125581, 0.00089321, 0.00117225,\n",
       "         0.00111444, 0.00121086, 0.0010174 , 0.00121905, 0.00124876,\n",
       "         0.00128383, 0.00098941, 0.00126438, 0.00107785, 0.00089859,\n",
       "         0.00114978, 0.00122653, 0.00114886, 0.0010932 , 0.00106895,\n",
       "         0.00099552, 0.00086543, 0.00110359, 0.00085983, 0.00127729,\n",
       "         0.00112055, 0.0011893 , 0.00112711, 0.00108425, 0.00126606,\n",
       "         0.00118174, 0.0011963 , 0.0009525 , 0.00099038, 0.00084274,\n",
       "         0.00134407, 0.00092132, 0.00133321, 0.00103683, 0.00125815,\n",
       "         0.00113149, 0.00128317, 0.00089877, 0.00091582, 0.0010795 ,\n",
       "         0.00108668, 0.00133377, 0.00098901, 0.00120339, 0.00125447,\n",
       "         0.00099612, 0.00094444, 0.00105516, 0.00106617, 0.00097125,\n",
       "         0.00101496, 0.00091773, 0.00114142, 0.00094932, 0.00120109,\n",
       "         0.00095685, 0.00138758, 0.00091784, 0.00104878, 0.00096734,\n",
       "         0.00100045, 0.00104305, 0.00123054, 0.00121774, 0.00097636,\n",
       "         0.00103919, 0.00096349, 0.00101666, 0.00106011, 0.00091212,\n",
       "         0.00099753, 0.00110781, 0.00105919, 0.00113271, 0.00103592,\n",
       "         0.00123793, 0.00107973, 0.001203  , 0.00100026, 0.00132564,\n",
       "         0.00090773, 0.00103948, 0.00094581, 0.00098754, 0.00121263,\n",
       "         0.00111231, 0.00094246, 0.00109075, 0.00113328, 0.00116492,\n",
       "         0.00115771, 0.00083394, 0.00097529, 0.00114435, 0.00093246,\n",
       "         0.00113413, 0.00118437, 0.0011173 , 0.00107788, 0.00112887,\n",
       "         0.00119198, 0.00114347, 0.00087704, 0.00097274, 0.00094091,\n",
       "         0.00121851, 0.00106015, 0.00100318, 0.00082825, 0.00122022,\n",
       "         0.00163451, 0.00134896, 0.00098763, 0.00099663, 0.00124829,\n",
       "         0.00113312, 0.00108553, 0.00124887, 0.00105184, 0.00100743,\n",
       "         0.00107977, 0.00095035, 0.00090574, 0.00113184, 0.00109656,\n",
       "         0.00102651, 0.00091667, 0.00110985, 0.00113058, 0.00109708,\n",
       "         0.00095024, 0.00082414, 0.00108122, 0.00102813, 0.00105107,\n",
       "         0.00089077, 0.00121819, 0.00145072, 0.00126741, 0.0010619 ,\n",
       "         0.00104401, 0.00093972, 0.00109496, 0.00123907, 0.00119935,\n",
       "         0.00130585, 0.00114056, 0.00081717, 0.00111225, 0.0009894 ,\n",
       "         0.00096613, 0.00104946, 0.00079349, 0.00098115, 0.00100052,\n",
       "         0.00126426, 0.00135077, 0.00094351, 0.0012778 , 0.00101753,\n",
       "         0.00087146, 0.00121037, 0.00113461, 0.00113922, 0.00108209,\n",
       "         0.00113417, 0.00122965, 0.00110824, 0.00102723, 0.00128752,\n",
       "         0.00100851, 0.00108056, 0.00112019, 0.00117445, 0.00107601,\n",
       "         0.00123493, 0.00114151, 0.00121332, 0.00097546, 0.00114911,\n",
       "         0.00114051, 0.00129539, 0.00126424, 0.00102909, 0.00125005,\n",
       "         0.00131134, 0.00107848, 0.00101135, 0.00106423, 0.00131899,\n",
       "         0.00131633, 0.00084126, 0.00091918, 0.00115571, 0.00091843,\n",
       "         0.00109869, 0.0011288 , 0.00118646, 0.00091413, 0.00094786,\n",
       "         0.00133525, 0.00121898, 0.00101896, 0.00138394, 0.00116509,\n",
       "         0.00103035, 0.00118159, 0.00103436, 0.00121555, 0.00092714,\n",
       "         0.0011422 , 0.00124745, 0.00123046, 0.00108872, 0.0010894 ,\n",
       "         0.00118527, 0.00096552, 0.0011713 , 0.00113044, 0.00096882,\n",
       "         0.00103933, 0.00124084, 0.0009688 , 0.00095167, 0.00082642,\n",
       "         0.00130478, 0.0010184 , 0.00087806, 0.00115126, 0.00125572,\n",
       "         0.00096072, 0.00097821, 0.00125489, 0.00093372, 0.00093937,\n",
       "         0.00112719, 0.00127705, 0.00114628, 0.00111788, 0.0009618 ,\n",
       "         0.00091931, 0.00101191, 0.00120064, 0.0012332 , 0.00117512,\n",
       "         0.00088292, 0.00089971, 0.00097651, 0.00108499, 0.00106002,\n",
       "         0.00095462, 0.00092205, 0.00099582, 0.00096609, 0.00143641,\n",
       "         0.00115906, 0.00130217, 0.00124669, 0.00094625, 0.00108777,\n",
       "         0.00113886, 0.00096058, 0.00115996, 0.0007856 , 0.0012057 ,\n",
       "         0.00118683, 0.00123554, 0.00100527, 0.00117215, 0.00102691,\n",
       "         0.00103251, 0.00118529, 0.00118158, 0.00105438, 0.00092168,\n",
       "         0.00108866, 0.00089177, 0.00097793, 0.00117416, 0.00097442,\n",
       "         0.00118288, 0.00107241, 0.00086124, 0.00116118, 0.00107137,\n",
       "         0.00091494, 0.00118702, 0.00103644, 0.00109265, 0.00086293,\n",
       "         0.00114291, 0.00088892, 0.00099796, 0.0012935 , 0.00101811,\n",
       "         0.00105067, 0.00090077, 0.00106418, 0.00111203, 0.00109304,\n",
       "         0.00111387, 0.00094793, 0.00093237, 0.00109263, 0.00108282,\n",
       "         0.00096691, 0.00117718, 0.0009854 , 0.00108004, 0.00095593,\n",
       "         0.00122452, 0.00110961, 0.00122297, 0.00092687, 0.00104975,\n",
       "         0.00129078, 0.00094047, 0.00113896, 0.00111607, 0.00081004,\n",
       "         0.00093722, 0.00112002, 0.00118622, 0.0008723 , 0.00113543,\n",
       "         0.00101236, 0.00110365, 0.00109189, 0.00109375, 0.00124406,\n",
       "         0.00100493, 0.00073573, 0.00098069, 0.00101116, 0.00110778,\n",
       "         0.00100698, 0.00087662, 0.00114838, 0.00091173, 0.00118474,\n",
       "         0.00150182, 0.00130587, 0.00109008, 0.00102305, 0.00121426,\n",
       "         0.00103365, 0.00092895, 0.00114067, 0.00111739, 0.00097146,\n",
       "         0.00099462, 0.00127425, 0.00101452, 0.00114353, 0.00095809,\n",
       "         0.00075307, 0.00100278, 0.00101173, 0.0013186 , 0.00095107,\n",
       "         0.00105693, 0.00086776, 0.00107992, 0.00085966, 0.00090125,\n",
       "         0.00129635, 0.00102712, 0.00130254, 0.0013022 , 0.00098828,\n",
       "         0.00106307, 0.0012525 , 0.00110843, 0.00115179, 0.00119163,\n",
       "         0.00104792, 0.00092927, 0.00111585, 0.00107181, 0.00112513,\n",
       "         0.00126686, 0.00111142, 0.00112432, 0.00092755, 0.00116226,\n",
       "         0.00106556, 0.00134173, 0.00127921, 0.00103369, 0.00092108,\n",
       "         0.00102762, 0.0008535 , 0.00105871, 0.00124285, 0.00109506,\n",
       "         0.00126365, 0.00113261, 0.00107657, 0.00103513, 0.0011651 ,\n",
       "         0.0010563 , 0.00120514, 0.00097099, 0.0010425 , 0.00120523,\n",
       "         0.00085751, 0.00138826, 0.00124477, 0.00121216, 0.00104391,\n",
       "         0.00122627, 0.00111392, 0.00089737, 0.00097515, 0.00103281,\n",
       "         0.00105509, 0.00108574, 0.00088479, 0.00105899, 0.00125985,\n",
       "         0.00122042, 0.00113071, 0.0011612 , 0.00102481, 0.00102404,\n",
       "         0.00119317, 0.00083832, 0.00120388, 0.00113391, 0.0009454 ,\n",
       "         0.00101232, 0.00122576, 0.00103251, 0.00077662, 0.00115538,\n",
       "         0.00106806, 0.00117677, 0.00110498, 0.0009581 , 0.0010152 ,\n",
       "         0.00120213, 0.00090782, 0.00113565, 0.00121804, 0.00115545,\n",
       "         0.00104437, 0.00096501, 0.00129529, 0.00098198, 0.00111859,\n",
       "         0.00090001, 0.00099267, 0.00089064, 0.00106455, 0.00111248,\n",
       "         0.00091718, 0.00097243, 0.00123499, 0.00101321, 0.00122986,\n",
       "         0.00111646, 0.00110466, 0.00095786, 0.00110085, 0.00098536,\n",
       "         0.00152192, 0.00093722, 0.00126169, 0.00097705, 0.00110962,\n",
       "         0.001132  , 0.00120494, 0.0012292 , 0.00101743, 0.0012319 ,\n",
       "         0.0012587 , 0.00111315, 0.00105228, 0.00135673, 0.00118542,\n",
       "         0.00106833, 0.0010996 , 0.00144079, 0.00123602, 0.00115117,\n",
       "         0.00087344, 0.00095486, 0.00087957, 0.00104336, 0.00129445,\n",
       "         0.00112922, 0.00106164, 0.00101858, 0.00100938, 0.0011378 ,\n",
       "         0.00108557, 0.00123989, 0.00102823, 0.00115506, 0.00111906,\n",
       "         0.00080877, 0.00082206, 0.00102196, 0.00087214, 0.00101075,\n",
       "         0.00110677, 0.00088937, 0.00102629, 0.00111584, 0.00100492,\n",
       "         0.00095485, 0.00093888, 0.00098149, 0.00087263, 0.00087853,\n",
       "         0.00117234, 0.00108861, 0.00138998, 0.00096409, 0.00097347,\n",
       "         0.00114962, 0.00109066, 0.001165  , 0.00130676, 0.0010072 ,\n",
       "         0.00129972, 0.00115984, 0.00100998, 0.00105207, 0.00093853,\n",
       "         0.00109729, 0.00121804, 0.00112321, 0.0010609 , 0.00102992,\n",
       "         0.00107831, 0.00127022, 0.00116738, 0.00102639, 0.0011836 ,\n",
       "         0.0010888 , 0.00113263, 0.00107935, 0.00109921, 0.00122971,\n",
       "         0.00114625, 0.00099059, 0.00096526, 0.00113923, 0.00123156,\n",
       "         0.00122818, 0.00097527, 0.00109767, 0.00105108, 0.00129445,\n",
       "         0.00100406, 0.00097294, 0.00106853, 0.00103735, 0.00102216,\n",
       "         0.00097429, 0.00097911, 0.00136813, 0.00117868, 0.00112937,\n",
       "         0.00107976, 0.00095184, 0.0009634 , 0.00096473, 0.00113197,\n",
       "         0.00108583, 0.00103299, 0.00099742, 0.00113285, 0.00107999,\n",
       "         0.00126284, 0.00116808, 0.00094158, 0.00125071, 0.00122289,\n",
       "         0.00082946, 0.00087804, 0.00097071, 0.00113646, 0.00122677,\n",
       "         0.00123894, 0.00100738, 0.00111219, 0.0010822 , 0.0012504 ,\n",
       "         0.00105977, 0.00108894, 0.0011309 , 0.00105154, 0.00100203,\n",
       "         0.00113226, 0.00099786, 0.00090585, 0.00090737, 0.00123188,\n",
       "         0.00104618, 0.00134839, 0.00126774, 0.00085308, 0.00086   ,\n",
       "         0.00114727, 0.00082294, 0.00116391, 0.00114117, 0.00135394,\n",
       "         0.00096177, 0.00090092, 0.00127417, 0.00128077, 0.00112824,\n",
       "         0.00112497, 0.00112697, 0.00114154, 0.00113572, 0.00082176,\n",
       "         0.00123127, 0.00084127, 0.00091212, 0.00113501, 0.00155741,\n",
       "         0.00107361, 0.00090192, 0.00119542, 0.0011031 , 0.00126286,\n",
       "         0.00099692, 0.0010491 , 0.00110972, 0.00115172, 0.00103839,\n",
       "         0.00108355, 0.00078884, 0.00127393, 0.00107743, 0.00121861]],\n",
       "       dtype=float32), array([[0.50494224]], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.predict(np.array([trainX[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"gz_dev.model.new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
